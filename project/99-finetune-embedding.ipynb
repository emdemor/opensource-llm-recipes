{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2925a119-ce15-46dd-b8a8-f8b1f5333686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> accelerate==0.29.3\n"
     ]
    }
   ],
   "source": [
    "def install_lib(libname):\n",
    "    print(f\">>> {libname}\")\n",
    "    get_ipython().system(f\"pip install -qqq {libname}\")\n",
    "\n",
    "libs = [\n",
    "    \"accelerate==0.29.3\"\n",
    "]\n",
    "\n",
    "for lib in libs:\n",
    "    install_lib(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a113f545-760f-40cc-b718-2f12ff087670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import login\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5c3a55-a0b9-4426-8de1-c9ee3a1a1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "# MODEL_ID = 'PORTULAN/serafim-900m-portuguese-pt-sentence-encoder-ir'\n",
    "MODEL_ID = \"BAAI/bge-small-en-v1.5\"\n",
    "MATRYOSHKA_DIMENSIONS = [384, 256, 128, 64] # [768, 512, 256, 128, 64]\n",
    "TRAIN_DATASET = \"data/bacen/train_dataset.json\"\n",
    "TEST_DATASET = \"data/bacen/test_dataset.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce02f20-8e03-496d-8ebd-99e344c688d3",
   "metadata": {},
   "source": [
    "## 1. Crie e Prepare o Conjunto de Dados de Incorporação\n",
    "\n",
    "Um conjunto de dados de embedding geralmente consiste em pares de texto (pergunta, resposta/contexto) ou tríades que representam relações ou semelhanças entre frases. O formato do conjunto de dados que você escolher ou tiver disponível também afetará a função de perda que você pode usar. Formatos comuns para conjuntos de dados de embedding:\n",
    "\n",
    "- **Par Positivo**: Pares de texto de frases relacionadas (consulta, contexto | consulta, resposta), adequados para tarefas como pesquisa de semelhança ou busca semântica, exemplos de conjuntos de dados: `sentence-transformers/sentence-compression`, `sentence-transformers/natural-questions`.\n",
    "- **Tríades**: Tríades de texto compostas por (âncora, positivo, negativo), exemplos de conjuntos de dados `sentence-transformers/quora-duplicates`, `nirantk/triplets`.\n",
    "- **Par com Pontuação de Similaridade**: Pares de frases com uma pontuação de similaridade indicando o quão relacionadas são, exemplos de conjuntos de dados: `sentence-transformers/stsb`, `PhilipMay/stsb_multi_mt`\n",
    "\n",
    "Saiba mais em [Visão Geral dos Conjuntos de Dados](https://sbert.net/docs/sentence_transformer/dataset_overview.html).\n",
    "\n",
    "Vamos usar o dataset [Itau-Unibanco/FAQ_BACEN)](https://huggingface.co/datasets/Itau-Unibanco/FAQ_BACEN), que inclui 7.000 pares de texto positivos de perguntas e contextos correspondentes do [Relatório SEC da NVIDIA de 2023_10](https://stocklight.com/stocks/us/nasdaq-nvda/nvidia/annual-reports/nasdaq-nvda-2023-10K-23668751.pdf).\n",
    "\n",
    "O conjunto de dados tem o seguinte formato:\n",
    "```json\n",
    "{\"questions\": \"<pergunta>\", \"answers\": \"<contexto relevante para a resposta>\"}\n",
    "{\"questions\": \"<pergunta>\", \"answers\": \"<contexto relevante para a resposta>\"}\n",
    "{\"questions\": \"<pergunta>\", \"answers\": \"<contexto relevante para a resposta>\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6cb6fa-b337-4d2c-971b-78bf7dda98b2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b43e08-3d13-4024-8fbd-6098334e2eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Dataset importado com 4046601 linhas\n",
      ">>> Apos remover domínios sem relevância, o dataset ficou com 3158116 linhas\n",
      ">>> Apos remover domínios com termos indesejáveis, o dataset ficou com 3085331 linhas\n",
      "CPU times: user 72.5 ms, sys: 39 ms, total: 112 ms\n",
      "Wall time: 65.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_filepath = \"data/clips_mqa/pt\"\n",
    "dataset = load_from_disk(dataset_filepath)\n",
    "print(f\">>> Dataset importado com {dataset.num_rows} linhas\")\n",
    "\n",
    "# Removendo domínios sem relevância\n",
    "def valid_domain(text):\n",
    "    if (text[-3:] == \".br\") or (text[-4:] in [\".com\", \".net\", \".org\"]):\n",
    "        return True\n",
    "    return False\n",
    "dataset = dataset.filter(lambda row: valid_domain(row[\"domain\"]) )\n",
    "print(f\">>> Apos remover domínios sem relevância, o dataset ficou com {dataset.num_rows} linhas\")\n",
    "        \n",
    "    \n",
    "# bloquear dominios \n",
    "def contains_prohibited_term_regex(text):\n",
    "    blacklist = [\n",
    "        \"mundosugar.com.br\",\n",
    "        \"aposta\",\n",
    "        \"apuesta\",\n",
    "        \"sex\",\n",
    "        \"porn\",\n",
    "        \"penis\",\n",
    "        \"vagi\",\n",
    "        \"turba\",\n",
    "        \"sensual\",\n",
    "    ]\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, blacklist)))\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "dataset = dataset.filter(lambda row: not contains_prohibited_term_regex(row[\"domain\"]) )\n",
    "print(f\">>> Apos remover domínios com termos indesejáveis, o dataset ficou com {dataset.num_rows} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a6ed993a-d893-424a-bce6-c8bb406cd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 1.25 s, total: 19.4 s\n",
      "Wall time: 19.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bucket</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1708125</th>\n",
       "      <td>633ac8de66695d1671ffdea1476231fa</td>\n",
       "      <td>2021.10</td>\n",
       "      <td>hoteis.com</td>\n",
       "      <td></td>\n",
       "      <td>quais sao as medidas de limpeza e higiene em v...</td>\n",
       "      <td>este estabelecimento confirma que sao utilizad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466777</th>\n",
       "      <td>c678d0382e184b5d534dea19f6d6dda3</td>\n",
       "      <td>2019.47</td>\n",
       "      <td>aluguetemporada.com.br</td>\n",
       "      <td></td>\n",
       "      <td>Posso reservar um imovel para temporada direta...</td>\n",
       "      <td>Sim. O AlugueTemporada oferece 134 imoveis par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474495</th>\n",
       "      <td>c4fe2ce007f3ba02412e705170008ce6</td>\n",
       "      <td>2021.25</td>\n",
       "      <td>kayak.com.br</td>\n",
       "      <td></td>\n",
       "      <td>qual e a agencia de aluguel de carros mais pop...</td>\n",
       "      <td>premium ford focus ou similar e o tipo de carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88406</th>\n",
       "      <td>e6bd3705bfab4cc7722bcaaf2371d374</td>\n",
       "      <td>2020.29</td>\n",
       "      <td>edestinos.com.br</td>\n",
       "      <td></td>\n",
       "      <td>quando os voos do aeroporto umtata airport sao...</td>\n",
       "      <td>a oferta da companhia aerea esta mudando const...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id   bucket                  domain  \\\n",
       "1708125  633ac8de66695d1671ffdea1476231fa  2021.10              hoteis.com   \n",
       "466777   c678d0382e184b5d534dea19f6d6dda3  2019.47  aluguetemporada.com.br   \n",
       "2474495  c4fe2ce007f3ba02412e705170008ce6  2021.25            kayak.com.br   \n",
       "88406    e6bd3705bfab4cc7722bcaaf2371d374  2020.29        edestinos.com.br   \n",
       "\n",
       "        text                                           question  \\\n",
       "1708125       quais sao as medidas de limpeza e higiene em v...   \n",
       "466777        Posso reservar um imovel para temporada direta...   \n",
       "2474495       qual e a agencia de aluguel de carros mais pop...   \n",
       "88406         quando os voos do aeroporto umtata airport sao...   \n",
       "\n",
       "                                                    answer  \n",
       "1708125  este estabelecimento confirma que sao utilizad...  \n",
       "466777   Sim. O AlugueTemporada oferece 134 imoveis par...  \n",
       "2474495  premium ford focus ou similar e o tipo de carr...  \n",
       "88406    a oferta da companhia aerea esta mudando const...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset.to_pandas().sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d07afbc-69c2-420e-9d8b-868f9c647065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f3c019aec14b769a2263a35520bc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b06ea3bad44d7cb40fb9105705473b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "347761"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling\n",
    "dataset = dataset.shuffle().select(range(10000))\n",
    "\n",
    "# Selecting columns\n",
    "dataset = dataset.rename_columns({\"question\": \"anchor\", \"answer\": \"positive\"}) .select_columns([\"id\", \"anchor\", \"positive\"])\n",
    "\n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(TRAIN_DATASET, orient=\"records\")\n",
    "dataset[\"test\"].to_json(TEST_DATASET, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c403101-1dd2-4112-8f3f-d8680de9962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6483e9e02f64471bfbe031751b0b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93832447cac425ba5ba96ed3dee5126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load test dataset\n",
    "train_dataset = load_dataset(\"json\", data_files=TRAIN_DATASET, split=\"train\")\n",
    "test_dataset = load_dataset(\"json\", data_files=TEST_DATASET, split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223e8efa-3904-4af8-9dfe-65be0a34d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad91c2cb-6e22-40dc-83c7-9a3d231b2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fede618-bdbe-4692-8bf6-a52582b525bc",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a39791-c8b6-4485-8831-e7778bde5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    MODEL_ID, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8809d73-2f26-420c-9ce5-feab4a3b5468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 ms, sys: 0 ns, total: 2.85 ms\n",
      "Wall time: 2.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in MATRYOSHKA_DIMENSIONS:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc224f5-a6e6-46da-8ee1-cd8d8dbeb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_384_cosine_ndcg@10: 0.5718883115078188\n",
      "dim_256_cosine_ndcg@10: 0.5554733697644808\n",
      "dim_128_cosine_ndcg@10: 0.5229214149363955\n",
      "dim_64_cosine_ndcg@10: 0.4474030387901696\n",
      "CPU times: user 48.6 s, sys: 1.26 s, total: 49.8 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rerun_baseline = False\n",
    "\n",
    "if rerun_baseline:\n",
    "    results = evaluator(model)\n",
    "    for dim in MATRYOSHKA_DIMENSIONS:\n",
    "        key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "        print\n",
    "        print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920f98e-be9c-4227-856e-70d2a5f79539",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad2ac38-1b5f-4c14-a852-b86ea4e97bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    "\n",
    "attn_implementation = \"sdpa\"# \"eager\" # sdpa\n",
    "\n",
    "# # load model with SDPA for using Flash Attention 2\n",
    "# model = SentenceTransformer(\n",
    "#     MODEL_ID,\n",
    "#     model_kwargs={\"attn_implementation\": attn_implementation},\n",
    "#     model_card_data=SentenceTransformerModelCardData(\n",
    "#         language=\"pt-br\",\n",
    "#         license=\"apache-2.0\",\n",
    "#         model_name=\"FAQ-BACEN\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    MODEL_ID,\n",
    "    model_kwargs={\"attn_implementation\": attn_implementation},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"pt-br\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"QA-Brazil\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87175f7b-ca50-4d62-b25f-25dee9d648dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=MATRYOSHKA_DIMENSIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b1ca232-1f25-451b-b57c-be5e976389d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# load train dataset again\n",
    "train_dataset = load_dataset(\"json\", data_files=TRAIN_DATASET, split=\"train\")\n",
    "\n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"./models/bacen/embeddings\", # output directory and hugging face model ID\n",
    "    num_train_epochs=10,                         # number of epochs\n",
    "    per_device_train_batch_size=32,             # train batch size\n",
    "    gradient_accumulation_steps=16,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=16,              # evaluation batch size\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    #tf32=True,                                  # use tf32 precision\n",
    "    #bf16=True,                                  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                      # save after each epoch\n",
    "    logging_steps=10,                           # log every 10 steps\n",
    "    save_total_limit=3,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fd0165d-d471-48cd-aecf-e06046ab9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor: em media, quantas conexoes estao disponiveis por dia de goiania para sao paulo?\n",
      "positive: entre goiania e sao paulo existem por volta de 2 conexoes diariamente. com nosso mecanismo de busca, voce pode comparar os horarios dos onibus para encontrar a viagem perfeita.\n"
     ]
    }
   ],
   "source": [
    "test = train_dataset.to_pandas().sample(1).iloc[0].to_dict()\n",
    "print(f'anchor: {test[\"anchor\"]}')\n",
    "print(f'positive: {test[\"positive\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9019738-b291-4b44-bb2a-055db1e728dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model, # BAAI/bge-small-en-v1.5\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"positive\", \"anchor\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb7eb1cf-7085-441d-b8c5-19f1058fe60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 32:06, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 384 Cosine Accuracy@1</th>\n",
       "      <th>Dim 384 Cosine Accuracy@3</th>\n",
       "      <th>Dim 384 Cosine Accuracy@5</th>\n",
       "      <th>Dim 384 Cosine Accuracy@10</th>\n",
       "      <th>Dim 384 Cosine Precision@1</th>\n",
       "      <th>Dim 384 Cosine Precision@3</th>\n",
       "      <th>Dim 384 Cosine Precision@5</th>\n",
       "      <th>Dim 384 Cosine Precision@10</th>\n",
       "      <th>Dim 384 Cosine Recall@1</th>\n",
       "      <th>Dim 384 Cosine Recall@3</th>\n",
       "      <th>Dim 384 Cosine Recall@5</th>\n",
       "      <th>Dim 384 Cosine Recall@10</th>\n",
       "      <th>Dim 384 Cosine Ndcg@10</th>\n",
       "      <th>Dim 384 Cosine Mrr@10</th>\n",
       "      <th>Dim 384 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.574500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.618404</td>\n",
       "      <td>0.603160</td>\n",
       "      <td>0.607097</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.205333</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.610940</td>\n",
       "      <td>0.594781</td>\n",
       "      <td>0.597889</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.579668</td>\n",
       "      <td>0.563689</td>\n",
       "      <td>0.567261</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.179333</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.530545</td>\n",
       "      <td>0.513918</td>\n",
       "      <td>0.518398</td>\n",
       "      <td>0.518398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.987900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.215667</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.643179</td>\n",
       "      <td>0.629808</td>\n",
       "      <td>0.634561</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.634542</td>\n",
       "      <td>0.621492</td>\n",
       "      <td>0.626425</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.208667</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.623123</td>\n",
       "      <td>0.607525</td>\n",
       "      <td>0.612013</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.594328</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>0.583505</td>\n",
       "      <td>0.583505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.871400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.648385</td>\n",
       "      <td>0.632767</td>\n",
       "      <td>0.637731</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.642306</td>\n",
       "      <td>0.627749</td>\n",
       "      <td>0.633101</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.210333</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.629942</td>\n",
       "      <td>0.611400</td>\n",
       "      <td>0.616088</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.604096</td>\n",
       "      <td>0.588518</td>\n",
       "      <td>0.593913</td>\n",
       "      <td>0.593913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.486500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.217333</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.635823</td>\n",
       "      <td>0.640959</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.648134</td>\n",
       "      <td>0.631752</td>\n",
       "      <td>0.637255</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.211667</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.636560</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.623459</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.613487</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>0.601351</td>\n",
       "      <td>0.601351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.404100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.658165</td>\n",
       "      <td>0.641502</td>\n",
       "      <td>0.646710</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.216333</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.652194</td>\n",
       "      <td>0.634640</td>\n",
       "      <td>0.639714</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.210667</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.637288</td>\n",
       "      <td>0.620030</td>\n",
       "      <td>0.625557</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.618707</td>\n",
       "      <td>0.602270</td>\n",
       "      <td>0.607817</td>\n",
       "      <td>0.607817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.255500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.656806</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.644174</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.651649</td>\n",
       "      <td>0.635473</td>\n",
       "      <td>0.641240</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.642017</td>\n",
       "      <td>0.624682</td>\n",
       "      <td>0.630161</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.204333</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.618190</td>\n",
       "      <td>0.601308</td>\n",
       "      <td>0.607057</td>\n",
       "      <td>0.607057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.088100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.658433</td>\n",
       "      <td>0.640394</td>\n",
       "      <td>0.645689</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.655942</td>\n",
       "      <td>0.639517</td>\n",
       "      <td>0.645102</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.642856</td>\n",
       "      <td>0.625453</td>\n",
       "      <td>0.631111</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.621665</td>\n",
       "      <td>0.604345</td>\n",
       "      <td>0.609843</td>\n",
       "      <td>0.609843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.086300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.659978</td>\n",
       "      <td>0.642429</td>\n",
       "      <td>0.647723</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.217333</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.656703</td>\n",
       "      <td>0.640283</td>\n",
       "      <td>0.645938</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.644018</td>\n",
       "      <td>0.626145</td>\n",
       "      <td>0.631545</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.621709</td>\n",
       "      <td>0.604422</td>\n",
       "      <td>0.609762</td>\n",
       "      <td>0.609762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.061200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.659982</td>\n",
       "      <td>0.642460</td>\n",
       "      <td>0.647599</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.217667</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.657766</td>\n",
       "      <td>0.640795</td>\n",
       "      <td>0.646327</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>0.626052</td>\n",
       "      <td>0.631347</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.622118</td>\n",
       "      <td>0.604642</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.610027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# save the best model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a708a1b-1c15-4c0f-b1ae-85fe89281f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_384_cosine_ndcg@10: 0.6596838439631117\n",
      "dim_256_cosine_ndcg@10: 0.6576391611101314\n",
      "dim_128_cosine_ndcg@10: 0.6455207361109278\n",
      "dim_64_cosine_ndcg@10: 0.6230519369171184\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    "\n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    "\n",
    "# Print the main score\n",
    "for dim in MATRYOSHKA_DIMENSIONS:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80d1224c-685e-45c4-b111-54da48cd32d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    \"Exemplo de sentença um.\",\n",
    "    \"Exemplo de sentença um.\"\n",
    "]\n",
    "\n",
    "# Obter os embeddings\n",
    "embeddings = fine_tuned_model.encode(sentences)\n",
    "cos_sim(embeddings[0], embeddings[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ed741b-e0ae-4be1-9061-2cbf8e768c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9671)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    \"O gato mordeu o cachorro\",\n",
    "    \"O cachorro mordeu o gato.\"\n",
    "]\n",
    "\n",
    "# Obter os embeddings\n",
    "embeddings = fine_tuned_model.encode(sentences)\n",
    "cos_sim(embeddings[0], embeddings[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c86eb1b-2934-4fc7-8fb3-7569efbbd818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7082)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    \"O gato mordeu o cachorro\",\n",
    "    \"O gato mordeu o cão.\"\n",
    "]\n",
    "\n",
    "# Obter os embeddings\n",
    "embeddings = fine_tuned_model.encode(sentences)\n",
    "cos_sim(embeddings[0], embeddings[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1e18584-1031-467b-941c-37d40db41058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2540)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    \"O gato mordeu o cachorro\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Obter os embeddings\n",
    "embeddings = fine_tuned_model.encode(sentences)\n",
    "cos_sim(embeddings[0], embeddings[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990cc1e-fd81-4902-9c65-f9515b7bed56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
