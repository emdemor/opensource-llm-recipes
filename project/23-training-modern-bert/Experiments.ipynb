{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3170c79f-54ea-47e0-b761-540874d32824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:04:00.005672Z",
     "iopub.status.busy": "2025-02-15T02:04:00.005357Z",
     "iopub.status.idle": "2025-02-15T02:04:00.011189Z",
     "shell.execute_reply": "2025-02-15T02:04:00.010795Z",
     "shell.execute_reply.started": "2025-02-15T02:04:00.005644Z"
    }
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fed1c-702e-40b9-a2cf-745e64663a8b",
   "metadata": {},
   "source": [
    "# Fine Tune ModernBERT\n",
    "\n",
    "## Referências\n",
    "1. Warner, Benjamin, et al. [\"Finally, a Replacement for BERT.\" Hugging Face, 19 Dec. 2024, huggingface.co/blog/modernbert](https://huggingface.co/blog/modernbert).\n",
    "2. Stijn Smits. [\"Fine-tuning ModernBERT on a Dutch Dataset with Custom Tokenizer Training\" GitHub, 14 Fev. 2025, https://github.com/s-smits/modernbert-finetune](https://github.com/s-smits/modernbert-finetune).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae764a-691f-48ab-8551-22c2e0d3f237",
   "metadata": {},
   "source": [
    "## Training a WordPiece tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902fcad-1b3e-410b-a7f5-580d95083560",
   "metadata": {},
   "source": [
    "Para treinar um novo tokenizador, é preciso seguir os seguintes passos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd3680-a24c-42a0-834d-f11f24901125",
   "metadata": {},
   "source": [
    "A. Configure os parâmetros `DATASET_NAME`, `TOKENIZER_SAVE_PATH`, `VOCAB_SIZE` e `NUM_EXAMPLES_TO_TRAIN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d74889c-1888-4176-b5e0-65f35c531beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:10:22.798099Z",
     "iopub.status.busy": "2025-02-15T02:10:22.797796Z",
     "iopub.status.idle": "2025-02-15T02:10:22.801949Z",
     "shell.execute_reply": "2025-02-15T02:10:22.800952Z",
     "shell.execute_reply.started": "2025-02-15T02:10:22.798082Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = None\n",
    "TOKENIZER_SAVE_PATH = \"domain_tokenizer\"\n",
    "VOCAB_SIZE = 32768\n",
    "NUM_EXAMPLES_TO_TRAIN = 3_634_908\n",
    "MODEL_TYPE = \"bpe\"\n",
    "BATCH_SIZE = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbe011-4aa8-4a93-9c11-acaa88d1b8e3",
   "metadata": {},
   "source": [
    "**Importando o dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "605ea899-3e63-4930-b6cd-a10c7e69365d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:10:23.457323Z",
     "iopub.status.busy": "2025-02-15T02:10:23.456751Z",
     "iopub.status.idle": "2025-02-15T02:10:25.873090Z",
     "shell.execute_reply": "2025-02-15T02:10:25.872179Z",
     "shell.execute_reply.started": "2025-02-15T02:10:23.457295Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"emdemor/news-of-the-brazilian-newspaper\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "df = df.sample(len(df)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5df115-9f96-4a64-ac1a-eac484806187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:10:26.798860Z",
     "iopub.status.busy": "2025-02-15T02:10:26.798676Z",
     "iopub.status.idle": "2025-02-15T02:10:33.641761Z",
     "shell.execute_reply": "2025-02-15T02:10:33.641190Z",
     "shell.execute_reply.started": "2025-02-15T02:10:26.798847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3634908"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df.sample(min(NUM_EXAMPLES_TO_TRAIN, len(df)))\n",
    "texts = temp[\"text\"].to_list() + temp[\"title\"].to_list()\n",
    "\n",
    "\n",
    "def dividir_em_frases(texto):\n",
    "    frases = re.split(r\"(?<=[.!?])\\s+\", texto)\n",
    "    return [frase.strip() for frase in frases if frase.strip()]\n",
    "\n",
    "\n",
    "texts = []\n",
    "for string in temp[\"text\"].to_list() + temp[\"title\"].to_list():\n",
    "    if string:\n",
    "        frases = dividir_em_frases(string)\n",
    "        texts.extend(frases)\n",
    "\n",
    "texts = list(set(texts))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4f7ae5-cae7-48e8-bce1-f6e97fd16f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:10:38.053634Z",
     "iopub.status.busy": "2025-02-15T02:10:38.053369Z",
     "iopub.status.idle": "2025-02-15T02:11:02.577233Z",
     "shell.execute_reply": "2025-02-15T02:11:02.576511Z",
     "shell.execute_reply.started": "2025-02-15T02:10:38.053611Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44d55552334409d9cbc4c1d309897bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando tokenizer: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 3634908/3634908 [00:13<00:00, 274308.77exemplos/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to domain_tokenizer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"TRANSFORMERS_CACHE\"):\n",
    "    os.environ[\"HF_HOME\"] = os.environ.pop(\"TRANSFORMERS_CACHE\")\n",
    "\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from tokenizers import Tokenizer, normalizers\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.bert.tokenization_bert import BasicTokenizer, BertTokenizer\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "dataset_iterator = iter(dataset)\n",
    "\n",
    "# Cria o tokenizer com o modelo WordPiece\n",
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.normalizer = normalizers.Sequence([])\n",
    "\n",
    "trainer = WordPieceTrainer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
    "    min_frequency=2,\n",
    ")\n",
    "\n",
    "\n",
    "def batch_iterator(batch_size=BATCH_SIZE):\n",
    "    total_batches = (NUM_EXAMPLES_TO_TRAIN + batch_size - 1) // batch_size\n",
    "    from tqdm import (\n",
    "        tqdm,  # Certifique-se de importar o tqdm se ainda não estiver importado\n",
    "    )\n",
    "\n",
    "    with tqdm(\n",
    "        total=NUM_EXAMPLES_TO_TRAIN, desc=\"Treinando tokenizer\", unit=\"exemplos\"\n",
    "    ) as pbar:\n",
    "        for i in range(0, NUM_EXAMPLES_TO_TRAIN, batch_size):\n",
    "            batch_texts = dataset[i : i + batch_size][\"text\"]\n",
    "            pbar.update(len(batch_texts))\n",
    "            yield batch_texts\n",
    "\n",
    "\n",
    "# Treina o tokenizer\n",
    "tokenizer.train_from_iterator(\n",
    "    batch_iterator(), trainer=trainer, length=NUM_EXAMPLES_TO_TRAIN\n",
    ")\n",
    "\n",
    "# Cria o diretório se não existir e salva o tokenizer\n",
    "os.makedirs(TOKENIZER_SAVE_PATH, exist_ok=True)\n",
    "tokenizer_file = os.path.join(TOKENIZER_SAVE_PATH, \"tokenizer.json\")\n",
    "tokenizer.save(tokenizer_file)\n",
    "print(f\"Tokenizer trained and saved to {TOKENIZER_SAVE_PATH}\")\n",
    "\n",
    "# Cria automaticamente o arquivo config.json se não existir, informando o model_type\n",
    "config_path = os.path.join(TOKENIZER_SAVE_PATH, \"config.json\")\n",
    "if not os.path.exists(config_path):\n",
    "    config = {\"model_type\": \"bert\"}\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7de81-e67e-453c-9cdf-5a9672bf17d4",
   "metadata": {},
   "source": [
    "## Fine-tuning the ModernBERT-base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6fbd96-c708-4975-9372-5cc901198182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:43:38.359458Z",
     "iopub.status.busy": "2025-02-15T02:43:38.359157Z",
     "iopub.status.idle": "2025-02-15T02:43:41.133330Z",
     "shell.execute_reply": "2025-02-15T02:43:41.132722Z",
     "shell.execute_reply.started": "2025-02-15T02:43:38.359431Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "if os.environ.get(\"TRANSFORMERS_CACHE\"):\n",
    "    os.environ[\"HF_HOME\"] = os.environ.pop(\"TRANSFORMERS_CACHE\")\n",
    "\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import Repository, whoami\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c776201-40c6-4f5b-8bd1-b6e6c0a06e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:41:36.794438Z",
     "iopub.status.busy": "2025-02-15T02:41:36.794157Z",
     "iopub.status.idle": "2025-02-15T02:41:36.796640Z",
     "shell.execute_reply": "2025-02-15T02:41:36.796309Z",
     "shell.execute_reply.started": "2025-02-15T02:41:36.794425Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall torchvision -y\n",
    "# !pip install torchvision==0.18.0 -f https://download.pytorch.org/whl/torch_stable.html -qqq\n",
    "# !pip install --upgrade 'optree>=0.13.0' -qqq\n",
    "# !pip install -U torch torch-adopt torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# !pip install -U torch-adopt -qqq\n",
    "\n",
    "# !pip uninstall transformers -y\n",
    "# !pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58c041-c009-4ffc-b3ab-9059fab198a9",
   "metadata": {},
   "source": [
    "# Preparar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af1fee5-a158-4e30-ab9e-111390cfcfe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:43:44.389588Z",
     "iopub.status.busy": "2025-02-15T02:43:44.389106Z",
     "iopub.status.idle": "2025-02-15T02:43:48.401711Z",
     "shell.execute_reply": "2025-02-15T02:43:48.401242Z",
     "shell.execute_reply.started": "2025-02-15T02:43:44.389561Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_TO_TRAIN = 3000\n",
    "\n",
    "dataset = load_dataset(\"emdemor/news-of-the-brazilian-newspaper\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "df = df.sample(len(df)).reset_index(drop=True)\n",
    "\n",
    "temp = df.sample(min(NUM_EXAMPLES_TO_TRAIN, len(df)))\n",
    "texts = temp[\"text\"].to_list() + temp[\"title\"].to_list()\n",
    "\n",
    "\n",
    "def dividir_em_frases(texto):\n",
    "    frases = re.split(r\"(?<=[.!?])\\s+\", texto)\n",
    "    return [frase.strip() for frase in frases if frase.strip()]\n",
    "\n",
    "\n",
    "texts = []\n",
    "for string in temp[\"text\"].to_list() + temp[\"title\"].to_list():\n",
    "    if string:\n",
    "        frases = dividir_em_frases(string)\n",
    "        texts.extend(frases)\n",
    "\n",
    "texts = list(set(texts))[:NUM_EXAMPLES_TO_TRAIN]\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "dataset_iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31e6c5-6b25-446b-92d2-8b6d9e99c804",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd7718f-2451-4656-b940-2fd1dab13a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:44:47.774294Z",
     "iopub.status.busy": "2025-02-15T02:44:47.773931Z",
     "iopub.status.idle": "2025-02-15T02:44:47.809632Z",
     "shell.execute_reply": "2025-02-15T02:44:47.809146Z",
     "shell.execute_reply.started": "2025-02-15T02:44:47.774259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "model_checkpoint = \"answerdotai/ModernBERT-base\"\n",
    "username = \"emdemor\"\n",
    "tokenizer_path = \"domain_tokenizer\"  # Path to custom tokenizer directory\n",
    "\n",
    "# --- Dataset size (in rows) ---\n",
    "estimated_dataset_size_in_rows = 3000\n",
    "\n",
    "# --- Training Config ---\n",
    "num_train_epochs = 1\n",
    "# Reduce or remove chunk size to allow for dynamic batching\n",
    "chunk_size = None  # Remove chunk size\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 2\n",
    "eval_size_ratio = 0.05\n",
    "total_save_limit = 2\n",
    "\n",
    "effective_batch_size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "total_steps_per_epoch = math.ceil(estimated_dataset_size_in_rows / effective_batch_size)\n",
    "total_train_steps = total_steps_per_epoch * num_train_epochs\n",
    "eval_size_per_chunk = int(estimated_dataset_size_in_rows * eval_size_ratio)\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Testing Mode ---\n",
    "TESTING = True  # Set to True for testing, False for full training\n",
    "FLASH_ATTENTION = True\n",
    "\n",
    "if TESTING:\n",
    "    push_interval = 10_000\n",
    "else:\n",
    "    push_interval = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c6c718-857e-4079-9b6d-8a23e7cd6e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:51:43.664471Z",
     "iopub.status.busy": "2025-02-15T02:51:43.664270Z",
     "iopub.status.idle": "2025-02-15T02:51:43.685648Z",
     "shell.execute_reply": "2025-02-15T02:51:43.684925Z",
     "shell.execute_reply.started": "2025-02-15T02:51:43.664458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is already installed.\n",
      "❌ Flash Attention não é compatível: FlashAttention only supports Ampere GPUs or newer.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from flash_attn import flash_attn_qkvpacked_func\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if FLASH_ATTENTION:\n",
    "    try:\n",
    "        import flash_attn\n",
    "\n",
    "        print(\"FlashAttention is already installed.\")\n",
    "    except ImportError:\n",
    "        print(\"FlashAttention is not installed. Installing...\")\n",
    "        try:\n",
    "            import subprocess\n",
    "\n",
    "            subprocess.run(\n",
    "                [\"pip\", \"install\", \"flash-attn\", \"--no-build-isolation\"], check=True\n",
    "            )\n",
    "            import flash_attn\n",
    "\n",
    "            print(\"FlashAttention installed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error installing FlashAttention: {e}\")\n",
    "            exit()\n",
    "\n",
    "\n",
    "def check_flash_attention_support():\n",
    "    \"\"\"Verifica se a GPU suporta Flash Attention 2.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ GPU não disponível.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        qkv = torch.randn(1, 1, 3, 16, 64, dtype=torch.float16, device=\"cuda\")\n",
    "        flash_attn_qkvpacked_func(qkv, causal=False)\n",
    "        print(\"✅ Sua GPU suporta Flash Attention!\")\n",
    "        return True\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ Flash Attention não é compatível:\", str(e))\n",
    "        return False\n",
    "\n",
    "flash_attn_available = check_flash_attention_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337969b-6b3c-485b-9902-775ee2ec79c5",
   "metadata": {},
   "source": [
    "### Importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a810225-a4aa-494f-b2f2-b705cebe4709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:47:40.689367Z",
     "iopub.status.busy": "2025-02-15T02:47:40.689024Z",
     "iopub.status.idle": "2025-02-15T02:47:41.376921Z",
     "shell.execute_reply": "2025-02-15T02:47:41.376431Z",
     "shell.execute_reply.started": "2025-02-15T02:47:40.689348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom tokenizer from domain_tokenizer...\n",
      "Loading model config from answerdotai/ModernBERT-base...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModernBertForMaskedLM(\n",
       "  (model): ModernBertModel(\n",
       "    (embeddings): ModernBertEmbeddings(\n",
       "      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModernBertEncoderLayer(\n",
       "        (attn_norm): Identity()\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4-5): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (7-8): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (15): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (16-17): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (18): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (19-20): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (21): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): ModernBertPredictionHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (act): GELUActivation()\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Linear(in_features=768, out_features=50368, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loading custom tokenizer from {tokenizer_path}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "print(f\"Loading model config from {model_checkpoint}...\")\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "config.torch_dtype = torch.float16\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint, config=config)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a802cbc-0ee1-4cf0-93b8-ef2028b09706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:02.839907Z",
     "iopub.status.busy": "2025-02-15T02:52:02.839708Z",
     "iopub.status.idle": "2025-02-15T02:52:02.842970Z",
     "shell.execute_reply": "2025-02-15T02:52:02.842334Z",
     "shell.execute_reply.started": "2025-02-15T02:52:02.839892Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Integrate Flash-attn (if available) ---\n",
    "if flash_attn_available:\n",
    "    print(\"Replacing standard attention with FlashAttention...\")\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            module.attention = FlashAttention()\n",
    "    print(\"FlashAttention integrated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123af378-6178-40d4-93f6-2a02be9507d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:12.421462Z",
     "iopub.status.busy": "2025-02-15T02:52:12.421202Z",
     "iopub.status.idle": "2025-02-15T02:52:12.424467Z",
     "shell.execute_reply": "2025-02-15T02:52:12.423812Z",
     "shell.execute_reply.started": "2025-02-15T02:52:12.421439Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tokenization Function ---\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        # No truncation and max_length to allow dynamic padding truncation=True, max_length=chunk_size, padding=\"longest\",\n",
    "        return_special_tokens_mask=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb89ae4-6e3d-4413-a134-4611e7daffd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:16.783700Z",
     "iopub.status.busy": "2025-02-15T02:52:16.783406Z",
     "iopub.status.idle": "2025-02-15T02:52:16.911033Z",
     "shell.execute_reply": "2025-02-15T02:52:16.910607Z",
     "shell.execute_reply.started": "2025-02-15T02:52:16.783679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b6dc1a319d4eb3a2a141b0ba46b953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tokenized.\n"
     ]
    }
   ],
   "source": [
    "# --- Tokenize Dataset ---\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "print(\"Dataset tokenized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d384c19-d02a-43aa-8b45-751c9a7e5efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:24.791884Z",
     "iopub.status.busy": "2025-02-15T02:52:24.791630Z",
     "iopub.status.idle": "2025-02-15T02:52:24.794526Z",
     "shell.execute_reply": "2025-02-15T02:52:24.794092Z",
     "shell.execute_reply.started": "2025-02-15T02:52:24.791867Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "output_dir = f\"{model_name}-ptbr-{'test' if TESTING else 'full'}\"\n",
    "repo_name = f\"{username}/{output_dir}\"\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9becb470-2dec-4637-ad30-dd7197bb4868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:26.368980Z",
     "iopub.status.busy": "2025-02-15T02:52:26.368685Z",
     "iopub.status.idle": "2025-02-15T02:52:26.371678Z",
     "shell.execute_reply": "2025-02-15T02:52:26.371187Z",
     "shell.execute_reply.started": "2025-02-15T02:52:26.368962Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355d018f-ab98-4afd-a1e9-3a9200dac0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:52:34.625619Z",
     "iopub.status.busy": "2025-02-15T02:52:34.625013Z",
     "iopub.status.idle": "2025-02-15T02:52:34.629883Z",
     "shell.execute_reply": "2025-02-15T02:52:34.629396Z",
     "shell.execute_reply.started": "2025-02-15T02:52:34.625586Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# --- Optimizer and Scheduler ---\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_train_steps\n",
    ")\n",
    "\n",
    "# --- AMP scaler for mixed precision ---\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7431ef5c-edf8-401c-9d25-5433687b62b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:53:04.214711Z",
     "iopub.status.busy": "2025-02-15T02:53:04.214456Z",
     "iopub.status.idle": "2025-02-15T02:53:04.220435Z",
     "shell.execute_reply": "2025-02-15T02:53:04.219841Z",
     "shell.execute_reply.started": "2025-02-15T02:53:04.214693Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Helper Function to Fix Batch Inputs ---\n",
    "def fix_batch_inputs(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Ensures that input tensors have the correct shape and dtype.\n",
    "    - Removes any extra dimensions (e.g., [1, batch, seq_len] -> [batch, seq_len]).\n",
    "    - Casts input_ids to torch.long.\n",
    "    \"\"\"\n",
    "    for key in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]:\n",
    "        if key in inputs:\n",
    "            if inputs[key].dim() == 3 and inputs[key].shape[0] == 1:\n",
    "                inputs[key] = inputs[key].squeeze(0)\n",
    "            elif inputs[key].dim() > 2:\n",
    "                raise ValueError(\n",
    "                    f\"Unexpected tensor shape for {key}: {inputs[key].shape}\"\n",
    "                )\n",
    "    if \"input_ids\" in inputs and inputs[\"input_ids\"].dtype != torch.long:\n",
    "        inputs[\"input_ids\"] = inputs[\"input_ids\"].long()\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# --- Forward Pass Function ---\n",
    "def forward_pass(model, inputs):\n",
    "    \"\"\"\n",
    "    Performs a forward pass with autocast for FP16.\n",
    "    Returns the loss.\n",
    "    \"\"\"\n",
    "    inputs = fix_batch_inputs(inputs)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
    "        outputs = model(**inputs, return_dict=True)\n",
    "    if outputs.loss is None:\n",
    "        raise ValueError(\"Model did not return a loss.\")\n",
    "    return outputs.loss\n",
    "\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate(model, eval_dataset, data_collator):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the evaluation dataset.\n",
    "    Returns the average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    eval_iterator = eval_dataset.iter(batch_size=per_device_train_batch_size)\n",
    "    for batch in tqdm(eval_iterator, desc=\"Evaluating\"):\n",
    "        with torch.no_grad(), torch.amp.autocast(\n",
    "            \"cuda\", enabled=(device.type == \"cuda\")\n",
    "        ):\n",
    "            inputs = data_collator(batch)\n",
    "            try:\n",
    "                loss = forward_pass(model, inputs)\n",
    "                losses.append(loss.item())\n",
    "            except Exception as e:\n",
    "                print(f\"Evaluation batch failed: {e}. Skipping.\")\n",
    "                continue\n",
    "    model.train()\n",
    "    average_loss = sum(losses) / len(losses) if losses else float(\"inf\")\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03f21b0-147d-4a8d-98a1-e7b87c20fc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:53:20.219242Z",
     "iopub.status.busy": "2025-02-15T02:53:20.218901Z",
     "iopub.status.idle": "2025-02-15T02:53:20.224995Z",
     "shell.execute_reply": "2025-02-15T02:53:20.224465Z",
     "shell.execute_reply.started": "2025-02-15T02:53:20.219213Z"
    }
   },
   "outputs": [],
   "source": [
    "class DynamicPaddingDataCollator(DataCollatorForLanguageModeling):\n",
    "    \"\"\"\n",
    "    Data collator that dynamically pads the inputs for language modeling.\n",
    "    This ensures that all sequences within a batch have the same length,\n",
    "    but the overall length can vary between batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, examples: Dict[str, Any]) -> Dict[str, torch.Tensor]:\n",
    "        # Find the maximum length within the current batch\n",
    "        max_length = max(len(input_ids) for input_ids in examples[\"input_ids\"])\n",
    "\n",
    "        # Pad or truncate each example to the max_length\n",
    "        batch = []\n",
    "        input_ids = examples[\"input_ids\"]\n",
    "        attention_mask = examples[\"attention_mask\"]\n",
    "\n",
    "        for ids, mask in zip(input_ids, attention_mask):\n",
    "            padding_length = max_length - len(ids)\n",
    "            if padding_length > 0:\n",
    "                # Pad\n",
    "                ids = torch.tensor(ids + [self.tokenizer.pad_token_id] * padding_length)\n",
    "                mask = torch.tensor(mask + [0] * padding_length)\n",
    "            elif padding_length <= 0:\n",
    "                # Truncate (if enabled in your tokenizer)\n",
    "                ids = torch.tensor(ids[:max_length])\n",
    "                mask = torch.tensor(mask[:max_length])\n",
    "\n",
    "            batch.append({\"input_ids\": ids, \"attention_mask\": mask})\n",
    "\n",
    "        # Apply the rest of the data collation logic (MLM masking, etc.)\n",
    "        batch = self.torch_call(\n",
    "            batch\n",
    "        )  # Use torch_call instead of __call__ to call the parent's method\n",
    "\n",
    "        # Ensure correct shapes and dtypes\n",
    "        batch = fix_batch_inputs(batch)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc45909-0643-450f-b63b-b98c2854556e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:53:22.231680Z",
     "iopub.status.busy": "2025-02-15T02:53:22.231308Z",
     "iopub.status.idle": "2025-02-15T02:53:22.235988Z",
     "shell.execute_reply": "2025-02-15T02:53:22.235177Z",
     "shell.execute_reply.started": "2025-02-15T02:53:22.231652Z"
    }
   },
   "outputs": [],
   "source": [
    "mlm_probabilities = [0.3, 0.2, 0.18, 0.16, 0.14]\n",
    "\n",
    "chunk_size_dataset = len(dataset) // len(mlm_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c51411e-67f9-4cde-90d5-4b5d7bbee7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T02:53:25.561036Z",
     "iopub.status.busy": "2025-02-15T02:53:25.560373Z",
     "iopub.status.idle": "2025-02-15T02:53:25.564233Z",
     "shell.execute_reply": "2025-02-15T02:53:25.563800Z",
     "shell.execute_reply.started": "2025-02-15T02:53:25.561005Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5303c51-bf87-4f3d-9b33-ecbffc22104b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T13:13:51.490454Z",
     "iopub.status.busy": "2025-02-14T13:13:51.490129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1, MLM Probability: 0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7419209deefa4166a0b55a8d30ec44b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (MLM 0.3): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "\n",
      "Epoch 1/1, MLM Probability: 0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8edad66a677439ea1095ed8bf99ca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (MLM 0.2): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "\n",
      "Epoch 1/1, MLM Probability: 0.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19336aba8e9240be871529518ef5c27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (MLM 0.18): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "Training batch failed: FlashAttention only supports Ampere GPUs or newer.. Skipping.\n",
      "\n",
      "Epoch 1/1, MLM Probability: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd18ed219482411cadd7014e9af79bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (MLM 0.16): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving and pushing model at step 190000...\n",
      "Model saved and pushed at step 190000.\n",
      "Saving and pushing model at step 200000...\n",
      "Model saved and pushed at step 200000.\n",
      "Saving and pushing model at step 210000...\n",
      "Model saved and pushed at step 210000.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f1240907b64bf7ae324fc4d1cb31ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss at step 218750: 3.2397417649450686\n",
      "Saving and pushing model at step 220000...\n",
      "Model saved and pushed at step 220000.\n",
      "Saving and pushing model at step 230000...\n",
      "Model saved and pushed at step 230000.\n",
      "Saving and pushing model at step 240000...\n",
      "Model saved and pushed at step 240000.\n",
      "Saving and pushing model at step 250000...\n",
      "Model saved and pushed at step 250000.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_train_epochs):\n",
    "    for i, mlm_probability in enumerate(mlm_probabilities):\n",
    "        print(\n",
    "            f\"\\nEpoch {epoch + 1}/{num_train_epochs}, MLM Probability: {mlm_probability}\"\n",
    "        )\n",
    "\n",
    "        data_collator = DynamicPaddingDataCollator(\n",
    "            tokenizer=tokenizer, mlm_probability=mlm_probability\n",
    "        )\n",
    "\n",
    "        train_dataset = (\n",
    "            tokenized_dataset.skip(i * chunk_size_dataset + eval_size_per_chunk)\n",
    "            .take(chunk_size_dataset)\n",
    "            .shuffle(seed=42)\n",
    "        )\n",
    "        eval_dataset = tokenized_dataset.skip(i * chunk_size_dataset).take(\n",
    "            eval_size_per_chunk\n",
    "        )\n",
    "\n",
    "        train_iterator = train_dataset.iter(batch_size=per_device_train_batch_size)\n",
    "        for step, batch in enumerate(\n",
    "            tqdm(train_iterator, desc=f\"Training (MLM {mlm_probability})\")\n",
    "        ):\n",
    "            try:\n",
    "                inputs = data_collator(batch)\n",
    "                loss = forward_pass(model, inputs)\n",
    "            except Exception as e:\n",
    "                print(f\"Training batch failed: {e}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            scaler.scale(loss / gradient_accumulation_steps).backward()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()  # Clear cache\n",
    "                global_step += 1\n",
    "\n",
    "                # Evaluation\n",
    "                eval_interval = total_steps_per_epoch // (num_train_epochs * 4)\n",
    "                if eval_interval > 0 and (global_step % eval_interval == 0):\n",
    "                    eval_loss = evaluate(model, eval_dataset, data_collator)\n",
    "                    print(f\"Evaluation loss at step {global_step}: {eval_loss}\")\n",
    "\n",
    "                # Push to hub incl TESTING\n",
    "                if global_step % push_interval == 0:\n",
    "                    print(f\"Saving and pushing model at step {global_step}...\")\n",
    "                    model.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "                    print(f\"Model saved and pushed at step {global_step}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81d8e4a-a441-40f6-8da8-12b1a0e95f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T12:45:11.475051Z",
     "iopub.status.busy": "2025-02-15T12:45:11.474739Z",
     "iopub.status.idle": "2025-02-15T12:45:11.477791Z",
     "shell.execute_reply": "2025-02-15T12:45:11.477363Z",
     "shell.execute_reply.started": "2025-02-15T12:45:11.475032Z"
    }
   },
   "outputs": [],
   "source": [
    "num_chunks = len(mlm_probabilities)\n",
    "available_size = len(tokenized_dataset) - eval_size_per_chunk * num_chunks\n",
    "if available_size < num_chunks:\n",
    "    num_chunks = max(1, available_size)\n",
    "    mlm_probabilities = mlm_probabilities[:num_chunks]\n",
    "\n",
    "chunk_size_dataset = available_size // num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a70f625-906d-49f8-8a56-e52f93cdaa94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T12:45:49.824018Z",
     "iopub.status.busy": "2025-02-15T12:45:49.823534Z",
     "iopub.status.idle": "2025-02-15T12:45:52.190444Z",
     "shell.execute_reply": "2025-02-15T12:45:52.189955Z",
     "shell.execute_reply.started": "2025-02-15T12:45:49.824000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving and pushing final model...\n",
      "Final model saved and pushed.\n"
     ]
    }
   ],
   "source": [
    "# Final Save and Push\n",
    "print(\"\\nSaving and pushing final model...\")\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(\"Final model saved and pushed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2180404-7da9-4ca3-9b06-0e0da87b9eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c7f07-d4f7-4b73-9a43-75cb11dca8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb004ae9-f26f-4c6b-831b-178bbce6a14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbf6eb-bab9-4303-a355-b089dfab846e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
