{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4830bddc-4c6b-4fe8-8638-c5d83e0b97b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:55:19.183538Z",
     "iopub.status.busy": "2024-10-06T15:55:19.183243Z",
     "iopub.status.idle": "2024-10-06T15:55:19.185807Z",
     "shell.execute_reply": "2024-10-06T15:55:19.185321Z",
     "shell.execute_reply.started": "2024-10-06T15:55:19.183512Z"
    }
   },
   "outputs": [],
   "source": [
    "# # !pip install pytube pydub\n",
    "# !pip install -U youtube_dl\n",
    "# !pip install -U yt-dlp==2024.8.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7394d4-3a9c-4a11-810c-673dad864652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:10.966014Z",
     "iopub.status.busy": "2024-10-06T15:56:10.965643Z",
     "iopub.status.idle": "2024-10-06T15:56:12.835201Z",
     "shell.execute_reply": "2024-10-06T15:56:12.834403Z",
     "shell.execute_reply.started": "2024-10-06T15:56:10.965992Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pathlib\n",
    "import shutil\n",
    "import whisper\n",
    "import torch\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Markdown\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0708448-882f-443b-972d-cb780c9e5a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:12.838158Z",
     "iopub.status.busy": "2024-10-06T15:56:12.838028Z",
     "iopub.status.idle": "2024-10-06T15:56:12.840653Z",
     "shell.execute_reply": "2024-10-06T15:56:12.840309Z",
     "shell.execute_reply.started": "2024-10-06T15:56:12.838144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large', 'large-v3-turbo', 'turbo']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8171ed34-5888-48aa-893a-0097c9d3bdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:12.841612Z",
     "iopub.status.busy": "2024-10-06T15:56:12.841429Z",
     "iopub.status.idle": "2024-10-06T15:56:22.055075Z",
     "shell.execute_reply": "2024-10-06T15:56:22.054460Z",
     "shell.execute_reply.started": "2024-10-06T15:56:12.841599Z"
    }
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model('large-v3-turbo').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a15dd7-caa0-46d2-b74d-092dd3b1ad44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.055794Z",
     "iopub.status.busy": "2024-10-06T15:56:22.055649Z",
     "iopub.status.idle": "2024-10-06T15:56:22.058583Z",
     "shell.execute_reply": "2024-10-06T15:56:22.058135Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.055776Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\" Your output should use the following template:\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Analogy\n",
    "\n",
    "### Notes\n",
    "\n",
    "- [Emoji] Bulletpoint\n",
    "\n",
    "### Keywords\n",
    "\n",
    "- Explanation\n",
    "\n",
    "You have been tasked with creating a concise summary of a YouTube video using its transcription.\n",
    "\n",
    "Make a summary of the transcript.\n",
    "\n",
    "Additionally make a short complex analogy to give context and/or analogy from day-to-day life from the transcript.\n",
    "\n",
    "Create 10 bullet points (each with an appropriate emoji) that summarize the key points or important moments from the video's transcription.\n",
    "\n",
    "In addition to the bullet points, extract the most important keywords and any complex words not known to the average reader aswell as any acronyms mentioned. For each keyword and complex word, provide an explanation and definition based on its occurrence in the transcription.\n",
    "\n",
    "Please ensure that the summary, bullet points, and explanations fit within the 330-word limit, while still offering a comprehensive and clear understanding of the video's content. Use the text above:\n",
    "\n",
    "Please, I need you to translate the answer into Portuguese!\n",
    "\n",
    "```\n",
    "{title}\n",
    "\n",
    "{transcription}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f43874-9312-422e-b4e7-9d86b261f9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.060147Z",
     "iopub.status.busy": "2024-10-06T15:56:22.059938Z",
     "iopub.status.idle": "2024-10-06T15:56:22.145121Z",
     "shell.execute_reply": "2024-10-06T15:56:22.144556Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.060128Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_audio(path, start_time, end_time, output_path):\n",
    "    audio = AudioSegment.from_file(path)\n",
    "    start_time_ms = start_time * 1000\n",
    "    end_time_ms = end_time * 1000\n",
    "    trimmed_audio = audio[start_time_ms:end_time_ms]\n",
    "    trimmed_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "class YoutubeTranscripter:\n",
    "    def __init__(self, video_url, whisper_model):\n",
    "        self.video_url = video_url\n",
    "        self.whisper_model = whisper_model\n",
    "        self.metadata = None\n",
    "        self.title = None\n",
    "        self.label = None\n",
    "        self.language = None\n",
    "        self.chapters = None\n",
    "        self._temp_dir = tempfile.mkdtemp()\n",
    "        self._raw_video_path = None\n",
    "        self._video_parts_folderpath = None\n",
    "        self._audios_to_transcribe = []\n",
    "        self._transcripted_parts = None\n",
    "\n",
    "    def get_metadata(self):\n",
    "        ydl_opts = {\n",
    "            'skip_download': True,\n",
    "            'extract_flat': True,\n",
    "        }\n",
    "        \n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            self.metadata = ydl.extract_info(self.video_url, download=False)\n",
    "\n",
    "        self.title = self.metadata[\"title\"]\n",
    "        self.label = self.metadata[\"title\"].lower().replace(\" \",\"_\")\n",
    "        self.language = self.metadata[\"language\"]\n",
    "        self.chapters = self.metadata[\"chapters\"]\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        output_filename = f\"{self._temp_dir}/{self.label}\"\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'outtmpl': f'{output_filename}.%(ext)s',\n",
    "        }\n",
    "\n",
    "        self._raw_video_path = f'{output_filename}.mp3'\n",
    "        \n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([self.video_url])\n",
    "\n",
    "    def prepare(self):\n",
    "        if self.chapters:\n",
    "            self._video_parts_folderpath = self._raw_video_path.replace(\".mp3\", \"\")\n",
    "            pathlib.Path(self._video_parts_folderpath).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "            for i, c in enumerate(self.chapters):\n",
    "                print(f\"[splitting] - Part {i+1} - {c['title']}\")\n",
    "                output_path = f\"{self._video_parts_folderpath}/{str(i+1).zfill(4)}__{c['title']}__.mp3\"\n",
    "                cut_audio(self._raw_video_path, c[\"start_time\"], c[\"end_time\"], output_path)\n",
    "                c.update({\"audio_path\": output_path})\n",
    "                self._audios_to_transcribe.append(c)\n",
    "        else:\n",
    "            self._audios_to_transcribe.append(\n",
    "                {\n",
    "                    \"title\": self.title,\n",
    "                    \"audio_path\": self._raw_video_path,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def transcript(self):\n",
    "        response = []\n",
    "        for i, a in enumerate(self._audios_to_transcribe):\n",
    "            print(f\"[transcripting] - Part {i+1} - {a['audio_path']}\")\n",
    "            result = self.whisper_model.transcribe(a[\"audio_path\"], language=self.language)\n",
    "            a.update({\"transcription\": result})\n",
    "            response.append(a)\n",
    "        if not self._transcripted_parts:\n",
    "            self._transcripted_parts = response\n",
    "        return response\n",
    "            \n",
    "    def cleanup(self):\n",
    "        if self._temp_dir:\n",
    "            shutil.rmtree(self._temp_dir)\n",
    "            self._temp_dir = None\n",
    "            self._raw_video_path = None\n",
    "            self._video_parts_folderpath = None\n",
    "            self._audios_to_transcribe = []\n",
    "            print(\"Diret√≥rio tempor√°rio removido.\")\n",
    "\n",
    "    def summarize(self):\n",
    "        if not self._transcripted_parts:\n",
    "            self._transcripted_parts = self.transcript()\n",
    "\n",
    "        formatted_text = []\n",
    "        for i,r in enumerate(self._transcripted_parts):\n",
    "            chapter_text = dedent(f\"\"\"\n",
    "            ## {i+1}. {r['title']}\n",
    "            {r['transcription']['text']}\n",
    "            \"\"\")\n",
    "        \n",
    "            formatted_text.append(chapter_text)\n",
    "        \n",
    "        formatted_text = \"\\n\\n\".join(formatted_text)\n",
    "        \n",
    "        chain = self.set_chain()\n",
    "\n",
    "        response = chain.invoke({\"title\": self.title, \"transcription\": formatted_text})\n",
    "\n",
    "        return response\n",
    "\n",
    "    def set_chain(self):\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"title\", \"transcription\"], template=prompt_template\n",
    "        )\n",
    "        \n",
    "        \n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "        )\n",
    "        \n",
    "        return prompt | llm\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        self.get_metadata()\n",
    "        self.download()\n",
    "        self.prepare()\n",
    "        response = self.transcript()\n",
    "        self.cleanup()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3218ea-0cdc-4185-860a-2ce140352d64",
   "metadata": {},
   "source": [
    "# Transcrever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ef4d69-69f7-498a-b554-84147011a71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:58:42.111259Z",
     "iopub.status.busy": "2024-10-06T15:58:42.110954Z",
     "iopub.status.idle": "2024-10-06T16:00:26.599326Z",
     "shell.execute_reply": "2024-10-06T16:00:26.597800Z",
     "shell.execute_reply.started": "2024-10-06T15:58:42.111242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xGUHzRo81OM\n",
      "[youtube] xGUHzRo81OM: Downloading webpage\n",
      "[youtube] xGUHzRo81OM: Downloading ios player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading web creator player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xGUHzRo81OM\n",
      "[youtube] xGUHzRo81OM: Downloading webpage\n",
      "[youtube] xGUHzRo81OM: Downloading ios player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading web creator player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading m3u8 information\n",
      "[info] xGUHzRo81OM: Downloading 1 format(s): 251\n",
      "[download] Destination: /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.webm\n",
      "[download] 100% of   18.69MiB in 00:00:13 at 1.38MiB/s   \n",
      "[ExtractAudio] Destination: /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.mp3\n",
      "Deleting original file /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.webm (pass -k to keep)\n",
      "[transcripting] - Part 1 - /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.mp3\n",
      "Diret√≥rio tempor√°rio removido.\n",
      "CPU times: user 1min 3s, sys: 539 ms, total: 1min 3s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "O v√≠deo \"Top 10 Atores que CALARAM a sua BOCA\" de Gaveta discute escolhas pol√™micas de atores em pap√©is ic√¥nicos que inicialmente geraram desconfian√ßa, mas que acabaram se mostrando excelentes. O apresentador compartilha sua experi√™ncia pessoal e opini√µes sobre cada escolha, destacando como alguns atores, como Michael Keaton, Jennifer Lawrence e Heath Ledger, surpreenderam o p√∫blico com suas atua√ß√µes.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Escolher um ator para um papel √© como escolher um ingrediente para uma receita: √†s vezes, o que parece uma combina√ß√£o estranha pode resultar em um prato delicioso. Assim como um chef pode surpreender com uma mistura inesperada, um diretor pode encontrar um talento oculto em um ator que, √† primeira vista, n√£o parece se encaixar.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- üé≠ Michael Keaton como Batman: Inicialmente criticado, mas se tornou um √≠cone.\n",
       "- üåü Jennifer Lawrence como Katniss: Pol√™mica pela apar√™ncia, mas provou seu talento.\n",
       "- ü¶∏‚Äç‚ôÇÔ∏è Chris Evans como Capit√£o Am√©rica: Duvidado por seu passado c√¥mico, mas se destacou.\n",
       "- üé§ Lady Gaga em Nasce Uma Estrela: Surpreendeu com atua√ß√£o dram√°tica.\n",
       "- üßõ‚Äç‚ôÇÔ∏è Tom Cruise como Lestat: Superou expectativas em Entrevista com o Vampiro.\n",
       "- üê∫ Hugh Jackman como Wolverine: Inicialmente criticado, mas se tornou o Wolverine definitivo.\n",
       "- üî´ Daniel Craig como James Bond: Mudou a percep√ß√£o do personagem para um tom mais realista.\n",
       "- üé¨ Ryan Reynolds como Deadpool: Superou a m√° impress√£o de sua primeira interpreta√ß√£o.\n",
       "- üé• Robert Pattinson como Batman: Provou ser um ator vers√°til ap√≥s Crep√∫sculo.\n",
       "- üÉè Heath Ledger como Coringa: Transformou a vis√£o do personagem e ganhou um Oscar.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Pol√™mica**: Situa√ß√£o que gera controv√©rsia ou debate.\n",
       "- **Atua√ß√£o**: A arte de interpretar um personagem em teatro, cinema ou televis√£o.\n",
       "- **Coringa**: Personagem ic√¥nico da DC Comics, conhecido por sua complexidade e vilania.\n",
       "- **Reboot**: Reinterpreta√ß√£o ou rein√≠cio de uma franquia, geralmente com novos atores ou diretores.\n",
       "- **Expectativa**: A cren√ßa ou esperan√ßa de que algo ocorrer√° de uma certa maneira."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transcripter = YoutubeTranscripter(video_url=\"https://www.youtube.com/watch?v=xGUHzRo81OM\", whisper_model=model)\n",
    "response = transcripter.run()\n",
    "summary = transcripter.summarize()\n",
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75eaac-57de-453c-88e3-5014a2733f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860ec0b-36f5-48b8-8144-28dc63be7352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd5da68-40d4-46ca-8846-bc04f7684215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.145842Z",
     "iopub.status.busy": "2024-10-06T15:56:22.145690Z",
     "iopub.status.idle": "2024-10-06T15:56:56.567079Z",
     "shell.execute_reply": "2024-10-06T15:56:56.566177Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.145825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[info] MnBV8zLq-_Y: Downloading 1 format(s): 251\n",
      "[download] Destination: /tmp/tmpe_gg1glr/ansible_vault.webm\n",
      "[download] 100% of    5.05MiB in 00:00:04 at 1.23MiB/s   \n",
      "[ExtractAudio] Destination: /tmp/tmpe_gg1glr/ansible_vault.mp3\n",
      "Deleting original file /tmp/tmpe_gg1glr/ansible_vault.webm (pass -k to keep)\n",
      "[transcripting] - Part 1 - /tmp/tmpe_gg1glr/ansible_vault.mp3\n",
      "Diret√≥rio tempor√°rio removido.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "Ansible Vault √© uma ferramenta de linha de comando que permite criptografar vari√°veis e arquivos sens√≠veis, garantindo que dados como credenciais de m√°quina n√£o fiquem expostos em texto simples. O especialista Alex Dordjian explica como usar o Ansible Vault para proteger dados em repouso, criar e editar arquivos criptografados, e gerenciar diferentes cofres e senhas. Ele tamb√©m destaca a import√¢ncia de revisar playbooks para evitar a exposi√ß√£o acidental de dados sens√≠veis e fornece uma demonstra√ß√£o pr√°tica de como implementar o Ansible Vault.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Usar o Ansible Vault √© como ter um cofre em casa: voc√™ pode guardar documentos importantes (dados sens√≠veis) dentro dele, mas ainda precisa ter cuidado ao abrir o cofre (executar playbooks) para n√£o deixar informa√ß√µes √† vista.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- üîí Ansible Vault √© uma ferramenta de criptografia.\n",
       "- üóùÔ∏è Permite proteger credenciais e arquivos sens√≠veis.\n",
       "- üìÇ Suporta a cria√ß√£o e edi√ß√£o de arquivos criptografados.\n",
       "- üîç √â importante revisar playbooks para evitar vazamentos de dados.\n",
       "- üîë V√°rios cofres e senhas podem ser gerenciados.\n",
       "- üõ†Ô∏è Funciona com Ansible Playbook e Ansible Navigator.\n",
       "- üìú Oferece op√ß√µes para visualizar e editar arquivos criptografados.\n",
       "- üîÑ Possui funcionalidade para reconfigurar senhas de criptografia.\n",
       "- üìö Documenta√ß√£o dispon√≠vel para guias e FAQs.\n",
       "- üíª Demonstra√ß√£o pr√°tica de uso do Ansible Vault.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Ansible Vault**: Ferramenta de linha de comando para criptografar dados sens√≠veis.\n",
       "- **Criptografia**: Processo de codificar informa√ß√µes para proteger dados.\n",
       "- **Playbook**: Conjunto de instru√ß√µes que o Ansible executa.\n",
       "- **Cofre**: Local seguro para armazenar informa√ß√µes sens√≠veis.\n",
       "- **Vari√°veis**: Elementos que armazenam dados que podem ser utilizados em scripts.\n",
       "- **Rekey**: Processo de alterar a senha de criptografia de um cofre.\n",
       "\n",
       "Essas defini√ß√µes ajudam a entender melhor os conceitos discutidos no v√≠deo e a import√¢ncia do Ansible Vault na seguran√ßa de dados."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripter = YoutubeTranscripter(video_url=\"https://www.youtube.com/watch?v=MnBV8zLq-_Y\", whisper_model=model)\n",
    "response = transcripter.run()\n",
    "summary = transcripter.summarize()\n",
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce63361-a8b4-452c-902b-0333a7f97a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523633cf-42f2-4e17-88d5-fb3c9ac73b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71f90b-ce33-4ad6-a8dc-e53be6b5adb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927176e6-fcc6-4d37-9a75-e5b62bff6b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d8f557-9985-4676-8c98-1712492df9ce",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5aebde-2bf9-4f69-b669-18957624abe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:37:01.367364Z",
     "iopub.status.busy": "2024-10-06T15:37:01.367200Z",
     "iopub.status.idle": "2024-10-06T15:37:01.373474Z",
     "shell.execute_reply": "2024-10-06T15:37:01.373020Z",
     "shell.execute_reply.started": "2024-10-06T15:37:01.367349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## 1. Intro\n",
       " Hey Rilsen! Yeah? What is KnowledgeCraft? Do we need it to enhance our LLM performance? Oh, and also, do you know how to integrate it with Lanchain? Okay guys, hold on, take it easy. I will explain to you in detail step by step. Start from the theory, how to set up our Neo4j database, and then how to integrate it using Lanchain, and of course, all that we will use in open source LLM. So, without further ado, let's get started.\n",
       "\n",
       "\n",
       "\n",
       "## 2. What is Knowledge Graph?\n",
       " What is Nullesquas? Once upon a time, way back in 1736, there was a Swiss madwish named Leonard Ehler who faced a mind-bending challenge. The Southern Bridge of Gunsberg Problem. Is there a way to walk across all bridges once, starting and ending at the same place? Ehler realized something more crucial. What mattered was how things were connected. So it turned the city's landmark into dots or nodes and its bridges into lies or ages, creating a neat little network known as the origin of the graph theory. How we tying this overgraph, sped cold-up, instead of just building about landmarks and bridges, now, that's staying picky. So, in ancient, nodes ask the adjectives such as people, buildings, schools, bands, and many more, and that the ages as the relationship between them. For example, there is Amy working at a band and chatting away in Mandarin. Now, house and Brian, also a band-a-band who loves fried fries. Oh, there is also Anne, Brian's friend who is vanatig for fried fries too, and also flown in Mandarin. Sounds a bit tangled, right? But look at the graph we've got. Suddenly, it all starts to make sense. Now, with the idea of nodes and ages, entities and relationship, we have this final graph. But hey, let's get real. Our world is not just about Anne, Amy, and Brian. It's not just about bands and fried fries too, right? So, it's a vast thrill of people, teams, entities, and all of those have this special relationship. And that's what we call as a knowledge graph. So, once again, knowledge graph is a network of real-world entities and illustrates the relationship between them. All then, we store the knowledge graph in a graph database such as Neo4j database and process it using CypherQuery language. Neo4j's CypherQuery language includes clauses like use, match, read, return, and more. You can delve into them further with this Neo4j cheat sheet. Neo4j. Neo4j. talented ale. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Kraj. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j.\n",
       "\n",
       "\n",
       "\n",
       "## 3. Why is it important?\n",
       " Now, let's talk about how a knowledge graph empowers an ALANA. So using a knowledge graph, you can identify the links within a seemingly disconnected cut-set. What does it mean? So February 2024, researchers from Microsoft conducted a research to compare base retrieval augmented generation system, or RAC, and graph RAC. They used favorite incident information from a news article dataset and deposit equations. What has no furtherance yet done? The result, baseline RAC not able to answer it because sometimes using factor zero research is not always affected. Especially when the query does not provide enough context about its true intent, or when the context is fragment across large corpus of text. You probably have heard about plus in the middle things. And that's the problem. And they proved that graph RAC able to answer these questions because first, they were all search about the entities which has no forzea. This allows the LLM to grow itself and then provide a very detailed answer. In November 2023, there was also a research that showed how knowledge graph optimized the search in the SQL database. The researchers revealed that, when answering using GPT-4 with zero-shot prompts directly on SQL database achieves an accuracy of 16%. Notably, the accuracy increases 54% when questions are posed over a knowledge graph representation of the enterprise SQL database.\n",
       "\n",
       "\n",
       "\n",
       "## 4. Workflow\n",
       " Okay, so that's the reason why I learned knowledge graph for our LLAM is very interesting and important. And before we go into code, it's better for us to understand how it works. So first thing here, we will get the user question. And then we'll pass this user question to our LLAM. In this tab, our LLAM will also receive a database schema. Database schema means like the entities and relationship that we already store to our new 4G database. And the whole process in here, we call it as the graph chain. And then from the graph chain, it will generate a cipher query. And then we will run the cipher query to our new 4G database to get a result. And the result, we will pass it to the LLAM. In here, the LLAM will pass the result, we will create the result into our final answer. And in this tab, we will get the final one. Okay, thumbs to code.\n",
       "\n",
       "\n",
       "\n",
       "## 5. Code\n",
       " So actually all the code, the data I've already provided in this GitHub and I already put it in my description. So the first thing that we need to do is just to clone this. So just copy and then go to our VS code and do GitClone here. Okay guys, once done, our next step will be creating a virtual environment. So just go to our folder and then do pip install at this. It will take a few seconds, so I will skip this part. Now let's open the notebook that we have in here. So since we have already installed all the buttons in from the bit installable that we've just done before. So let's run this one. So in here, I'll go through, since we're going to use the open source LLAM, which is the Gemini. And then having Shays and also Neo4, so I'll go right now on how to get the ATI key for all this. But before that, we need to create a .eans as well to save the file variable and just... And then –Ω—É–∂nen it. So go ahead. And see other\n",
       "\n",
       "\n",
       "\n",
       "## 6. Neo4J, Google Gemini, Hugging Face set up\n",
       " to this the google gemini api key so i will just go to this url and then already create api if you have it and for your hugging face just follow this link and then use new token but since i already have these tokens you just copy and then save the rnv variable and then for neo4g actually you can use my neo4g desktop or for this i'll use neo4g error which is a little bit simpler so if you have it gone you should sign up in here okay so the incident is ready and now like click open okay so in here we have the connection url in here we have the database user and also password make sure to also copy the connection url and the database username to the environment variable the dot answer file so right now just copy paste the password and click connect now the database is connected and now the next test is how to connect the python in here to the our database in the neo4g so actually langchain already provide us with a very simple connector which is this one langchain community to graphs neo4g.crown here so just click run it's all done okay\n",
       "\n",
       "\n",
       "\n",
       "## 7. Data Overview\n",
       " So we have done to set up everything. So now let's talk about the data itself. So the data that we will use in here, I will keep it simple. We won't process data from the unstructured format such as the PDF, the text file. Nope. But in here, we will use data from Kegel. So that's for Manus Kumar for providing this data set. So basically, it is a LinkedIn data set, professional information like the name, the CPM and current company that they work in the position and many more. And actually, here we did a little bit preprocessing to finally get this final data. The next.\n",
       "\n",
       "\n",
       "\n",
       "## 8. Insert Data to Neo4J\n",
       " thing is how to insert this data to Neo4j database. So as you can see here, since our data in Neo4j is still empty to node 0 and the relationship 0, and you can also check it by run to cell. You can see in here, there's nothing in here. So how to input it? So the first thing that we hear is by using the cipher query to interact with our database. So I'll explain one by one, start one here. Load CSV with headers from blah, blah, blah, blah. So actually, it's loading the CSV file from this GitHub repository. And then as we read the CSV file for each row, and in here, there's a cipher query inside. So we know that, okay, in here, name is the entity of name is person. So we make it to define the entity that we have in our database. So in here, it's a little bit different than the previous one, right? So basically, we use for each. Because if you see in the languages here, sometimes one people picks many languages, such as Roberto Mirola. He can speak English, Italian, France, Dutch, and German. So in here, we separate with this symbol. And this line is talking about the relationship. If you still remember about the explanation about relationship entity. So this one is the relationship or the ageist. Just run this one. Okay. And let's check it. Okay. So now our data is already in the Neo4j database. Check once again. Let's reload this. Okay. See? Now we have the company. Now we have educated ad, country industrial limits. All the data in from CSV is already imported in our Neo4j. Okay. Thanks, guys.\n",
       "\n",
       "\n",
       "\n",
       "## 9. Building a Graph Chain\n",
       " Hey guys, now let's talk about the most interesting part of this video. How to operate the large language model to interact with our knowledge graph in Neoprene. So in here, we are using chat Google generative AI, Gemini Pro is open source, and then the API ensures the parameter that we have saved before in .elv file, and in here, we set the temporary to . The question is, why are we not set it to 0.5 or 0.9? The reason is because in this task, we need the LLM not to do a creative writing, but we needed to translate the natural language to a cyber query language. And then here, the chain with the one chain with graph cyber QA chain. The line chain has provided it's very easy to use. So the graph is the graph that we have defined in here, and the LLM is the model that we want to use, and for both, I set it to be close to true. What does it mean? Because I want to understand what happened beyond LLM. So run this, and then in here, we have several questions. I've already created a table that contains the pair of the question and the correct answer, so it becomes easier for us to check whether the answer, resided from the LLM, is correct or not. We want to know how it's performed, so let's run it.\n",
       "\n",
       "\n",
       "\n",
       "## 10. Evaluation 1\n",
       " Okay, that's cool. Okay, so now let's talk about the result. So the first question, this will companies and advertising services industry. In here, it generates cyber and full contacts is said, and the result is toolbox creative, big advertising service enable. That's perfect. And the second question is, a worker you graduated from Cyberfresor University is currently employed at. Okay, I'm not sure why, but the general cyber query in here looks a little bit messy, and that's why there's a null in the context area. The result is I do not have the information we filmed here. And then the third question, where is POW looks working? Okay, so in here, the general cyber query is correct, and in the full contacts in here, toolbox creative is correct, but I don't know sure why, but then it's changing here as a result. I don't know the answer. The fourth question is, we see open here, which actually, if you remember about the schema of our database, the relationship, there's no spoken in in our database, right? So that's why it's null, and I don't have that information. The last one is, okay, the problem is the same, is native of. Actually, it's kind of huge needing about relationship, about the properties, about the entities, right? Because we don't have relationship is native of in our schema. So that's why it's also wrong. The answer is zero. The correct answer is one. Now, let's do a quick recap on the result that we have got before. So in here, we have two correct answer and three false answer from the LLM, right? And from this result, we can identify some problems. The first one is, not being able to accurately translate text into a cyber query. And the second one is, hallucinates properties, relationship, and entities. This one is one of the biggest problems of the LLM in-\n",
       "\n",
       "\n",
       "\n",
       "## 11. Prompting Strategies\n",
       " generating a cyber query. So, what is the solution? We call it as prompting strategies. So, in short, we provide examples to our model to help it understand the structure correctly, similar to how pairs guide us when we learn to work, right? More examples makes the models learn and smarter. Now, let's jump to a code. So, the first thing that we need to do is to create pairs of questions and cyber query. So, I won't do it manually. Just copy this and paste the objectivity. Okay, once we got a result, so just copy and paste it to our Facebook, for example, in here. I want to copy these questions. And the most important part is to create text once again. If the general query from the JetsBD is already correct or not, we can do this by go to our Neo4j copy, paste, and text. Okay, good. We have this name, Pakusatya. So, if the general cyber query is correct, just do all that and copy and paste it here. The last thing that you need to do is to add places in here, because if you don't do it, you will not get it. I've already have this one, so I won't use it. I'll use mine to just run this. And in here, actually, LangChain already provide us with a free shot prompt template. And so, prompt template is just the prompt that we want to use, that we will use as a parameter in here. And the example, this is a sample that we have already divided in here. So, it will take the top three examples from it. And then the perfect self-ex, and here is the input variables, which is question and schema. We'll use the question and this, and the schema is here. So, run this one. This is an example of the prompt. Let's create our second chain. And check this one. All right.\n",
       "\n",
       "\n",
       "\n",
       "## 12. Evaluation 2\n",
       " For the first question, the answer is correct. Toolbox Creative, Big Advertising Suit Into People's Tool. And for the second question, we get the correct answer which is Elastic Pet. And in here, we got Toolbox Creative. For the fourth question, Degenerative Cypher Quares is also correct and we get here Vitaly New Hint. And then for the last one, okay, we got the correct answer though which is one. So using the problem strategies will enhance our model. Right now, we have all correct answer.\n",
       "\n",
       "\n",
       "\n",
       "## 13. Bonus ( How to Create a Dynamic Prompt? )\n",
       " Okay guys, our job is done, but as I've told you before, that I have a bonus for you. So, if you're still a member, we have this question. Where do Michael work? And the problem that we got is, which workers are friends. What industries are workers named animal associated with and which workers live in Canada and speak German? So I have a choice, there's no correlation, right? Between which workers speak friends and where do Michael work? And the reason is this line. So in here, we are taking top three from this list. In fact, we have more than three questions. So what's the point to just only take this top three? And that's why we need a dynamic problem. So to create a dynamic problem, we need a semantic similarity example selector. So basically, if you calculate which one is the closest between the question and the list that we have. So the first one that you need is the hacking phase embeddings and then the neo-forged factor. So previously, we are taking the top three questions from the examples list. Now, we will use the example selector to create a dynamic problem. If we run this. So, where do Michael work? What companies do workers named John work in? It makes sense. Where do workers named Alice live? And what industries are workers named Emily associated? So right now, the generative problem is more dynamic and we're not just the top.\n",
       "\n",
       "\n",
       "\n",
       "## 14. Outro\n",
       " to read from our list.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "formatted_text = []\n",
    "for i,r in enumerate(response):\n",
    "    chapter_text = dedent(f\"\"\"\n",
    "    ## {i+1}. {r['title']}\n",
    "    {r['transcription']['text']}\n",
    "    \"\"\")\n",
    "\n",
    "    formatted_text.append(chapter_text)\n",
    "\n",
    "formatted_text = \"\\n\\n\".join(formatted_text)\n",
    "\n",
    "Markdown(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd435519-8a77-40d6-abca-80359e6f903c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:03.129468Z",
     "iopub.status.busy": "2024-10-06T15:39:03.129141Z",
     "iopub.status.idle": "2024-10-06T15:39:03.132967Z",
     "shell.execute_reply": "2024-10-06T15:39:03.132503Z",
     "shell.execute_reply.started": "2024-10-06T15:39:03.129446Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\" Your output should use the following template:\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Analogy\n",
    "\n",
    "### Notes\n",
    "\n",
    "- [Emoji] Bulletpoint\n",
    "\n",
    "### Keywords\n",
    "\n",
    "- Explanation\n",
    "\n",
    "You have been tasked with creating a concise summary of a YouTube video using its transcription.\n",
    "\n",
    "Make a summary of the transcript.\n",
    "\n",
    "Additionally make a short complex analogy to give context and/or analogy from day-to-day life from the transcript.\n",
    "\n",
    "Create 10 bullet points (each with an appropriate emoji) that summarize the key points or important moments from the video's transcription.\n",
    "\n",
    "In addition to the bullet points, extract the most important keywords and any complex words not known to the average reader aswell as any acronyms mentioned. For each keyword and complex word, provide an explanation and definition based on its occurrence in the transcription.\n",
    "\n",
    "Please ensure that the summary, bullet points, and explanations fit within the 330-word limit, while still offering a comprehensive and clear understanding of the video's content. Use the text above:\n",
    "\n",
    "Please, I need you to translate the answer into Portuguese!\n",
    "\n",
    "```\n",
    "{title}\n",
    "\n",
    "{transcription}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"title\", \"transcription\"], template=prompt_template\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8adfdb3-203a-4f25-a348-8a414f5faf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:05.246826Z",
     "iopub.status.busy": "2024-10-06T15:39:05.246519Z",
     "iopub.status.idle": "2024-10-06T15:39:05.295897Z",
     "shell.execute_reply": "2024-10-06T15:39:05.295405Z",
     "shell.execute_reply.started": "2024-10-06T15:39:05.246802Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "526ebac5-6174-4da4-95e8-3eba05e066de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:06.755486Z",
     "iopub.status.busy": "2024-10-06T15:39:06.755296Z",
     "iopub.status.idle": "2024-10-06T15:39:14.210141Z",
     "shell.execute_reply": "2024-10-06T15:39:14.207848Z",
     "shell.execute_reply.started": "2024-10-06T15:39:06.755471Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = chain.invoke({\"title\": transcripter.title, \"transcription\": formatted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1936f84-aa1b-483b-91e0-49081b1ff027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:14.222765Z",
     "iopub.status.busy": "2024-10-06T15:39:14.217970Z",
     "iopub.status.idle": "2024-10-06T15:39:14.228998Z",
     "shell.execute_reply": "2024-10-06T15:39:14.228188Z",
     "shell.execute_reply.started": "2024-10-06T15:39:14.222275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "O v√≠deo apresenta um tutorial sobre como integrar um gr√°fico de conhecimento com modelos de linguagem de grande porte (LLMs) usando Python. O apresentador explica a teoria por tr√°s dos gr√°ficos de conhecimento, como configurar um banco de dados Neo4j e integr√°-lo com a biblioteca LangChain. O v√≠deo tamb√©m discute a import√¢ncia dos gr√°ficos de conhecimento para melhorar a precis√£o das respostas dos LLMs, demonstrando como eles podem identificar conex√µes em conjuntos de dados aparentemente desconectados.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Integrar um gr√°fico de conhecimento a um LLM √© como usar um mapa detalhado para navegar em uma cidade desconhecida. Sem o mapa, voc√™ pode se perder em ruas e avenidas, mas com ele, voc√™ pode encontrar o caminho mais eficiente e descobrir conex√µes que n√£o seriam vis√≠veis √† primeira vista.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- üß† O que √© um gr√°fico de conhecimento? √â uma rede de entidades do mundo real e suas rela√ß√µes.\n",
       "- üìä Import√¢ncia: Gr√°ficos de conhecimento ajudam LLMs a responder perguntas complexas com mais precis√£o.\n",
       "- üîó Conex√µes: Eles identificam links em conjuntos de dados desconectados, melhorando a compreens√£o do contexto.\n",
       "- üíª Configura√ß√£o: O v√≠deo ensina a configurar um banco de dados Neo4j e a usar a linguagem Cypher.\n",
       "- üìà Resultados: Pesquisas mostram que o uso de gr√°ficos de conhecimento aumenta a precis√£o das respostas dos LLMs.\n",
       "- üîÑ Workflow: O processo envolve receber perguntas, gerar consultas Cypher e retornar resultados.\n",
       "- üìö Exemplos: O apresentador usa um conjunto de dados do LinkedIn para demonstrar a inser√ß√£o e consulta de dados.\n",
       "- ‚öôÔ∏è Estrat√©gias de Prompt: Exemplos ajudam os modelos a entender melhor a estrutura das consultas.\n",
       "- üîç Avalia√ß√£o: O v√≠deo mostra como avaliar a precis√£o das respostas geradas pelos LLMs.\n",
       "- üéÅ B√¥nus: O apresentador oferece dicas sobre como criar prompts din√¢micos para melhorar a intera√ß√£o.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Gr√°fico de Conhecimento**: Uma representa√ß√£o de entidades e suas rela√ß√µes no mundo real.\n",
       "- **Neo4j**: Um banco de dados orientado a grafos que armazena dados em forma de n√≥s e arestas.\n",
       "- **Cypher**: A linguagem de consulta usada para interagir com o banco de dados Neo4j.\n",
       "- **LLM (Modelo de Linguagem de Grande Porte)**: Modelos de intelig√™ncia artificial que processam e geram texto em linguagem natural.\n",
       "- **LangChain**: Uma biblioteca que facilita a integra√ß√£o de LLMs com bancos de dados e outras fontes de dados.\n",
       "\n",
       "Essas defini√ß√µes ajudam a entender os conceitos discutidos no v√≠deo e sua aplica√ß√£o pr√°tica."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcf757-89eb-4842-84e6-af7d94fc16bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fae43-aeab-4d2f-9bc8-3cf9a7e2b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc4ea2-4c85-4b6f-9120-fc2197d5589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2d751-4c8e-4b97-8c04-790cd1b2cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7b518-7941-4f05-86c1-c01d96512869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6318596-440c-45d0-9576-b4a143504bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f55465f-fe5c-43e0-b95a-bc9a8e2da90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:29:17.120964Z",
     "iopub.status.busy": "2024-10-06T15:29:17.120628Z",
     "iopub.status.idle": "2024-10-06T15:29:17.477307Z",
     "shell.execute_reply": "2024-10-06T15:29:17.476688Z",
     "shell.execute_reply.started": "2024-10-06T15:29:17.120940Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formatted_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mformatted_text\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'formatted_text' is not defined"
     ]
    }
   ],
   "source": [
    "formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf8e2d9-64bc-4596-99f2-413983fdd0d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:22:56.199454Z",
     "iopub.status.busy": "2024-10-06T15:22:56.199184Z",
     "iopub.status.idle": "2024-10-06T15:22:57.391307Z",
     "shell.execute_reply": "2024-10-06T15:22:57.389030Z",
     "shell.execute_reply.started": "2024-10-06T15:22:56.199429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848a4e5-3605-4711-bb73-9fe2d9eb8232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4f99c-f5d9-4809-b09d-b98f23ec32d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931dc9d-d84c-40db-8bc4-1aff9e70525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c57ebb-12f4-4d79-b925-ec4cb21d9b5e",
   "metadata": {},
   "source": [
    "### [Extra] - Informa√ß√µes e Metadadaos sobre v√≠deos do Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581c2422-c39f-4014-8d46-898275c794fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:03.531515Z",
     "iopub.status.busy": "2024-10-06T02:14:03.531254Z",
     "iopub.status.idle": "2024-10-06T02:14:03.534685Z",
     "shell.execute_reply": "2024-10-06T02:14:03.534321Z",
     "shell.execute_reply.started": "2024-10-06T02:14:03.531500Z"
    }
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def get_youtube_video_metadata(video_url):\n",
    "    ydl_opts = {\n",
    "        'skip_download': True,  # N√£o baixa o v√≠deo\n",
    "        'extract_flat': True,   # N√£o extrai streams de m√≠dia, s√≥ metadados\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4341c3-332e-4eee-957e-386757baa3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:05.693631Z",
     "iopub.status.busy": "2024-10-06T02:14:05.693450Z",
     "iopub.status.idle": "2024-10-06T02:14:12.008286Z",
     "shell.execute_reply": "2024-10-06T02:14:12.005844Z",
     "shell.execute_reply.started": "2024-10-06T02:14:05.693617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading player 96d06116\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n"
     ]
    }
   ],
   "source": [
    "video_metadata = get_youtube_video_metadata(VIDEO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04889a40-1e9a-48cc-9383-e06000dabf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:12.013412Z",
     "iopub.status.busy": "2024-10-06T02:14:12.012661Z",
     "iopub.status.idle": "2024-10-06T02:14:12.031044Z",
     "shell.execute_reply": "2024-10-06T02:14:12.030591Z",
     "shell.execute_reply.started": "2024-10-06T02:14:12.013338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec51b4b7-6707-4374-92d4-70400bc81537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:01.354156Z",
     "iopub.status.busy": "2024-10-06T02:15:01.353899Z",
     "iopub.status.idle": "2024-10-06T02:15:01.357036Z",
     "shell.execute_reply": "2024-10-06T02:15:01.356601Z",
     "shell.execute_reply.started": "2024-10-06T02:15:01.354140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title = ansible_vault\n",
      "language = en\n"
     ]
    }
   ],
   "source": [
    "title = video_metadata[\"title\"].lower().replace(\" \",\"_\")\n",
    "language = video_metadata[\"language\"]\n",
    "\n",
    "print(f\"title = {title}\")\n",
    "print(f\"language = {language}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4b2a1-990a-424a-94c8-fd06c6c6800e",
   "metadata": {},
   "source": [
    "# Download audio from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1230f01-0221-4f76-86b0-c5e895891712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:04.627550Z",
     "iopub.status.busy": "2024-10-06T02:15:04.627298Z",
     "iopub.status.idle": "2024-10-06T02:15:16.718774Z",
     "shell.execute_reply": "2024-10-06T02:15:16.718372Z",
     "shell.execute_reply.started": "2024-10-06T02:15:04.627535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[info] MnBV8zLq-_Y: Downloading 1 format(s): 251\n",
      "[download] Destination: data/ansible_vault_raw.webm\n",
      "[download] 100% of    5.05MiB in 00:00:04 at 1.02MiB/s   \n",
      "[ExtractAudio] Destination: data/ansible_vault_raw.mp3\n",
      "Deleting original file data/ansible_vault_raw.webm (pass -k to keep)\n",
      "CPU times: user 409 ms, sys: 66.7 ms, total: 476 ms\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_filename = f\"data/{title}_raw\"\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'{output_filename}.%(ext)s',\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6d69b-e69f-488c-a6fd-1fe65d5d7a17",
   "metadata": {},
   "source": [
    "As informa√ß√µes dispon√≠veis s√£o:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52507359-e44b-4e13-83d2-fa32a7b279ae",
   "metadata": {},
   "source": [
    "# Cortar audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfde451-ff29-4f82-9d7c-d86f1ead2b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:17.699457Z",
     "iopub.status.busy": "2024-10-06T02:15:17.699270Z",
     "iopub.status.idle": "2024-10-06T02:15:18.258093Z",
     "shell.execute_reply": "2024-10-06T02:15:18.257365Z",
     "shell.execute_reply.started": "2024-10-06T02:15:17.699441Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/output_audio.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 7\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m start_time_ms \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     10\u001b[0m end_time_ms \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/output_audio.mp3'"
     ]
    }
   ],
   "source": [
    "raw_filename = \"data/raw_audio.mp3\"\n",
    "output_filename = \"data/output_audio.mp3\"\n",
    "start_time = 0\n",
    "end_time = 10\n",
    "\n",
    "\n",
    "audio = AudioSegment.from_file(output_filename)\n",
    "\n",
    "start_time_ms = start_time * 1000\n",
    "end_time_ms = end_time * 1000\n",
    "trimmed_audio = audio[start_time_ms:end_time_ms]\n",
    "trimmed_audio.export(output_filename, format=\"mp3\")\n",
    "print(f\"√Åudio recortado salvo em: {output_filename}\")\n",
    "\n",
    "Audio(output_filename, autoplay=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd8ac0-c666-41cb-8a18-17a7b8cf4c47",
   "metadata": {},
   "source": [
    "# Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f784b4-9b26-41f8-9044-b8d9a376237b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:13:27.817946Z",
     "iopub.status.busy": "2024-09-23T13:13:27.817109Z",
     "iopub.status.idle": "2024-09-23T13:13:27.823544Z",
     "shell.execute_reply": "2024-09-23T13:13:27.823179Z",
     "shell.execute_reply.started": "2024-09-23T13:13:27.817871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f8040f-19be-4130-8c93-4bdaffce91d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:13:29.228249Z",
     "iopub.status.busy": "2024-09-23T13:13:29.227347Z",
     "iopub.status.idle": "2024-09-23T13:13:46.558383Z",
     "shell.execute_reply": "2024-09-23T13:13:46.557846Z",
     "shell.execute_reply.started": "2024-09-23T13:13:29.228149Z"
    }
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "232aa0bc-e531-4318-b5c9-785caedd9707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:37:27.420378Z",
     "iopub.status.busy": "2024-09-23T13:37:27.420223Z",
     "iopub.status.idle": "2024-09-23T13:40:09.490762Z",
     "shell.execute_reply": "2024-09-23T13:40:09.490296Z",
     "shell.execute_reply.started": "2024-09-23T13:37:27.420365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My name is Alex Dorjson. I'm an Ansible Solutions Specialist and today I'm going to be talking about Ansible Vault and what it can be used for. So first let's talk about what Ansible Vault is. Ansible Vault is just a command line utility that's installed as part of Ansible that provides a way for you to encrypt different variables and files. So now I don't have to worry about my sensitive data being out there in plain text. Many cases I see this used to protect different machine credentials, some of your hosts and group files, especially if I'm connecting to other utilities or APIs and I can use this to encrypt just individual strings or entire files. I'll personally say I generally use entire files rather than strings just because it's easier to maintain and easier to rekey if I need to. So important reminder, this is only designed to protect data at rest. So obviously if I'm trying to use this in a standard variable and I have a debug statement in my playbook I can still print out that data so it's important to make sure that a a is a string, and b is a variable. So I'm going to use this as my default variable and I'm going to use it for the way that you're reviewing your playbooks, making sure I'm doing things properly, or using the no-log module when it's required for different aspects of what I'm trying to do. I can also set up different vaults and different passwords and better access control over these different vaults. So I can have certain data in some vaults, certain data in other vaults to really lock down who can get access to what different variables. So how does it work? So Ansible Vault is a command line option. I've got a bunch of different things that I can do. So I can either use it to create an initial file and encrypt it with that password. I can also just encrypt an existing file. So maybe you already have group files created and I want to encrypt those. Maybe I need to decrypt them back to our normal text file to do some editing. Obviously I can just do Ansible Vault and edit to edit that particular file. Or if I just want to see the content that's there I can use Ansible Vault view. And then as I talked about earlier, you know, maybe someone did get access to my Ansible Vault password for some reason. I can do Ansible Vault rekey to change that encryption password. So it gives me a very easy way to create and edit these different files really depending on what your needs are. So then when I'm actually running playbooks, again, I can use this to, you know, whether it's with Ansible Playbook or Ansible Navigator, I can use Ansible Vault with that. So with Ansible Playbook, I can use different options, you know, such as ask vault pass or the vault password file. If I've got, as I said, multiple vaults, I can use that vault ID. For Ansible Navigator, I will need to either use a vault password or a vault password. For Ansible Navigator, I will need to either use a vault password or a vault password. So I can either use a vault password file and provide that in my Ansible config or I can use environmental variables for that. It doesn't have the ask options, just a limitation of Ansible Navigator. But personally, I still use Ansible Vault for all of my connection variables that I run from CLI. So let's jump into a demonstration to see how I can use Ansible Vault for different files. Now let's jump into actually using Ansible Vault. So as you can see, I already have a few files here. I have a very basic playbook that will actually go through the process of debugging out of your variable that I'm going to create. I've got an empty group vars folder, which is where I'll put all my connection variables. And then I have, you know, a password file that I'll use in just a second. So in this case, I do want to do Ansible vault and I want to create a new file, but I want this to be in my group vars and I want this to apply for all different hosts in my inventory. In this case, I'm just going to run this on local hosts, but I still want to leverage that vault message variable. So when I try to create this file, it will ask me for a vault password. And now I can create that vault message and I can just call it whatever I want. This is a new vault message. Save it. And as you notice, if I try to view that particular file, it is now encrypted. So I do already have an existing password file and maybe I just want to encrypt this existing file. So I can do Ansible vault encrypt that password file and once again, have the option to assign it a vault password and now that file is encrypted. I can do Ant National Vault Decrypt or I can do an absolute edit that password file. It will require obviously the vault password to jump in and I can edit that particular file using my default editor or I can do Ansible vault view. And now I can go to this backup page that I've built in there. And it's pretty interesting. This new vault password file will have that view for any customers. This is like a very specific file you shouldÈõÖ view once again asking me for that password and I can just see so similar to just you know running a cat on that command or I could do decrypt to decrypt that particular file I can also do rekey to change the vault password this really gives me that full capability to use Ants with vault to make changes to different files or strings so maybe I now actually want to run this particular playbook using that variable that I set up before so in this case I'm just gonna use Ansible navigator I mean Ansible playbook to do it so I'll do Ansible playbook in this case I want to ask for that vault pass and I'll use that debug.yaml and as you can see it did this is a new vault message which is that vault password that I had set up previously do I use ansible vault regularly absolutely yes so this is VS code where I do most my playbook editing and I am running Ansible playbook and I'm running Ansible playbook and I'm running Ansible playbook and I'm running Ansible navigator so as you can see I have an inventory here obviously I've got you know multiple different groups and variables so for you know again my higher level all variables I had that encrypted using Ansible vault same thing for my individual group level variables so it's important to note for Ansible navigator yes I can use Ansible vault but I either have to store that vault password somewhere securely on the file system or I can store that vault password in an environmental variable for me I've got it stored locally on my file system and I just have my Ansible config pointing to that particular vault password so in my case I've got it stored very securely and then I have a link back to that particular file in my current working directory Ansible navigator docs will have that information for you and I will paste that in the description down below so where can you go from here I'll include in the description down below a basic walkthrough of Ansible vault using a blog very similar to what I just walked through here also the Ansible vault docs has all the information on the specific key requirements if you want to use a vault ID so this gives you the capability to have multiple vaults within a single playbook run so again as I talked about with role based access control is trying to limit who gets access to what vaults I can have that capability and then there's also an FAQ that walks into how I can use Ansible vault with Ansible navigator which is what I do today so thank you for taking the time to learn a little bit more about how Ansible vault can be utilized to provide some at-rest encryption for my different passwords and keys thank you\n",
      "CPU times: user 2min 42s, sys: 358 ms, total: 2min 43s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_filename = f\"data/{title}_raw.mp3\"\n",
    "\n",
    "result = model.transcribe(audio_filename, language=language)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836999fd-4250-4a15-a8b8-892c46e94f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a2fe2-7050-44fd-8ad5-1332d85677ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dcf6859-65ac-4604-9d03-24219d1216e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vamos pro jogo das frases, jogam um ande-marc√£o. Nesse jogo, voc√™s escreveram frases l√° fora e elas est√£o nessa caixa. Cada um vai pegar duas frases e colocar no bolso. Durante a cena, eles tiram essa frase e l√™m a frase, mas n√£o basta ler. Tem que justificar a frase dentro da cena j√° come√ßada. E a cena leva o t√≠tulo de Eu Queria Voar. E o jogo das frases come√ßa agora. Jinoveva, volta pro poleiro! Eu sei por que voc√™ t√° a√≠ fora! Por qu√™? Eu vi voc√™ ontem √† noite acordado olhando as corujas de um lado pro outro. At√© os morcegos voc√™ ficou olhando. Os morcegos, eles parecem ratos, n√£o sabe o que eles fazem. Eles v√£o, Jinoveva, eu sei. Eles v√£o... Aceitam como voc√™ √©, Jinoveva, e outra coisa. Acho que esqueci o ferro ligado. S√≥ um minuto. Isso, vai l√°! Vai que o CIRAM vai queimar! Vai queimar tudo que... Agora... √â que agora √© a chocadeira, eu deixo o ferrinho do lado da chocadeira. Mais f√°cil do que eu ficar. Tem mais o que fazer. Rebeca, voc√™ tem que ter mais ambi√ß√£o. Bicou caovos e fica se escancando. √â a natureza, √© minha natureza, √© como eu sou. A natureza √© todo o potencial que a gente pode explorar, e a gente pode ser muito mais do que isso. Galinhas podem... Aqui n√£o tem farol, aqui √© rotat√≥ria. O meu norte √© um giro infinito. Foi o melhor que eu pude fazer. Olha isso! Voc√™ tentando voar √© a vida te dando farol vermelho! E como numa rotat√≥ria voc√™ t√° em c√≠rculos! Tem que acreditar! Rebeca, tem que acreditar! Voc√™ quer acreditar? Vamos l√° fora! Pau! Uau! Uau, que urubuz√£o! Oi, urubu! Ouro com o Antonio! Fiquei sabendo que uma de voc√™s est√° interessada em voar. Eu tenho aqui exatamente o que voc√™ precisa. O neg√≥cio que vai fazer voc√™ chegar nas estrelas, se √© que voc√™ me entende. Isso daqui vai te fazer ir pras nuvens, cara. O pre√ßo disso s√£o 10 ovos. 10 ovos, isso √© pra minha fichinha. N√£o, n√£o, n√£o, n√£o, n√£o! E voc√™ vai ver estrela com isso? √â de fazer o qu√™? √â de voar! Ok, eu topo! Nada mais imponente que um sonho a ser realizado. Toma os seus ovos. Se algu√©m perguntar se eu te vendi isso, isso nunca aconteceu antes. Ok, os ovos estavam no meu suvaco, pode levar... Vai, urubu! Ah! Deixa l√°, que barulho eu fa√ßo, urubu! Ah! Ah! Fui no mangue catalixo, eu quero conversar com o urubu! Comercer com o urubu! Comercer com o urubu! Olha, ele deu um... Ele deu um √≥dio! Eu n√£o sei, mas se o delegalo vem, ele vai ficar... N√£o fala pra um delegalo! Ele vai ficar bom! Ai, meu Deus! O seu delegalo! N√£o tem nada acontecendo aqui, outra coisa! Estou √† beira de um ataque cego! Ah! N√£o tem nada de errado acontecendo aqui! Ah! Ah! Vou levar pro ferrinho quente! Ah! Tinha um novo verbo, deu uma coisa estranha aqui! Ah! Delegalo, eu s√≥ quero voar! Eu s√≥ quero voar, delegalo! Ah! Na minha n√∫mero de estritos, o Galinha n√£o voa! At√© provaram que a terra era redonda, todo mundo acreditava que ela era plana, entende? J√° tem gente que duvida! Delegalo! Nada vai me impedir! Galinha, par com isso! A sua vida √© uma linha reta pra ter far√≥is, √© uma rotat√≥ria! Voc√™ tem que continuar por aqui! Oh! Ah! Ah! Ah! Oh, meu Deus! Ah! Oh, mortal! √â o Boel! √â o Boel! Afial de Contas! Uma galinha! Hoje √© dia de comer feij√£o! Caraca! Gente, assim... Eu tava vendo o avi√£o tentando levantar com um motor de corsa! Que fique claro que eu cortei o carboidrato! N√≥s somos os barbichas, obrigado por assistir o nosso v√≠deo! Se voc√™ gostou, inscreva-se no nosso canal, compartilhe esse v√≠deo! Se voc√™ n√£o gostou, assiste algum outro v√≠deo, at√© voc√™ achar o que voc√™ gosta! A√≠ voc√™ compartilha, se inscreve e d√° like no v√≠deo! Se n√£o gostar de nenhum, nenhum assim, n√£o teve nenhum! A√≠ compartilha igual, s√≥ que falando, meu Deus do c√©u, vergonha nacional! Onde √© civil, limite do humor! Test√£o, test√£o, test√£o! Boa! Viraliza at√© mais, n√©?\n",
      "CPU times: user 43.4 s, sys: 503 ms, total: 43.9 s\n",
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_filename = \"data/raw_audio.mp3\"\n",
    "\n",
    "model = whisper.load_model(\"small\").to(device)\n",
    "result = model.transcribe(audio_filename, language=\"pt\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95f1cd-ca8c-4c7c-ab48-6a3b277fe0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a5913-8ae5-4202-954b-be5b404831d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2b6fc-62db-4c72-ac8e-0654d2ff8d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e5cef-13cb-4f47-a2ea-14f828435bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67abc23-cb7d-4c1b-8521-22c12890f230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e9ff6-1000-4d4f-873d-3ba98f253af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086c863-94d2-453a-b283-5ae667e3194d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2ba4ee-7a76-463f-a6fa-c2ca84fec4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: pt\n",
      "candidato Pablo Maisal, se a cidade t√° mal, relaxe e vote Pablo Maisal. Pegou a 100 installership, se √© uma corrida eleitoral\n",
      "CPU times: user 2.3 s, sys: 8.69 ms, total: 2.31 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"data/output_audio.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(language=\"pt\")\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f53ea-ee3f-4329-8e91-77af76439aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5924657-a0df-4dad-9520-c49a42ccd249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T13:37:10.248954Z",
     "iopub.status.busy": "2024-10-06T13:37:10.248761Z",
     "iopub.status.idle": "2024-10-06T13:37:10.252508Z",
     "shell.execute_reply": "2024-10-06T13:37:10.252143Z",
     "shell.execute_reply.started": "2024-10-06T13:37:10.248937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a network graph maker who extracts terms and their relations from a given context. You are provided with a context chunk (delimited by ```) Your task is to extract the ontology of terms mentioned in the given context. These terms should represent the key concepts as per the context. \n",
      "Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\n",
      "\tTerms may include object, entity, location, organization, person, \n",
      "\tcondition, acronym, documents, service, concept, etc.\n",
      "\tTerms should be as atomistic as possible\n",
      "\n",
      "Thought 2: Think about how these terms can have one on one relation with other terms.\n",
      "\tTerms that are mentioned in the same sentence or the same paragraph are typically related to each other.\n",
      "\tTerms can be related to many other terms\n",
      "\n",
      "Thought 3: Find out the relation between each such related pair of terms. \n",
      "\n",
      "Format your output as a list of json. Each element of the list contains a pair of termsand the relation between them, like the follwing: \n",
      "[\n",
      "   {\n",
      "       \"node_1\": \"A concept from extracted ontology\",\n",
      "       \"node_2\": \"A related concept from extracted ontology\",\n",
      "       \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\"\n",
      "   }, {...}\n",
      "]\n",
      "\n",
      "context: ```\n",
      "A receita recorrente √© um faturamento cont√≠nuo que uma empresa recebe ao vender produtos e servi√ßos por meio do modelo de assinatura ou plano, que gera uma mensalidade para o cliente fazer o pagamento todo m√™s.\n",
      "\n",
      "Esse formato de contrato com os clientes √© bastante utilizado principalmente por empresas de Software as a Service (SaaS) e por aquelas que comercializam produtos e servi√ßos com demanda cont√≠nua.\n",
      "\n",
      "Com a ado√ß√£o desse modelo, as empresas buscam uma maior previsibilidade de receita para o caixa da companhia, a receita previs√≠vel, por saberem ao certo quanto entrar√° de faturamento ao longo dos meses.\n",
      "\n",
      "A receita previs√≠vel permite um melhor planejamento financeiro e maior controle das demandas futuras, facilitando o processo de produ√ß√£o e gest√£o dos neg√≥cios.\n",
      "\n",
      "Quando se tem uma estimativa de demanda que precisa ser atendida m√™s a m√™s, h√° uma melhor organiza√ß√£o do processo produtivo para atender essa demanda na medida certa, sem desperd√≠cio de recursos, o que impacta tamb√©m numa melhor gest√£o empresarial.\n",
      "\n",
      "Por isso, para quem utiliza esse modelo, √© fundamental a compreens√£o destes dois conceitos: receita recorrente mensal e receita recorrente anual.\n",
      "``` \n",
      "\n",
      " output: \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db54703-50f2-47fa-a3d4-f1615f71edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
