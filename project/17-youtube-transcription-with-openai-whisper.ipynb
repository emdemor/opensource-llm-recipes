{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4830bddc-4c6b-4fe8-8638-c5d83e0b97b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:55:19.183538Z",
     "iopub.status.busy": "2024-10-06T15:55:19.183243Z",
     "iopub.status.idle": "2024-10-06T15:55:19.185807Z",
     "shell.execute_reply": "2024-10-06T15:55:19.185321Z",
     "shell.execute_reply.started": "2024-10-06T15:55:19.183512Z"
    }
   },
   "outputs": [],
   "source": [
    "# # !pip install pytube pydub\n",
    "# !pip install -U youtube_dl\n",
    "# !pip install -U yt-dlp==2024.8.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7394d4-3a9c-4a11-810c-673dad864652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:10.966014Z",
     "iopub.status.busy": "2024-10-06T15:56:10.965643Z",
     "iopub.status.idle": "2024-10-06T15:56:12.835201Z",
     "shell.execute_reply": "2024-10-06T15:56:12.834403Z",
     "shell.execute_reply.started": "2024-10-06T15:56:10.965992Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pathlib\n",
    "import shutil\n",
    "import whisper\n",
    "import torch\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Markdown\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0708448-882f-443b-972d-cb780c9e5a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:12.838158Z",
     "iopub.status.busy": "2024-10-06T15:56:12.838028Z",
     "iopub.status.idle": "2024-10-06T15:56:12.840653Z",
     "shell.execute_reply": "2024-10-06T15:56:12.840309Z",
     "shell.execute_reply.started": "2024-10-06T15:56:12.838144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large', 'large-v3-turbo', 'turbo']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8171ed34-5888-48aa-893a-0097c9d3bdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:12.841612Z",
     "iopub.status.busy": "2024-10-06T15:56:12.841429Z",
     "iopub.status.idle": "2024-10-06T15:56:22.055075Z",
     "shell.execute_reply": "2024-10-06T15:56:22.054460Z",
     "shell.execute_reply.started": "2024-10-06T15:56:12.841599Z"
    }
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model('large-v3-turbo').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a15dd7-caa0-46d2-b74d-092dd3b1ad44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.055794Z",
     "iopub.status.busy": "2024-10-06T15:56:22.055649Z",
     "iopub.status.idle": "2024-10-06T15:56:22.058583Z",
     "shell.execute_reply": "2024-10-06T15:56:22.058135Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.055776Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\" Your output should use the following template:\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Analogy\n",
    "\n",
    "### Notes\n",
    "\n",
    "- [Emoji] Bulletpoint\n",
    "\n",
    "### Keywords\n",
    "\n",
    "- Explanation\n",
    "\n",
    "You have been tasked with creating a concise summary of a YouTube video using its transcription.\n",
    "\n",
    "Make a summary of the transcript.\n",
    "\n",
    "Additionally make a short complex analogy to give context and/or analogy from day-to-day life from the transcript.\n",
    "\n",
    "Create 10 bullet points (each with an appropriate emoji) that summarize the key points or important moments from the video's transcription.\n",
    "\n",
    "In addition to the bullet points, extract the most important keywords and any complex words not known to the average reader aswell as any acronyms mentioned. For each keyword and complex word, provide an explanation and definition based on its occurrence in the transcription.\n",
    "\n",
    "Please ensure that the summary, bullet points, and explanations fit within the 330-word limit, while still offering a comprehensive and clear understanding of the video's content. Use the text above:\n",
    "\n",
    "Please, I need you to translate the answer into Portuguese!\n",
    "\n",
    "```\n",
    "{title}\n",
    "\n",
    "{transcription}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f43874-9312-422e-b4e7-9d86b261f9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.060147Z",
     "iopub.status.busy": "2024-10-06T15:56:22.059938Z",
     "iopub.status.idle": "2024-10-06T15:56:22.145121Z",
     "shell.execute_reply": "2024-10-06T15:56:22.144556Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.060128Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_audio(path, start_time, end_time, output_path):\n",
    "    audio = AudioSegment.from_file(path)\n",
    "    start_time_ms = start_time * 1000\n",
    "    end_time_ms = end_time * 1000\n",
    "    trimmed_audio = audio[start_time_ms:end_time_ms]\n",
    "    trimmed_audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "class YoutubeTranscripter:\n",
    "    def __init__(self, video_url, whisper_model):\n",
    "        self.video_url = video_url\n",
    "        self.whisper_model = whisper_model\n",
    "        self.metadata = None\n",
    "        self.title = None\n",
    "        self.label = None\n",
    "        self.language = None\n",
    "        self.chapters = None\n",
    "        self._temp_dir = tempfile.mkdtemp()\n",
    "        self._raw_video_path = None\n",
    "        self._video_parts_folderpath = None\n",
    "        self._audios_to_transcribe = []\n",
    "        self._transcripted_parts = None\n",
    "\n",
    "    def get_metadata(self):\n",
    "        ydl_opts = {\n",
    "            'skip_download': True,\n",
    "            'extract_flat': True,\n",
    "        }\n",
    "        \n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            self.metadata = ydl.extract_info(self.video_url, download=False)\n",
    "\n",
    "        self.title = self.metadata[\"title\"]\n",
    "        self.label = self.metadata[\"title\"].lower().replace(\" \",\"_\")\n",
    "        self.language = self.metadata[\"language\"]\n",
    "        self.chapters = self.metadata[\"chapters\"]\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        output_filename = f\"{self._temp_dir}/{self.label}\"\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'outtmpl': f'{output_filename}.%(ext)s',\n",
    "        }\n",
    "\n",
    "        self._raw_video_path = f'{output_filename}.mp3'\n",
    "        \n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([self.video_url])\n",
    "\n",
    "    def prepare(self):\n",
    "        if self.chapters:\n",
    "            self._video_parts_folderpath = self._raw_video_path.replace(\".mp3\", \"\")\n",
    "            pathlib.Path(self._video_parts_folderpath).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "            for i, c in enumerate(self.chapters):\n",
    "                print(f\"[splitting] - Part {i+1} - {c['title']}\")\n",
    "                output_path = f\"{self._video_parts_folderpath}/{str(i+1).zfill(4)}__{c['title']}__.mp3\"\n",
    "                cut_audio(self._raw_video_path, c[\"start_time\"], c[\"end_time\"], output_path)\n",
    "                c.update({\"audio_path\": output_path})\n",
    "                self._audios_to_transcribe.append(c)\n",
    "        else:\n",
    "            self._audios_to_transcribe.append(\n",
    "                {\n",
    "                    \"title\": self.title,\n",
    "                    \"audio_path\": self._raw_video_path,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def transcript(self):\n",
    "        response = []\n",
    "        for i, a in enumerate(self._audios_to_transcribe):\n",
    "            print(f\"[transcripting] - Part {i+1} - {a['audio_path']}\")\n",
    "            result = self.whisper_model.transcribe(a[\"audio_path\"], language=self.language)\n",
    "            a.update({\"transcription\": result})\n",
    "            response.append(a)\n",
    "        if not self._transcripted_parts:\n",
    "            self._transcripted_parts = response\n",
    "        return response\n",
    "            \n",
    "    def cleanup(self):\n",
    "        if self._temp_dir:\n",
    "            shutil.rmtree(self._temp_dir)\n",
    "            self._temp_dir = None\n",
    "            self._raw_video_path = None\n",
    "            self._video_parts_folderpath = None\n",
    "            self._audios_to_transcribe = []\n",
    "            print(\"Diretório temporário removido.\")\n",
    "\n",
    "    def summarize(self):\n",
    "        if not self._transcripted_parts:\n",
    "            self._transcripted_parts = self.transcript()\n",
    "\n",
    "        formatted_text = []\n",
    "        for i,r in enumerate(self._transcripted_parts):\n",
    "            chapter_text = dedent(f\"\"\"\n",
    "            ## {i+1}. {r['title']}\n",
    "            {r['transcription']['text']}\n",
    "            \"\"\")\n",
    "        \n",
    "            formatted_text.append(chapter_text)\n",
    "        \n",
    "        formatted_text = \"\\n\\n\".join(formatted_text)\n",
    "        \n",
    "        chain = self.set_chain()\n",
    "\n",
    "        response = chain.invoke({\"title\": self.title, \"transcription\": formatted_text})\n",
    "\n",
    "        return response\n",
    "\n",
    "    def set_chain(self):\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"title\", \"transcription\"], template=prompt_template\n",
    "        )\n",
    "        \n",
    "        \n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "        )\n",
    "        \n",
    "        return prompt | llm\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        self.get_metadata()\n",
    "        self.download()\n",
    "        self.prepare()\n",
    "        response = self.transcript()\n",
    "        self.cleanup()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3218ea-0cdc-4185-860a-2ce140352d64",
   "metadata": {},
   "source": [
    "# Transcrever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ef4d69-69f7-498a-b554-84147011a71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:58:42.111259Z",
     "iopub.status.busy": "2024-10-06T15:58:42.110954Z",
     "iopub.status.idle": "2024-10-06T16:00:26.599326Z",
     "shell.execute_reply": "2024-10-06T16:00:26.597800Z",
     "shell.execute_reply.started": "2024-10-06T15:58:42.111242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xGUHzRo81OM\n",
      "[youtube] xGUHzRo81OM: Downloading webpage\n",
      "[youtube] xGUHzRo81OM: Downloading ios player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading web creator player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xGUHzRo81OM\n",
      "[youtube] xGUHzRo81OM: Downloading webpage\n",
      "[youtube] xGUHzRo81OM: Downloading ios player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading web creator player API JSON\n",
      "[youtube] xGUHzRo81OM: Downloading m3u8 information\n",
      "[info] xGUHzRo81OM: Downloading 1 format(s): 251\n",
      "[download] Destination: /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.webm\n",
      "[download] 100% of   18.69MiB in 00:00:13 at 1.38MiB/s   \n",
      "[ExtractAudio] Destination: /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.mp3\n",
      "Deleting original file /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.webm (pass -k to keep)\n",
      "[transcripting] - Part 1 - /tmp/tmpuqmd9co7/top_10_atores_que_calaram_a_sua_boca_|_gaveta.mp3\n",
      "Diretório temporário removido.\n",
      "CPU times: user 1min 3s, sys: 539 ms, total: 1min 3s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "O vídeo \"Top 10 Atores que CALARAM a sua BOCA\" de Gaveta discute escolhas polêmicas de atores em papéis icônicos que inicialmente geraram desconfiança, mas que acabaram se mostrando excelentes. O apresentador compartilha sua experiência pessoal e opiniões sobre cada escolha, destacando como alguns atores, como Michael Keaton, Jennifer Lawrence e Heath Ledger, surpreenderam o público com suas atuações.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Escolher um ator para um papel é como escolher um ingrediente para uma receita: às vezes, o que parece uma combinação estranha pode resultar em um prato delicioso. Assim como um chef pode surpreender com uma mistura inesperada, um diretor pode encontrar um talento oculto em um ator que, à primeira vista, não parece se encaixar.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- 🎭 Michael Keaton como Batman: Inicialmente criticado, mas se tornou um ícone.\n",
       "- 🌟 Jennifer Lawrence como Katniss: Polêmica pela aparência, mas provou seu talento.\n",
       "- 🦸‍♂️ Chris Evans como Capitão América: Duvidado por seu passado cômico, mas se destacou.\n",
       "- 🎤 Lady Gaga em Nasce Uma Estrela: Surpreendeu com atuação dramática.\n",
       "- 🧛‍♂️ Tom Cruise como Lestat: Superou expectativas em Entrevista com o Vampiro.\n",
       "- 🐺 Hugh Jackman como Wolverine: Inicialmente criticado, mas se tornou o Wolverine definitivo.\n",
       "- 🔫 Daniel Craig como James Bond: Mudou a percepção do personagem para um tom mais realista.\n",
       "- 🎬 Ryan Reynolds como Deadpool: Superou a má impressão de sua primeira interpretação.\n",
       "- 🎥 Robert Pattinson como Batman: Provou ser um ator versátil após Crepúsculo.\n",
       "- 🃏 Heath Ledger como Coringa: Transformou a visão do personagem e ganhou um Oscar.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Polêmica**: Situação que gera controvérsia ou debate.\n",
       "- **Atuação**: A arte de interpretar um personagem em teatro, cinema ou televisão.\n",
       "- **Coringa**: Personagem icônico da DC Comics, conhecido por sua complexidade e vilania.\n",
       "- **Reboot**: Reinterpretação ou reinício de uma franquia, geralmente com novos atores ou diretores.\n",
       "- **Expectativa**: A crença ou esperança de que algo ocorrerá de uma certa maneira."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transcripter = YoutubeTranscripter(video_url=\"https://www.youtube.com/watch?v=xGUHzRo81OM\", whisper_model=model)\n",
    "response = transcripter.run()\n",
    "summary = transcripter.summarize()\n",
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75eaac-57de-453c-88e3-5014a2733f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860ec0b-36f5-48b8-8144-28dc63be7352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd5da68-40d4-46ca-8846-bc04f7684215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:56:22.145842Z",
     "iopub.status.busy": "2024-10-06T15:56:22.145690Z",
     "iopub.status.idle": "2024-10-06T15:56:56.567079Z",
     "shell.execute_reply": "2024-10-06T15:56:56.566177Z",
     "shell.execute_reply.started": "2024-10-06T15:56:22.145825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[info] MnBV8zLq-_Y: Downloading 1 format(s): 251\n",
      "[download] Destination: /tmp/tmpe_gg1glr/ansible_vault.webm\n",
      "[download] 100% of    5.05MiB in 00:00:04 at 1.23MiB/s   \n",
      "[ExtractAudio] Destination: /tmp/tmpe_gg1glr/ansible_vault.mp3\n",
      "Deleting original file /tmp/tmpe_gg1glr/ansible_vault.webm (pass -k to keep)\n",
      "[transcripting] - Part 1 - /tmp/tmpe_gg1glr/ansible_vault.mp3\n",
      "Diretório temporário removido.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "Ansible Vault é uma ferramenta de linha de comando que permite criptografar variáveis e arquivos sensíveis, garantindo que dados como credenciais de máquina não fiquem expostos em texto simples. O especialista Alex Dordjian explica como usar o Ansible Vault para proteger dados em repouso, criar e editar arquivos criptografados, e gerenciar diferentes cofres e senhas. Ele também destaca a importância de revisar playbooks para evitar a exposição acidental de dados sensíveis e fornece uma demonstração prática de como implementar o Ansible Vault.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Usar o Ansible Vault é como ter um cofre em casa: você pode guardar documentos importantes (dados sensíveis) dentro dele, mas ainda precisa ter cuidado ao abrir o cofre (executar playbooks) para não deixar informações à vista.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- 🔒 Ansible Vault é uma ferramenta de criptografia.\n",
       "- 🗝️ Permite proteger credenciais e arquivos sensíveis.\n",
       "- 📂 Suporta a criação e edição de arquivos criptografados.\n",
       "- 🔍 É importante revisar playbooks para evitar vazamentos de dados.\n",
       "- 🔑 Vários cofres e senhas podem ser gerenciados.\n",
       "- 🛠️ Funciona com Ansible Playbook e Ansible Navigator.\n",
       "- 📜 Oferece opções para visualizar e editar arquivos criptografados.\n",
       "- 🔄 Possui funcionalidade para reconfigurar senhas de criptografia.\n",
       "- 📚 Documentação disponível para guias e FAQs.\n",
       "- 💻 Demonstração prática de uso do Ansible Vault.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Ansible Vault**: Ferramenta de linha de comando para criptografar dados sensíveis.\n",
       "- **Criptografia**: Processo de codificar informações para proteger dados.\n",
       "- **Playbook**: Conjunto de instruções que o Ansible executa.\n",
       "- **Cofre**: Local seguro para armazenar informações sensíveis.\n",
       "- **Variáveis**: Elementos que armazenam dados que podem ser utilizados em scripts.\n",
       "- **Rekey**: Processo de alterar a senha de criptografia de um cofre.\n",
       "\n",
       "Essas definições ajudam a entender melhor os conceitos discutidos no vídeo e a importância do Ansible Vault na segurança de dados."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripter = YoutubeTranscripter(video_url=\"https://www.youtube.com/watch?v=MnBV8zLq-_Y\", whisper_model=model)\n",
    "response = transcripter.run()\n",
    "summary = transcripter.summarize()\n",
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce63361-a8b4-452c-902b-0333a7f97a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523633cf-42f2-4e17-88d5-fb3c9ac73b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71f90b-ce33-4ad6-a8dc-e53be6b5adb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927176e6-fcc6-4d37-9a75-e5b62bff6b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d8f557-9985-4676-8c98-1712492df9ce",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5aebde-2bf9-4f69-b669-18957624abe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:37:01.367364Z",
     "iopub.status.busy": "2024-10-06T15:37:01.367200Z",
     "iopub.status.idle": "2024-10-06T15:37:01.373474Z",
     "shell.execute_reply": "2024-10-06T15:37:01.373020Z",
     "shell.execute_reply.started": "2024-10-06T15:37:01.367349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## 1. Intro\n",
       " Hey Rilsen! Yeah? What is KnowledgeCraft? Do we need it to enhance our LLM performance? Oh, and also, do you know how to integrate it with Lanchain? Okay guys, hold on, take it easy. I will explain to you in detail step by step. Start from the theory, how to set up our Neo4j database, and then how to integrate it using Lanchain, and of course, all that we will use in open source LLM. So, without further ado, let's get started.\n",
       "\n",
       "\n",
       "\n",
       "## 2. What is Knowledge Graph?\n",
       " What is Nullesquas? Once upon a time, way back in 1736, there was a Swiss madwish named Leonard Ehler who faced a mind-bending challenge. The Southern Bridge of Gunsberg Problem. Is there a way to walk across all bridges once, starting and ending at the same place? Ehler realized something more crucial. What mattered was how things were connected. So it turned the city's landmark into dots or nodes and its bridges into lies or ages, creating a neat little network known as the origin of the graph theory. How we tying this overgraph, sped cold-up, instead of just building about landmarks and bridges, now, that's staying picky. So, in ancient, nodes ask the adjectives such as people, buildings, schools, bands, and many more, and that the ages as the relationship between them. For example, there is Amy working at a band and chatting away in Mandarin. Now, house and Brian, also a band-a-band who loves fried fries. Oh, there is also Anne, Brian's friend who is vanatig for fried fries too, and also flown in Mandarin. Sounds a bit tangled, right? But look at the graph we've got. Suddenly, it all starts to make sense. Now, with the idea of nodes and ages, entities and relationship, we have this final graph. But hey, let's get real. Our world is not just about Anne, Amy, and Brian. It's not just about bands and fried fries too, right? So, it's a vast thrill of people, teams, entities, and all of those have this special relationship. And that's what we call as a knowledge graph. So, once again, knowledge graph is a network of real-world entities and illustrates the relationship between them. All then, we store the knowledge graph in a graph database such as Neo4j database and process it using CypherQuery language. Neo4j's CypherQuery language includes clauses like use, match, read, return, and more. You can delve into them further with this Neo4j cheat sheet. Neo4j. Neo4j. talented ale. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Kraj. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j. Neo4j.\n",
       "\n",
       "\n",
       "\n",
       "## 3. Why is it important?\n",
       " Now, let's talk about how a knowledge graph empowers an ALANA. So using a knowledge graph, you can identify the links within a seemingly disconnected cut-set. What does it mean? So February 2024, researchers from Microsoft conducted a research to compare base retrieval augmented generation system, or RAC, and graph RAC. They used favorite incident information from a news article dataset and deposit equations. What has no furtherance yet done? The result, baseline RAC not able to answer it because sometimes using factor zero research is not always affected. Especially when the query does not provide enough context about its true intent, or when the context is fragment across large corpus of text. You probably have heard about plus in the middle things. And that's the problem. And they proved that graph RAC able to answer these questions because first, they were all search about the entities which has no forzea. This allows the LLM to grow itself and then provide a very detailed answer. In November 2023, there was also a research that showed how knowledge graph optimized the search in the SQL database. The researchers revealed that, when answering using GPT-4 with zero-shot prompts directly on SQL database achieves an accuracy of 16%. Notably, the accuracy increases 54% when questions are posed over a knowledge graph representation of the enterprise SQL database.\n",
       "\n",
       "\n",
       "\n",
       "## 4. Workflow\n",
       " Okay, so that's the reason why I learned knowledge graph for our LLAM is very interesting and important. And before we go into code, it's better for us to understand how it works. So first thing here, we will get the user question. And then we'll pass this user question to our LLAM. In this tab, our LLAM will also receive a database schema. Database schema means like the entities and relationship that we already store to our new 4G database. And the whole process in here, we call it as the graph chain. And then from the graph chain, it will generate a cipher query. And then we will run the cipher query to our new 4G database to get a result. And the result, we will pass it to the LLAM. In here, the LLAM will pass the result, we will create the result into our final answer. And in this tab, we will get the final one. Okay, thumbs to code.\n",
       "\n",
       "\n",
       "\n",
       "## 5. Code\n",
       " So actually all the code, the data I've already provided in this GitHub and I already put it in my description. So the first thing that we need to do is just to clone this. So just copy and then go to our VS code and do GitClone here. Okay guys, once done, our next step will be creating a virtual environment. So just go to our folder and then do pip install at this. It will take a few seconds, so I will skip this part. Now let's open the notebook that we have in here. So since we have already installed all the buttons in from the bit installable that we've just done before. So let's run this one. So in here, I'll go through, since we're going to use the open source LLAM, which is the Gemini. And then having Shays and also Neo4, so I'll go right now on how to get the ATI key for all this. But before that, we need to create a .eans as well to save the file variable and just... And then нужnen it. So go ahead. And see other\n",
       "\n",
       "\n",
       "\n",
       "## 6. Neo4J, Google Gemini, Hugging Face set up\n",
       " to this the google gemini api key so i will just go to this url and then already create api if you have it and for your hugging face just follow this link and then use new token but since i already have these tokens you just copy and then save the rnv variable and then for neo4g actually you can use my neo4g desktop or for this i'll use neo4g error which is a little bit simpler so if you have it gone you should sign up in here okay so the incident is ready and now like click open okay so in here we have the connection url in here we have the database user and also password make sure to also copy the connection url and the database username to the environment variable the dot answer file so right now just copy paste the password and click connect now the database is connected and now the next test is how to connect the python in here to the our database in the neo4g so actually langchain already provide us with a very simple connector which is this one langchain community to graphs neo4g.crown here so just click run it's all done okay\n",
       "\n",
       "\n",
       "\n",
       "## 7. Data Overview\n",
       " So we have done to set up everything. So now let's talk about the data itself. So the data that we will use in here, I will keep it simple. We won't process data from the unstructured format such as the PDF, the text file. Nope. But in here, we will use data from Kegel. So that's for Manus Kumar for providing this data set. So basically, it is a LinkedIn data set, professional information like the name, the CPM and current company that they work in the position and many more. And actually, here we did a little bit preprocessing to finally get this final data. The next.\n",
       "\n",
       "\n",
       "\n",
       "## 8. Insert Data to Neo4J\n",
       " thing is how to insert this data to Neo4j database. So as you can see here, since our data in Neo4j is still empty to node 0 and the relationship 0, and you can also check it by run to cell. You can see in here, there's nothing in here. So how to input it? So the first thing that we hear is by using the cipher query to interact with our database. So I'll explain one by one, start one here. Load CSV with headers from blah, blah, blah, blah. So actually, it's loading the CSV file from this GitHub repository. And then as we read the CSV file for each row, and in here, there's a cipher query inside. So we know that, okay, in here, name is the entity of name is person. So we make it to define the entity that we have in our database. So in here, it's a little bit different than the previous one, right? So basically, we use for each. Because if you see in the languages here, sometimes one people picks many languages, such as Roberto Mirola. He can speak English, Italian, France, Dutch, and German. So in here, we separate with this symbol. And this line is talking about the relationship. If you still remember about the explanation about relationship entity. So this one is the relationship or the ageist. Just run this one. Okay. And let's check it. Okay. So now our data is already in the Neo4j database. Check once again. Let's reload this. Okay. See? Now we have the company. Now we have educated ad, country industrial limits. All the data in from CSV is already imported in our Neo4j. Okay. Thanks, guys.\n",
       "\n",
       "\n",
       "\n",
       "## 9. Building a Graph Chain\n",
       " Hey guys, now let's talk about the most interesting part of this video. How to operate the large language model to interact with our knowledge graph in Neoprene. So in here, we are using chat Google generative AI, Gemini Pro is open source, and then the API ensures the parameter that we have saved before in .elv file, and in here, we set the temporary to . The question is, why are we not set it to 0.5 or 0.9? The reason is because in this task, we need the LLM not to do a creative writing, but we needed to translate the natural language to a cyber query language. And then here, the chain with the one chain with graph cyber QA chain. The line chain has provided it's very easy to use. So the graph is the graph that we have defined in here, and the LLM is the model that we want to use, and for both, I set it to be close to true. What does it mean? Because I want to understand what happened beyond LLM. So run this, and then in here, we have several questions. I've already created a table that contains the pair of the question and the correct answer, so it becomes easier for us to check whether the answer, resided from the LLM, is correct or not. We want to know how it's performed, so let's run it.\n",
       "\n",
       "\n",
       "\n",
       "## 10. Evaluation 1\n",
       " Okay, that's cool. Okay, so now let's talk about the result. So the first question, this will companies and advertising services industry. In here, it generates cyber and full contacts is said, and the result is toolbox creative, big advertising service enable. That's perfect. And the second question is, a worker you graduated from Cyberfresor University is currently employed at. Okay, I'm not sure why, but the general cyber query in here looks a little bit messy, and that's why there's a null in the context area. The result is I do not have the information we filmed here. And then the third question, where is POW looks working? Okay, so in here, the general cyber query is correct, and in the full contacts in here, toolbox creative is correct, but I don't know sure why, but then it's changing here as a result. I don't know the answer. The fourth question is, we see open here, which actually, if you remember about the schema of our database, the relationship, there's no spoken in in our database, right? So that's why it's null, and I don't have that information. The last one is, okay, the problem is the same, is native of. Actually, it's kind of huge needing about relationship, about the properties, about the entities, right? Because we don't have relationship is native of in our schema. So that's why it's also wrong. The answer is zero. The correct answer is one. Now, let's do a quick recap on the result that we have got before. So in here, we have two correct answer and three false answer from the LLM, right? And from this result, we can identify some problems. The first one is, not being able to accurately translate text into a cyber query. And the second one is, hallucinates properties, relationship, and entities. This one is one of the biggest problems of the LLM in-\n",
       "\n",
       "\n",
       "\n",
       "## 11. Prompting Strategies\n",
       " generating a cyber query. So, what is the solution? We call it as prompting strategies. So, in short, we provide examples to our model to help it understand the structure correctly, similar to how pairs guide us when we learn to work, right? More examples makes the models learn and smarter. Now, let's jump to a code. So, the first thing that we need to do is to create pairs of questions and cyber query. So, I won't do it manually. Just copy this and paste the objectivity. Okay, once we got a result, so just copy and paste it to our Facebook, for example, in here. I want to copy these questions. And the most important part is to create text once again. If the general query from the JetsBD is already correct or not, we can do this by go to our Neo4j copy, paste, and text. Okay, good. We have this name, Pakusatya. So, if the general cyber query is correct, just do all that and copy and paste it here. The last thing that you need to do is to add places in here, because if you don't do it, you will not get it. I've already have this one, so I won't use it. I'll use mine to just run this. And in here, actually, LangChain already provide us with a free shot prompt template. And so, prompt template is just the prompt that we want to use, that we will use as a parameter in here. And the example, this is a sample that we have already divided in here. So, it will take the top three examples from it. And then the perfect self-ex, and here is the input variables, which is question and schema. We'll use the question and this, and the schema is here. So, run this one. This is an example of the prompt. Let's create our second chain. And check this one. All right.\n",
       "\n",
       "\n",
       "\n",
       "## 12. Evaluation 2\n",
       " For the first question, the answer is correct. Toolbox Creative, Big Advertising Suit Into People's Tool. And for the second question, we get the correct answer which is Elastic Pet. And in here, we got Toolbox Creative. For the fourth question, Degenerative Cypher Quares is also correct and we get here Vitaly New Hint. And then for the last one, okay, we got the correct answer though which is one. So using the problem strategies will enhance our model. Right now, we have all correct answer.\n",
       "\n",
       "\n",
       "\n",
       "## 13. Bonus ( How to Create a Dynamic Prompt? )\n",
       " Okay guys, our job is done, but as I've told you before, that I have a bonus for you. So, if you're still a member, we have this question. Where do Michael work? And the problem that we got is, which workers are friends. What industries are workers named animal associated with and which workers live in Canada and speak German? So I have a choice, there's no correlation, right? Between which workers speak friends and where do Michael work? And the reason is this line. So in here, we are taking top three from this list. In fact, we have more than three questions. So what's the point to just only take this top three? And that's why we need a dynamic problem. So to create a dynamic problem, we need a semantic similarity example selector. So basically, if you calculate which one is the closest between the question and the list that we have. So the first one that you need is the hacking phase embeddings and then the neo-forged factor. So previously, we are taking the top three questions from the examples list. Now, we will use the example selector to create a dynamic problem. If we run this. So, where do Michael work? What companies do workers named John work in? It makes sense. Where do workers named Alice live? And what industries are workers named Emily associated? So right now, the generative problem is more dynamic and we're not just the top.\n",
       "\n",
       "\n",
       "\n",
       "## 14. Outro\n",
       " to read from our list.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "formatted_text = []\n",
    "for i,r in enumerate(response):\n",
    "    chapter_text = dedent(f\"\"\"\n",
    "    ## {i+1}. {r['title']}\n",
    "    {r['transcription']['text']}\n",
    "    \"\"\")\n",
    "\n",
    "    formatted_text.append(chapter_text)\n",
    "\n",
    "formatted_text = \"\\n\\n\".join(formatted_text)\n",
    "\n",
    "Markdown(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd435519-8a77-40d6-abca-80359e6f903c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:03.129468Z",
     "iopub.status.busy": "2024-10-06T15:39:03.129141Z",
     "iopub.status.idle": "2024-10-06T15:39:03.132967Z",
     "shell.execute_reply": "2024-10-06T15:39:03.132503Z",
     "shell.execute_reply.started": "2024-10-06T15:39:03.129446Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\" Your output should use the following template:\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Analogy\n",
    "\n",
    "### Notes\n",
    "\n",
    "- [Emoji] Bulletpoint\n",
    "\n",
    "### Keywords\n",
    "\n",
    "- Explanation\n",
    "\n",
    "You have been tasked with creating a concise summary of a YouTube video using its transcription.\n",
    "\n",
    "Make a summary of the transcript.\n",
    "\n",
    "Additionally make a short complex analogy to give context and/or analogy from day-to-day life from the transcript.\n",
    "\n",
    "Create 10 bullet points (each with an appropriate emoji) that summarize the key points or important moments from the video's transcription.\n",
    "\n",
    "In addition to the bullet points, extract the most important keywords and any complex words not known to the average reader aswell as any acronyms mentioned. For each keyword and complex word, provide an explanation and definition based on its occurrence in the transcription.\n",
    "\n",
    "Please ensure that the summary, bullet points, and explanations fit within the 330-word limit, while still offering a comprehensive and clear understanding of the video's content. Use the text above:\n",
    "\n",
    "Please, I need you to translate the answer into Portuguese!\n",
    "\n",
    "```\n",
    "{title}\n",
    "\n",
    "{transcription}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"title\", \"transcription\"], template=prompt_template\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8adfdb3-203a-4f25-a348-8a414f5faf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:05.246826Z",
     "iopub.status.busy": "2024-10-06T15:39:05.246519Z",
     "iopub.status.idle": "2024-10-06T15:39:05.295897Z",
     "shell.execute_reply": "2024-10-06T15:39:05.295405Z",
     "shell.execute_reply.started": "2024-10-06T15:39:05.246802Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "526ebac5-6174-4da4-95e8-3eba05e066de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:06.755486Z",
     "iopub.status.busy": "2024-10-06T15:39:06.755296Z",
     "iopub.status.idle": "2024-10-06T15:39:14.210141Z",
     "shell.execute_reply": "2024-10-06T15:39:14.207848Z",
     "shell.execute_reply.started": "2024-10-06T15:39:06.755471Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = chain.invoke({\"title\": transcripter.title, \"transcription\": formatted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1936f84-aa1b-483b-91e0-49081b1ff027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:39:14.222765Z",
     "iopub.status.busy": "2024-10-06T15:39:14.217970Z",
     "iopub.status.idle": "2024-10-06T15:39:14.228998Z",
     "shell.execute_reply": "2024-10-06T15:39:14.228188Z",
     "shell.execute_reply.started": "2024-10-06T15:39:14.222275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Resumo\n",
       "\n",
       "O vídeo apresenta um tutorial sobre como integrar um gráfico de conhecimento com modelos de linguagem de grande porte (LLMs) usando Python. O apresentador explica a teoria por trás dos gráficos de conhecimento, como configurar um banco de dados Neo4j e integrá-lo com a biblioteca LangChain. O vídeo também discute a importância dos gráficos de conhecimento para melhorar a precisão das respostas dos LLMs, demonstrando como eles podem identificar conexões em conjuntos de dados aparentemente desconectados.\n",
       "\n",
       "### Analogia\n",
       "\n",
       "Integrar um gráfico de conhecimento a um LLM é como usar um mapa detalhado para navegar em uma cidade desconhecida. Sem o mapa, você pode se perder em ruas e avenidas, mas com ele, você pode encontrar o caminho mais eficiente e descobrir conexões que não seriam visíveis à primeira vista.\n",
       "\n",
       "### Notas\n",
       "\n",
       "- 🧠 O que é um gráfico de conhecimento? É uma rede de entidades do mundo real e suas relações.\n",
       "- 📊 Importância: Gráficos de conhecimento ajudam LLMs a responder perguntas complexas com mais precisão.\n",
       "- 🔗 Conexões: Eles identificam links em conjuntos de dados desconectados, melhorando a compreensão do contexto.\n",
       "- 💻 Configuração: O vídeo ensina a configurar um banco de dados Neo4j e a usar a linguagem Cypher.\n",
       "- 📈 Resultados: Pesquisas mostram que o uso de gráficos de conhecimento aumenta a precisão das respostas dos LLMs.\n",
       "- 🔄 Workflow: O processo envolve receber perguntas, gerar consultas Cypher e retornar resultados.\n",
       "- 📚 Exemplos: O apresentador usa um conjunto de dados do LinkedIn para demonstrar a inserção e consulta de dados.\n",
       "- ⚙️ Estratégias de Prompt: Exemplos ajudam os modelos a entender melhor a estrutura das consultas.\n",
       "- 🔍 Avaliação: O vídeo mostra como avaliar a precisão das respostas geradas pelos LLMs.\n",
       "- 🎁 Bônus: O apresentador oferece dicas sobre como criar prompts dinâmicos para melhorar a interação.\n",
       "\n",
       "### Palavras-chave\n",
       "\n",
       "- **Gráfico de Conhecimento**: Uma representação de entidades e suas relações no mundo real.\n",
       "- **Neo4j**: Um banco de dados orientado a grafos que armazena dados em forma de nós e arestas.\n",
       "- **Cypher**: A linguagem de consulta usada para interagir com o banco de dados Neo4j.\n",
       "- **LLM (Modelo de Linguagem de Grande Porte)**: Modelos de inteligência artificial que processam e geram texto em linguagem natural.\n",
       "- **LangChain**: Uma biblioteca que facilita a integração de LLMs com bancos de dados e outras fontes de dados.\n",
       "\n",
       "Essas definições ajudam a entender os conceitos discutidos no vídeo e sua aplicação prática."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcf757-89eb-4842-84e6-af7d94fc16bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fae43-aeab-4d2f-9bc8-3cf9a7e2b639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc4ea2-4c85-4b6f-9120-fc2197d5589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2d751-4c8e-4b97-8c04-790cd1b2cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7b518-7941-4f05-86c1-c01d96512869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6318596-440c-45d0-9576-b4a143504bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f55465f-fe5c-43e0-b95a-bc9a8e2da90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:29:17.120964Z",
     "iopub.status.busy": "2024-10-06T15:29:17.120628Z",
     "iopub.status.idle": "2024-10-06T15:29:17.477307Z",
     "shell.execute_reply": "2024-10-06T15:29:17.476688Z",
     "shell.execute_reply.started": "2024-10-06T15:29:17.120940Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formatted_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mformatted_text\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'formatted_text' is not defined"
     ]
    }
   ],
   "source": [
    "formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf8e2d9-64bc-4596-99f2-413983fdd0d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:22:56.199454Z",
     "iopub.status.busy": "2024-10-06T15:22:56.199184Z",
     "iopub.status.idle": "2024-10-06T15:22:57.391307Z",
     "shell.execute_reply": "2024-10-06T15:22:57.389030Z",
     "shell.execute_reply.started": "2024-10-06T15:22:56.199429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848a4e5-3605-4711-bb73-9fe2d9eb8232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4f99c-f5d9-4809-b09d-b98f23ec32d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931dc9d-d84c-40db-8bc4-1aff9e70525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c57ebb-12f4-4d79-b925-ec4cb21d9b5e",
   "metadata": {},
   "source": [
    "### [Extra] - Informações e Metadadaos sobre vídeos do Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581c2422-c39f-4014-8d46-898275c794fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:03.531515Z",
     "iopub.status.busy": "2024-10-06T02:14:03.531254Z",
     "iopub.status.idle": "2024-10-06T02:14:03.534685Z",
     "shell.execute_reply": "2024-10-06T02:14:03.534321Z",
     "shell.execute_reply.started": "2024-10-06T02:14:03.531500Z"
    }
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def get_youtube_video_metadata(video_url):\n",
    "    ydl_opts = {\n",
    "        'skip_download': True,  # Não baixa o vídeo\n",
    "        'extract_flat': True,   # Não extrai streams de mídia, só metadados\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4341c3-332e-4eee-957e-386757baa3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:05.693631Z",
     "iopub.status.busy": "2024-10-06T02:14:05.693450Z",
     "iopub.status.idle": "2024-10-06T02:14:12.008286Z",
     "shell.execute_reply": "2024-10-06T02:14:12.005844Z",
     "shell.execute_reply.started": "2024-10-06T02:14:05.693617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading player 96d06116\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n"
     ]
    }
   ],
   "source": [
    "video_metadata = get_youtube_video_metadata(VIDEO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04889a40-1e9a-48cc-9383-e06000dabf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:14:12.013412Z",
     "iopub.status.busy": "2024-10-06T02:14:12.012661Z",
     "iopub.status.idle": "2024-10-06T02:14:12.031044Z",
     "shell.execute_reply": "2024-10-06T02:14:12.030591Z",
     "shell.execute_reply.started": "2024-10-06T02:14:12.013338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec51b4b7-6707-4374-92d4-70400bc81537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:01.354156Z",
     "iopub.status.busy": "2024-10-06T02:15:01.353899Z",
     "iopub.status.idle": "2024-10-06T02:15:01.357036Z",
     "shell.execute_reply": "2024-10-06T02:15:01.356601Z",
     "shell.execute_reply.started": "2024-10-06T02:15:01.354140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title = ansible_vault\n",
      "language = en\n"
     ]
    }
   ],
   "source": [
    "title = video_metadata[\"title\"].lower().replace(\" \",\"_\")\n",
    "language = video_metadata[\"language\"]\n",
    "\n",
    "print(f\"title = {title}\")\n",
    "print(f\"language = {language}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4b2a1-990a-424a-94c8-fd06c6c6800e",
   "metadata": {},
   "source": [
    "# Download audio from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1230f01-0221-4f76-86b0-c5e895891712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:04.627550Z",
     "iopub.status.busy": "2024-10-06T02:15:04.627298Z",
     "iopub.status.idle": "2024-10-06T02:15:16.718774Z",
     "shell.execute_reply": "2024-10-06T02:15:16.718372Z",
     "shell.execute_reply.started": "2024-10-06T02:15:04.627535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MnBV8zLq-_Y\n",
      "[youtube] MnBV8zLq-_Y: Downloading webpage\n",
      "[youtube] MnBV8zLq-_Y: Downloading ios player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading web creator player API JSON\n",
      "[youtube] MnBV8zLq-_Y: Downloading m3u8 information\n",
      "[info] MnBV8zLq-_Y: Downloading 1 format(s): 251\n",
      "[download] Destination: data/ansible_vault_raw.webm\n",
      "[download] 100% of    5.05MiB in 00:00:04 at 1.02MiB/s   \n",
      "[ExtractAudio] Destination: data/ansible_vault_raw.mp3\n",
      "Deleting original file data/ansible_vault_raw.webm (pass -k to keep)\n",
      "CPU times: user 409 ms, sys: 66.7 ms, total: 476 ms\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_filename = f\"data/{title}_raw\"\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'{output_filename}.%(ext)s',\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6d69b-e69f-488c-a6fd-1fe65d5d7a17",
   "metadata": {},
   "source": [
    "As informações disponíveis são:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52507359-e44b-4e13-83d2-fa32a7b279ae",
   "metadata": {},
   "source": [
    "# Cortar audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfde451-ff29-4f82-9d7c-d86f1ead2b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T02:15:17.699457Z",
     "iopub.status.busy": "2024-10-06T02:15:17.699270Z",
     "iopub.status.idle": "2024-10-06T02:15:18.258093Z",
     "shell.execute_reply": "2024-10-06T02:15:18.257365Z",
     "shell.execute_reply.started": "2024-10-06T02:15:17.699441Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/output_audio.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 7\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m start_time_ms \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     10\u001b[0m end_time_ms \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/output_audio.mp3'"
     ]
    }
   ],
   "source": [
    "raw_filename = \"data/raw_audio.mp3\"\n",
    "output_filename = \"data/output_audio.mp3\"\n",
    "start_time = 0\n",
    "end_time = 10\n",
    "\n",
    "\n",
    "audio = AudioSegment.from_file(output_filename)\n",
    "\n",
    "start_time_ms = start_time * 1000\n",
    "end_time_ms = end_time * 1000\n",
    "trimmed_audio = audio[start_time_ms:end_time_ms]\n",
    "trimmed_audio.export(output_filename, format=\"mp3\")\n",
    "print(f\"Áudio recortado salvo em: {output_filename}\")\n",
    "\n",
    "Audio(output_filename, autoplay=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd8ac0-c666-41cb-8a18-17a7b8cf4c47",
   "metadata": {},
   "source": [
    "# Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f784b4-9b26-41f8-9044-b8d9a376237b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:13:27.817946Z",
     "iopub.status.busy": "2024-09-23T13:13:27.817109Z",
     "iopub.status.idle": "2024-09-23T13:13:27.823544Z",
     "shell.execute_reply": "2024-09-23T13:13:27.823179Z",
     "shell.execute_reply.started": "2024-09-23T13:13:27.817871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f8040f-19be-4130-8c93-4bdaffce91d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:13:29.228249Z",
     "iopub.status.busy": "2024-09-23T13:13:29.227347Z",
     "iopub.status.idle": "2024-09-23T13:13:46.558383Z",
     "shell.execute_reply": "2024-09-23T13:13:46.557846Z",
     "shell.execute_reply.started": "2024-09-23T13:13:29.228149Z"
    }
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "232aa0bc-e531-4318-b5c9-785caedd9707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T13:37:27.420378Z",
     "iopub.status.busy": "2024-09-23T13:37:27.420223Z",
     "iopub.status.idle": "2024-09-23T13:40:09.490762Z",
     "shell.execute_reply": "2024-09-23T13:40:09.490296Z",
     "shell.execute_reply.started": "2024-09-23T13:37:27.420365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My name is Alex Dorjson. I'm an Ansible Solutions Specialist and today I'm going to be talking about Ansible Vault and what it can be used for. So first let's talk about what Ansible Vault is. Ansible Vault is just a command line utility that's installed as part of Ansible that provides a way for you to encrypt different variables and files. So now I don't have to worry about my sensitive data being out there in plain text. Many cases I see this used to protect different machine credentials, some of your hosts and group files, especially if I'm connecting to other utilities or APIs and I can use this to encrypt just individual strings or entire files. I'll personally say I generally use entire files rather than strings just because it's easier to maintain and easier to rekey if I need to. So important reminder, this is only designed to protect data at rest. So obviously if I'm trying to use this in a standard variable and I have a debug statement in my playbook I can still print out that data so it's important to make sure that a a is a string, and b is a variable. So I'm going to use this as my default variable and I'm going to use it for the way that you're reviewing your playbooks, making sure I'm doing things properly, or using the no-log module when it's required for different aspects of what I'm trying to do. I can also set up different vaults and different passwords and better access control over these different vaults. So I can have certain data in some vaults, certain data in other vaults to really lock down who can get access to what different variables. So how does it work? So Ansible Vault is a command line option. I've got a bunch of different things that I can do. So I can either use it to create an initial file and encrypt it with that password. I can also just encrypt an existing file. So maybe you already have group files created and I want to encrypt those. Maybe I need to decrypt them back to our normal text file to do some editing. Obviously I can just do Ansible Vault and edit to edit that particular file. Or if I just want to see the content that's there I can use Ansible Vault view. And then as I talked about earlier, you know, maybe someone did get access to my Ansible Vault password for some reason. I can do Ansible Vault rekey to change that encryption password. So it gives me a very easy way to create and edit these different files really depending on what your needs are. So then when I'm actually running playbooks, again, I can use this to, you know, whether it's with Ansible Playbook or Ansible Navigator, I can use Ansible Vault with that. So with Ansible Playbook, I can use different options, you know, such as ask vault pass or the vault password file. If I've got, as I said, multiple vaults, I can use that vault ID. For Ansible Navigator, I will need to either use a vault password or a vault password. For Ansible Navigator, I will need to either use a vault password or a vault password. So I can either use a vault password file and provide that in my Ansible config or I can use environmental variables for that. It doesn't have the ask options, just a limitation of Ansible Navigator. But personally, I still use Ansible Vault for all of my connection variables that I run from CLI. So let's jump into a demonstration to see how I can use Ansible Vault for different files. Now let's jump into actually using Ansible Vault. So as you can see, I already have a few files here. I have a very basic playbook that will actually go through the process of debugging out of your variable that I'm going to create. I've got an empty group vars folder, which is where I'll put all my connection variables. And then I have, you know, a password file that I'll use in just a second. So in this case, I do want to do Ansible vault and I want to create a new file, but I want this to be in my group vars and I want this to apply for all different hosts in my inventory. In this case, I'm just going to run this on local hosts, but I still want to leverage that vault message variable. So when I try to create this file, it will ask me for a vault password. And now I can create that vault message and I can just call it whatever I want. This is a new vault message. Save it. And as you notice, if I try to view that particular file, it is now encrypted. So I do already have an existing password file and maybe I just want to encrypt this existing file. So I can do Ansible vault encrypt that password file and once again, have the option to assign it a vault password and now that file is encrypted. I can do Ant National Vault Decrypt or I can do an absolute edit that password file. It will require obviously the vault password to jump in and I can edit that particular file using my default editor or I can do Ansible vault view. And now I can go to this backup page that I've built in there. And it's pretty interesting. This new vault password file will have that view for any customers. This is like a very specific file you should雅 view once again asking me for that password and I can just see so similar to just you know running a cat on that command or I could do decrypt to decrypt that particular file I can also do rekey to change the vault password this really gives me that full capability to use Ants with vault to make changes to different files or strings so maybe I now actually want to run this particular playbook using that variable that I set up before so in this case I'm just gonna use Ansible navigator I mean Ansible playbook to do it so I'll do Ansible playbook in this case I want to ask for that vault pass and I'll use that debug.yaml and as you can see it did this is a new vault message which is that vault password that I had set up previously do I use ansible vault regularly absolutely yes so this is VS code where I do most my playbook editing and I am running Ansible playbook and I'm running Ansible playbook and I'm running Ansible playbook and I'm running Ansible navigator so as you can see I have an inventory here obviously I've got you know multiple different groups and variables so for you know again my higher level all variables I had that encrypted using Ansible vault same thing for my individual group level variables so it's important to note for Ansible navigator yes I can use Ansible vault but I either have to store that vault password somewhere securely on the file system or I can store that vault password in an environmental variable for me I've got it stored locally on my file system and I just have my Ansible config pointing to that particular vault password so in my case I've got it stored very securely and then I have a link back to that particular file in my current working directory Ansible navigator docs will have that information for you and I will paste that in the description down below so where can you go from here I'll include in the description down below a basic walkthrough of Ansible vault using a blog very similar to what I just walked through here also the Ansible vault docs has all the information on the specific key requirements if you want to use a vault ID so this gives you the capability to have multiple vaults within a single playbook run so again as I talked about with role based access control is trying to limit who gets access to what vaults I can have that capability and then there's also an FAQ that walks into how I can use Ansible vault with Ansible navigator which is what I do today so thank you for taking the time to learn a little bit more about how Ansible vault can be utilized to provide some at-rest encryption for my different passwords and keys thank you\n",
      "CPU times: user 2min 42s, sys: 358 ms, total: 2min 43s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_filename = f\"data/{title}_raw.mp3\"\n",
    "\n",
    "result = model.transcribe(audio_filename, language=language)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836999fd-4250-4a15-a8b8-892c46e94f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a2fe2-7050-44fd-8ad5-1332d85677ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dcf6859-65ac-4604-9d03-24219d1216e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vamos pro jogo das frases, jogam um ande-marcão. Nesse jogo, vocês escreveram frases lá fora e elas estão nessa caixa. Cada um vai pegar duas frases e colocar no bolso. Durante a cena, eles tiram essa frase e lêm a frase, mas não basta ler. Tem que justificar a frase dentro da cena já começada. E a cena leva o título de Eu Queria Voar. E o jogo das frases começa agora. Jinoveva, volta pro poleiro! Eu sei por que você tá aí fora! Por quê? Eu vi você ontem à noite acordado olhando as corujas de um lado pro outro. Até os morcegos você ficou olhando. Os morcegos, eles parecem ratos, não sabe o que eles fazem. Eles vão, Jinoveva, eu sei. Eles vão... Aceitam como você é, Jinoveva, e outra coisa. Acho que esqueci o ferro ligado. Só um minuto. Isso, vai lá! Vai que o CIRAM vai queimar! Vai queimar tudo que... Agora... É que agora é a chocadeira, eu deixo o ferrinho do lado da chocadeira. Mais fácil do que eu ficar. Tem mais o que fazer. Rebeca, você tem que ter mais ambição. Bicou caovos e fica se escancando. É a natureza, é minha natureza, é como eu sou. A natureza é todo o potencial que a gente pode explorar, e a gente pode ser muito mais do que isso. Galinhas podem... Aqui não tem farol, aqui é rotatória. O meu norte é um giro infinito. Foi o melhor que eu pude fazer. Olha isso! Você tentando voar é a vida te dando farol vermelho! E como numa rotatória você tá em círculos! Tem que acreditar! Rebeca, tem que acreditar! Você quer acreditar? Vamos lá fora! Pau! Uau! Uau, que urubuzão! Oi, urubu! Ouro com o Antonio! Fiquei sabendo que uma de vocês está interessada em voar. Eu tenho aqui exatamente o que você precisa. O negócio que vai fazer você chegar nas estrelas, se é que você me entende. Isso daqui vai te fazer ir pras nuvens, cara. O preço disso são 10 ovos. 10 ovos, isso é pra minha fichinha. Não, não, não, não, não! E você vai ver estrela com isso? É de fazer o quê? É de voar! Ok, eu topo! Nada mais imponente que um sonho a ser realizado. Toma os seus ovos. Se alguém perguntar se eu te vendi isso, isso nunca aconteceu antes. Ok, os ovos estavam no meu suvaco, pode levar... Vai, urubu! Ah! Deixa lá, que barulho eu faço, urubu! Ah! Ah! Fui no mangue catalixo, eu quero conversar com o urubu! Comercer com o urubu! Comercer com o urubu! Olha, ele deu um... Ele deu um ódio! Eu não sei, mas se o delegalo vem, ele vai ficar... Não fala pra um delegalo! Ele vai ficar bom! Ai, meu Deus! O seu delegalo! Não tem nada acontecendo aqui, outra coisa! Estou à beira de um ataque cego! Ah! Não tem nada de errado acontecendo aqui! Ah! Ah! Vou levar pro ferrinho quente! Ah! Tinha um novo verbo, deu uma coisa estranha aqui! Ah! Delegalo, eu só quero voar! Eu só quero voar, delegalo! Ah! Na minha número de estritos, o Galinha não voa! Até provaram que a terra era redonda, todo mundo acreditava que ela era plana, entende? Já tem gente que duvida! Delegalo! Nada vai me impedir! Galinha, par com isso! A sua vida é uma linha reta pra ter faróis, é uma rotatória! Você tem que continuar por aqui! Oh! Ah! Ah! Ah! Oh, meu Deus! Ah! Oh, mortal! É o Boel! É o Boel! Afial de Contas! Uma galinha! Hoje é dia de comer feijão! Caraca! Gente, assim... Eu tava vendo o avião tentando levantar com um motor de corsa! Que fique claro que eu cortei o carboidrato! Nós somos os barbichas, obrigado por assistir o nosso vídeo! Se você gostou, inscreva-se no nosso canal, compartilhe esse vídeo! Se você não gostou, assiste algum outro vídeo, até você achar o que você gosta! Aí você compartilha, se inscreve e dá like no vídeo! Se não gostar de nenhum, nenhum assim, não teve nenhum! Aí compartilha igual, só que falando, meu Deus do céu, vergonha nacional! Onde é civil, limite do humor! Testão, testão, testão! Boa! Viraliza até mais, né?\n",
      "CPU times: user 43.4 s, sys: 503 ms, total: 43.9 s\n",
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "audio_filename = \"data/raw_audio.mp3\"\n",
    "\n",
    "model = whisper.load_model(\"small\").to(device)\n",
    "result = model.transcribe(audio_filename, language=\"pt\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95f1cd-ca8c-4c7c-ab48-6a3b277fe0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a5913-8ae5-4202-954b-be5b404831d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2b6fc-62db-4c72-ac8e-0654d2ff8d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e5cef-13cb-4f47-a2ea-14f828435bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67abc23-cb7d-4c1b-8521-22c12890f230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e9ff6-1000-4d4f-873d-3ba98f253af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086c863-94d2-453a-b283-5ae667e3194d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2ba4ee-7a76-463f-a6fa-c2ca84fec4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: pt\n",
      "candidato Pablo Maisal, se a cidade tá mal, relaxe e vote Pablo Maisal. Pegou a 100 installership, se é uma corrida eleitoral\n",
      "CPU times: user 2.3 s, sys: 8.69 ms, total: 2.31 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"data/output_audio.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(language=\"pt\")\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f53ea-ee3f-4329-8e91-77af76439aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5924657-a0df-4dad-9520-c49a42ccd249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T13:37:10.248954Z",
     "iopub.status.busy": "2024-10-06T13:37:10.248761Z",
     "iopub.status.idle": "2024-10-06T13:37:10.252508Z",
     "shell.execute_reply": "2024-10-06T13:37:10.252143Z",
     "shell.execute_reply.started": "2024-10-06T13:37:10.248937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a network graph maker who extracts terms and their relations from a given context. You are provided with a context chunk (delimited by ```) Your task is to extract the ontology of terms mentioned in the given context. These terms should represent the key concepts as per the context. \n",
      "Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\n",
      "\tTerms may include object, entity, location, organization, person, \n",
      "\tcondition, acronym, documents, service, concept, etc.\n",
      "\tTerms should be as atomistic as possible\n",
      "\n",
      "Thought 2: Think about how these terms can have one on one relation with other terms.\n",
      "\tTerms that are mentioned in the same sentence or the same paragraph are typically related to each other.\n",
      "\tTerms can be related to many other terms\n",
      "\n",
      "Thought 3: Find out the relation between each such related pair of terms. \n",
      "\n",
      "Format your output as a list of json. Each element of the list contains a pair of termsand the relation between them, like the follwing: \n",
      "[\n",
      "   {\n",
      "       \"node_1\": \"A concept from extracted ontology\",\n",
      "       \"node_2\": \"A related concept from extracted ontology\",\n",
      "       \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\"\n",
      "   }, {...}\n",
      "]\n",
      "\n",
      "context: ```\n",
      "A receita recorrente é um faturamento contínuo que uma empresa recebe ao vender produtos e serviços por meio do modelo de assinatura ou plano, que gera uma mensalidade para o cliente fazer o pagamento todo mês.\n",
      "\n",
      "Esse formato de contrato com os clientes é bastante utilizado principalmente por empresas de Software as a Service (SaaS) e por aquelas que comercializam produtos e serviços com demanda contínua.\n",
      "\n",
      "Com a adoção desse modelo, as empresas buscam uma maior previsibilidade de receita para o caixa da companhia, a receita previsível, por saberem ao certo quanto entrará de faturamento ao longo dos meses.\n",
      "\n",
      "A receita previsível permite um melhor planejamento financeiro e maior controle das demandas futuras, facilitando o processo de produção e gestão dos negócios.\n",
      "\n",
      "Quando se tem uma estimativa de demanda que precisa ser atendida mês a mês, há uma melhor organização do processo produtivo para atender essa demanda na medida certa, sem desperdício de recursos, o que impacta também numa melhor gestão empresarial.\n",
      "\n",
      "Por isso, para quem utiliza esse modelo, é fundamental a compreensão destes dois conceitos: receita recorrente mensal e receita recorrente anual.\n",
      "``` \n",
      "\n",
      " output: \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db54703-50f2-47fa-a3d4-f1615f71edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
