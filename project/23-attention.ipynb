{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f0b627-c0af-418f-967b-210835a2d6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:58:27.142211Z",
     "iopub.status.busy": "2024-09-15T23:58:27.141553Z",
     "iopub.status.idle": "2024-09-15T23:58:28.681996Z",
     "shell.execute_reply": "2024-09-15T23:58:28.681337Z",
     "shell.execute_reply.started": "2024-09-15T23:58:27.142181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56764ffc-28b2-4be5-8cd1-c8725fef6bdb",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2dd3d70-5682-4229-9ac8-21cee59c9855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:41:35.308748Z",
     "iopub.status.busy": "2024-09-16T01:41:35.308188Z",
     "iopub.status.idle": "2024-09-16T01:41:35.312641Z",
     "shell.execute_reply": "2024-09-16T01:41:35.312064Z",
     "shell.execute_reply.started": "2024-09-16T01:41:35.308716Z"
    }
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def get_youtube_video_title(url):\n",
    "    ydl_opts = {}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        video_title = info_dict.get('title', None)\n",
    "    return video_title\n",
    "\n",
    "def get_youtube_video_metadata(video_url):\n",
    "    ydl_opts = {\n",
    "        'skip_download': True,  # Não baixa o vídeo\n",
    "        'extract_flat': True,   # Não extrai streams de mídia, só metadados\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "    return info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef91b04b-62d6-460e-9472-6336a2fb1984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:58:33.220164Z",
     "iopub.status.busy": "2024-09-15T23:58:33.219522Z",
     "iopub.status.idle": "2024-09-15T23:58:33.226347Z",
     "shell.execute_reply": "2024-09-15T23:58:33.225342Z",
     "shell.execute_reply.started": "2024-09-15T23:58:33.220092Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00c3301a-820d-4993-817d-37f30375ce99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:41:52.687272Z",
     "iopub.status.busy": "2024-09-16T01:41:52.687040Z",
     "iopub.status.idle": "2024-09-16T01:41:55.240403Z",
     "shell.execute_reply": "2024-09-16T01:41:55.239833Z",
     "shell.execute_reply.started": "2024-09-16T01:41:52.687257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tvIzBouq6lk\n",
      "[youtube] tvIzBouq6lk: Downloading webpage\n",
      "[youtube] tvIzBouq6lk: Downloading ios player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading web creator player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading m3u8 information\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "video_url = 'https://www.youtube.com/watch?v=tvIzBouq6lk'\n",
    "\n",
    "video_metadata = get_youtube_video_metadata(video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f44d2ebe-2545-4918-87a1-690670cc8da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:42:00.397142Z",
     "iopub.status.busy": "2024-09-16T01:42:00.396951Z",
     "iopub.status.idle": "2024-09-16T01:42:00.400109Z",
     "shell.execute_reply": "2024-09-16T01:42:00.399740Z",
     "shell.execute_reply.started": "2024-09-16T01:42:00.397127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "136725a7-e184-459d-b354-116ccbcf8448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:42:10.725324Z",
     "iopub.status.busy": "2024-09-16T01:42:10.724490Z",
     "iopub.status.idle": "2024-09-16T01:42:10.728716Z",
     "shell.execute_reply": "2024-09-16T01:42:10.728301Z",
     "shell.execute_reply.started": "2024-09-16T01:42:10.725250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP Demystified 14: Machine Translation With Sequence-to-Sequence and Attention'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadata[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23745c15-9910-4df9-85df-84978254fcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:43:44.662386Z",
     "iopub.status.busy": "2024-09-16T01:43:44.662146Z",
     "iopub.status.idle": "2024-09-16T01:43:44.664550Z",
     "shell.execute_reply": "2024-09-16T01:43:44.664196Z",
     "shell.execute_reply.started": "2024-09-16T01:43:44.662370Z"
    }
   },
   "outputs": [],
   "source": [
    "video_metadata[\"heatmap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4207327-8d19-4407-bfd7-e839fc75365a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330f035-5a78-4092-b0e9-a0d93b562c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ab5cd-2083-4497-ae2e-769b2048a914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f82aa4-2244-4433-ad68-0b70d8148135",
   "metadata": {},
   "source": [
    "# Fazendo download de vídeo do youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae177e7a-55f5-487b-8850-31bb2f1c839d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:58:48.870009Z",
     "iopub.status.busy": "2024-09-15T23:58:48.869771Z",
     "iopub.status.idle": "2024-09-15T23:58:48.872538Z",
     "shell.execute_reply": "2024-09-15T23:58:48.871967Z",
     "shell.execute_reply.started": "2024-09-15T23:58:48.869993Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEO_URL = 'https://www.youtube.com/watch?v=tvIzBouq6lk'\n",
    "TRANSCRIPTION_LANGUAGE = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a6135-a59d-40e2-8ce7-a9ec8e5132a4",
   "metadata": {},
   "source": [
    "#### Obtendo o nome do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7f9528-5b15-4329-880a-37e5395ef8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:59:15.272828Z",
     "iopub.status.busy": "2024-09-15T23:59:15.272500Z",
     "iopub.status.idle": "2024-09-15T23:59:18.142528Z",
     "shell.execute_reply": "2024-09-15T23:59:18.141991Z",
     "shell.execute_reply.started": "2024-09-15T23:59:15.272806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tvIzBouq6lk\n",
      "[youtube] tvIzBouq6lk: Downloading webpage\n",
      "[youtube] tvIzBouq6lk: Downloading ios player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading web creator player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading m3u8 information\n",
      "Título do vídeo:\n",
      "\t\"NLP Demystified 14: Machine Translation With Sequence-to-Sequence and Attention\"\n",
      "Formated label:\n",
      "\t\"nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention\"\n"
     ]
    }
   ],
   "source": [
    "video_title = get_youtube_video_title(VIDEO_URL)\n",
    "print(f'Título do vídeo:\\n\\t\"{video_title}\"')\n",
    "video_title = remove_special_characters(video_title).lower().replace(\" \",\"-\")\n",
    "print(f'Formated label:\\n\\t\"{video_title}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d71f26-906a-41d0-8252-b3e18aad5ee8",
   "metadata": {},
   "source": [
    "#### Download do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830062ee-31e5-4af6-bcba-d1583cec42eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:59:22.312681Z",
     "iopub.status.busy": "2024-09-15T23:59:22.311951Z",
     "iopub.status.idle": "2024-09-16T00:00:55.203089Z",
     "shell.execute_reply": "2024-09-16T00:00:55.202586Z",
     "shell.execute_reply.started": "2024-09-15T23:59:22.312653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tvIzBouq6lk\n",
      "[youtube] tvIzBouq6lk: Downloading webpage\n",
      "[youtube] tvIzBouq6lk: Downloading ios player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading web creator player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading m3u8 information\n",
      "[info] tvIzBouq6lk: Downloading 1 format(s): 251\n",
      "[download] Destination: data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.webm\n",
      "[download] 100% of   62.43MiB in 00:00:26 at 2.33MiB/s     \n",
      "[ExtractAudio] Destination: data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.mp3\n",
      "Deleting original file data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.webm (pass -k to keep)\n",
      "CPU times: user 1.84 s, sys: 365 ms, total: 2.2 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'data/{video_title}.%(ext)s',\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96738107-bdc4-4757-bd88-b62fbb249809",
   "metadata": {},
   "source": [
    "# Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871407ca-15bf-466d-97c6-74d4dbf701bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:01:16.679787Z",
     "iopub.status.busy": "2024-09-16T00:01:16.677653Z",
     "iopub.status.idle": "2024-09-16T00:01:16.690865Z",
     "shell.execute_reply": "2024-09-16T00:01:16.688686Z",
     "shell.execute_reply.started": "2024-09-16T00:01:16.679663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e61baf-fd5e-464a-9b18-98920afb14d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:01:18.562920Z",
     "iopub.status.busy": "2024-09-16T00:01:18.562491Z",
     "iopub.status.idle": "2024-09-16T00:01:35.897875Z",
     "shell.execute_reply": "2024-09-16T00:01:35.897327Z",
     "shell.execute_reply.started": "2024-09-16T00:01:18.562892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 3.27 s, total: 25.6 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c0edca-2fb1-4a66-be14-af99e354334b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:03:15.636010Z",
     "iopub.status.busy": "2024-09-16T00:03:15.635495Z",
     "iopub.status.idle": "2024-09-16T00:17:15.768948Z",
     "shell.execute_reply": "2024-09-16T00:17:15.768427Z",
     "shell.execute_reply.started": "2024-09-16T00:03:15.635988Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 6s, sys: 3.32 s, total: 14min 9s\n",
      "Wall time: 14min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_filename = f\"data/{video_title}.mp3\"\n",
    "raw_text_filename = f\"data/raw_{video_title}.txt\"\n",
    "\n",
    "\n",
    "result = model.transcribe(audio_filename, language=TRANSCRIPTION_LANGUAGE)\n",
    "\n",
    "with open(raw_text_filename, \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15106857-5705-4b61-b3d3-08c7e843b612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:20.746034Z",
     "iopub.status.busy": "2024-09-16T01:28:20.745768Z",
     "iopub.status.idle": "2024-09-16T01:28:20.826542Z",
     "shell.execute_reply": "2024-09-16T01:28:20.825023Z",
     "shell.execute_reply.started": "2024-09-16T01:28:20.746013Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258559d6-e88d-4ab8-9143-9b6fecdb87b5",
   "metadata": {},
   "source": [
    "# Sintetizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e8803b-3101-450e-a4b7-59721676821f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:30:06.413592Z",
     "iopub.status.busy": "2024-09-16T01:30:06.413277Z",
     "iopub.status.idle": "2024-09-16T01:30:06.416313Z",
     "shell.execute_reply": "2024-09-16T01:30:06.415906Z",
     "shell.execute_reply.started": "2024-09-16T01:30:06.413570Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "INPUT_PRICE = 0.150 # per million\n",
    "OUTPUT_PRICE = 0.600 # per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0570374c-7fec-420c-b860-6fe0676b1385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:29:58.063524Z",
     "iopub.status.busy": "2024-09-16T01:29:58.063191Z",
     "iopub.status.idle": "2024-09-16T01:29:58.066548Z",
     "shell.execute_reply": "2024-09-16T01:29:58.066028Z",
     "shell.execute_reply.started": "2024-09-16T01:29:58.063501Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15ec637-6928-4da6-8edf-c207bad74d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:33:21.083790Z",
     "iopub.status.busy": "2024-09-16T01:33:21.083526Z",
     "iopub.status.idle": "2024-09-16T01:33:21.131121Z",
     "shell.execute_reply": "2024-09-16T01:33:21.130467Z",
     "shell.execute_reply.started": "2024-09-16T01:33:21.083772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 ms, sys: 1.01 ms, total: 44 ms\n",
      "Wall time: 43.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "Path(f\"data/translate-{video_title}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sections = [\n",
    "\t\"Seq2Seq and Attention\",\n",
    "\t\"Seq2Seq as a general problem-solving approach\",\n",
    "\t\"Translating language with a seq2seq model\",\n",
    "\t\"Machine translation challenges\",\n",
    "\t\"Effective decoding with Beam Search\",\n",
    "\t\"Evaluating translation models with BLEU\",\n",
    "\t\"The information bottleneck\",\n",
    "\t\"Overcoming the bottleneck with Attention\",\n",
    "\t\"Additive vs Multiplicative Attention\",\n",
    "\t\"[DEMO] Neural Machine Translation WITHOUT Attention\",\n",
    "\t\"[DEMO] Neural Machine Translation WITH Attention\",\n",
    "\t\"Attention as information retrieval\",\n",
    "]\n",
    "\n",
    "text_template = (\n",
    "    \"Considere o seguinte texto:\\n\"\n",
    "    \"<text>{text}</text>\\n\"\n",
    "    f\"Ele tem as seguintes seções: {str(sections)}\"\n",
    "    \"Pode gerar um texto didático que explique a seção {section}\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\", \"section\"], template=text_template)\n",
    "llm = ChatOpenAI(temperature=0, model=LLM_MODEL)\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac508fb0-cade-4250-8400-246070429412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:34:46.992988Z",
     "iopub.status.busy": "2024-09-16T01:34:46.991378Z",
     "iopub.status.idle": "2024-09-16T01:34:47.005052Z",
     "shell.execute_reply": "2024-09-16T01:34:47.002003Z",
     "shell.execute_reply.started": "2024-09-16T01:34:46.992885Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66457862-247a-48c8-8749-578ad74b9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e84cbd0c-1eee-4cc9-9723-65f1d58506de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:36:10.197270Z",
     "iopub.status.busy": "2024-09-16T01:36:10.196948Z",
     "iopub.status.idle": "2024-09-16T01:36:21.684202Z",
     "shell.execute_reply": "2024-09-16T01:36:21.683217Z",
     "shell.execute_reply.started": "2024-09-16T01:36:10.197253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.00263235\n",
      "CPU times: user 75.7 ms, sys: 32.1 ms, total: 108 ms\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "section = \"Seq2Seq and Attention\"\n",
    "\n",
    "with open(raw_text_filename, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "cost = 0\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    summary = chain.invoke({\"text\": text, \"section\": section})\n",
    "    cost += cb.total_cost\n",
    "\n",
    "print(f\"cost = {cost * 6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13cefd59-6930-4a2a-af64-f3ad1b1d5313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:37:01.137494Z",
     "iopub.status.busy": "2024-09-16T01:37:01.137299Z",
     "iopub.status.idle": "2024-09-16T01:37:01.141359Z",
     "shell.execute_reply": "2024-09-16T01:37:01.140935Z",
     "shell.execute_reply.started": "2024-09-16T01:37:01.137479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Seq2Seq and Attention\n",
       "\n",
       "A arquitetura Seq2Seq (Sequence-to-Sequence) é uma abordagem fundamental em tarefas de processamento de linguagem natural (NLP), especialmente em tradução automática. Essa arquitetura é projetada para transformar uma sequência de entrada em uma sequência de saída, permitindo que o modelo lide com entradas e saídas de comprimentos variáveis. A estrutura básica de um modelo Seq2Seq consiste em dois componentes principais: o **encoder** e o **decoder**.\n",
       "\n",
       "#### Encoder\n",
       "\n",
       "O encoder é responsável por processar a sequência de entrada. Ele recebe a sequência, que pode ser uma frase em um idioma, e a transforma em uma representação interna, geralmente chamada de \"embedding\" ou \"vetor de estado\". Este vetor captura as informações essenciais da sequência de entrada, permitindo que o modelo compreenda o contexto e as relações entre as palavras. O encoder pode ser implementado usando redes neurais recorrentes (RNNs), como LSTMs ou GRUs, que são eficazes em lidar com dados sequenciais.\n",
       "\n",
       "#### Decoder\n",
       "\n",
       "O decoder, por sua vez, utiliza a representação gerada pelo encoder para produzir a sequência de saída. No caso da tradução, isso significa gerar a frase correspondente em outro idioma. O decoder é alimentado com o vetor de estado final do encoder e começa a gerar a saída palavra por palavra. Para cada palavra gerada, o decoder considera a palavra anterior e o vetor de estado, permitindo que ele produza uma sequência coerente.\n",
       "\n",
       "#### Desafios do Modelo Seq2Seq\n",
       "\n",
       "Embora a arquitetura Seq2Seq seja poderosa, ela enfrenta um desafio significativo conhecido como **bottleneck de informação**. O encoder deve compactar toda a informação da sequência de entrada em um único vetor de estado, o que pode resultar em perda de informações, especialmente em sequências longas. Isso ocorre porque o vetor final precisa representar toda a complexidade da entrada, o que pode ser difícil de realizar.\n",
       "\n",
       "#### Introduzindo a Atenção\n",
       "\n",
       "Para superar esse bottleneck, introduzimos o mecanismo de **atenção**. A atenção permite que o decoder acesse não apenas o vetor de estado final do encoder, mas também todos os estados ocultos gerados durante o processamento da sequência de entrada. Isso significa que, em vez de depender de uma única representação, o decoder pode \"prestar atenção\" em diferentes partes da sequência de entrada conforme necessário.\n",
       "\n",
       "O funcionamento do mecanismo de atenção é simples: em cada passo de decodificação, o decoder calcula uma pontuação de atenção para cada estado oculto do encoder, determinando quais partes da entrada são mais relevantes para a palavra que está sendo gerada. Essas pontuações são normalizadas usando uma função softmax, resultando em pesos de atenção que indicam a importância de cada estado oculto. O vetor de contexto é então calculado como uma combinação ponderada dos estados ocultos, permitindo que o decoder utilize informações relevantes de toda a sequência de entrada.\n",
       "\n",
       "#### Benefícios da Atenção\n",
       "\n",
       "O uso da atenção traz vários benefícios:\n",
       "\n",
       "1. **Melhor Captura de Contexto**: O decoder pode acessar informações de diferentes partes da sequência de entrada, melhorando a qualidade da saída.\n",
       "2. **Flexibilidade**: O modelo pode lidar com sequências de entrada e saída de comprimentos diferentes, sem a necessidade de um vetor de estado fixo.\n",
       "3. **Desempenho Aprimorado**: Modelos que utilizam atenção tendem a ter um desempenho superior em tarefas de tradução e outras aplicações de NLP.\n",
       "\n",
       "Em resumo, a arquitetura Seq2Seq, combinada com o mecanismo de atenção, representa um avanço significativo na capacidade dos modelos de aprendizado de máquina de lidar com tarefas complexas de linguagem, permitindo traduções mais precisas e contextualmente relevantes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4920ac1-6680-46e8-b7fd-7594200c68a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:29:04.430683Z",
     "iopub.status.busy": "2024-09-15T03:29:04.430440Z",
     "iopub.status.idle": "2024-09-15T03:29:04.433351Z",
     "shell.execute_reply": "2024-09-15T03:29:04.432882Z",
     "shell.execute_reply.started": "2024-09-15T03:29:04.430667Z"
    }
   },
   "source": [
    "# Traduzindo o texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a6dbee-fb9a-4639-a112-f698cd221c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:28.163731Z",
     "iopub.status.busy": "2024-09-16T01:28:28.163524Z",
     "iopub.status.idle": "2024-09-16T01:28:28.814401Z",
     "shell.execute_reply": "2024-09-16T01:28:28.813880Z",
     "shell.execute_reply.started": "2024-09-16T01:28:28.163707Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "INPUT_PRICE = 0.150 # per million\n",
    "OUTPUT_PRICE = 0.600 # per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e0023b-1b8a-4252-ae3b-7d4d2e77b737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:29.766211Z",
     "iopub.status.busy": "2024-09-16T01:28:29.765920Z",
     "iopub.status.idle": "2024-09-16T01:28:29.775844Z",
     "shell.execute_reply": "2024-09-16T01:28:29.775381Z",
     "shell.execute_reply.started": "2024-09-16T01:28:29.766187Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "book = TextLoader(raw_text_filename).load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3fa82f5-baad-411c-9173-d6098caee8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:27:39.715102Z",
     "iopub.status.busy": "2024-09-15T04:27:39.714880Z",
     "iopub.status.idle": "2024-09-15T04:30:01.354141Z",
     "shell.execute_reply": "2024-09-15T04:30:01.353352Z",
     "shell.execute_reply.started": "2024-09-15T04:27:39.715087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custo = 0.0686 | Percentual: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [02:21<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 799 ms, sys: 299 ms, total: 1.1 s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "Path(f\"data/translate-{video_title}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "text_template = (\n",
    "    \"Traduza o seguinte para português, mantendo os jargões técnicos em inglês. Não retorne nada exceto a tradução:\\n\"\n",
    "\n",
    "    \"{text}\"\n",
    "\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=text_template)\n",
    "llm = ChatOpenAI(temperature=0, model=LLM_MODEL)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "cost = 0\n",
    "with tqdm(total=len(paragraphs)) as pbar:\n",
    "    pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        with get_openai_callback() as cb:\n",
    "            summary = chain.invoke({\"text\": p.page_content+\". \"})\n",
    "            cost += cb.total_cost\n",
    "    \n",
    "        with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"w\") as f:\n",
    "            f.write(summary.content)\n",
    "        \n",
    "        pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb61fe68-578c-4620-934c-61030d4d678b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:32:53.381649Z",
     "iopub.status.busy": "2024-09-15T04:32:53.381401Z",
     "iopub.status.idle": "2024-09-15T04:32:53.385504Z",
     "shell.execute_reply": "2024-09-15T04:32:53.385105Z",
     "shell.execute_reply.started": "2024-09-15T04:32:53.381632Z"
    }
   },
   "outputs": [],
   "source": [
    "text_pieces = []\n",
    "for i, p in enumerate(paragraphs):\n",
    "    with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"r\") as f:\n",
    "        text_pieces.append(f.read())\n",
    "\n",
    "text = \" \".join(text_pieces)\n",
    "\n",
    "with open(f\"data/translated-{video_title}.txt\", \"w\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8ab41-4f54-4eeb-925d-40d341f17429",
   "metadata": {},
   "source": [
    "# Gerando Questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616d9cb-d94e-48a9-b617-03aaa54d51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adb2089a-d79f-4d1b-9d6d-58834bdd0e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:30:07.005441Z",
     "iopub.status.busy": "2024-09-15T15:30:07.005203Z",
     "iopub.status.idle": "2024-09-15T15:30:07.009880Z",
     "shell.execute_reply": "2024-09-15T15:30:07.009360Z",
     "shell.execute_reply.started": "2024-09-15T15:30:07.005424Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, tokenizer, model, device):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def tokenize(self, messages):\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "        return model_inputs\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=2000, **kwargs):\n",
    "        model_inputs = self.tokenize(messages)\n",
    "        model_inputs[\"attention_mask\"] = model_inputs[\"attention_mask\"].to(\n",
    "            model_inputs[\"input_ids\"].device\n",
    "        )\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            **kwargs\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a490df8-76aa-4429-a288-5697639460f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:31:26.893324Z",
     "iopub.status.busy": "2024-09-15T15:31:26.893044Z",
     "iopub.status.idle": "2024-09-15T15:31:26.895757Z",
     "shell.execute_reply": "2024-09-15T15:31:26.895305Z",
     "shell.execute_reply.started": "2024-09-15T15:31:26.893305Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_dtype = torch.float16\n",
    "attn_implementation = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "659525d3-2de6-4c29-b975-a5a5f6549160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:32:47.655512Z",
     "iopub.status.busy": "2024-09-15T15:32:47.655038Z",
     "iopub.status.idle": "2024-09-15T15:33:11.149080Z",
     "shell.execute_reply": "2024-09-15T15:33:11.148452Z",
     "shell.execute_reply.started": "2024-09-15T15:32:47.655469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e986dfd1473147d79c64399bb77caf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d342f566bba04251ad1c94d4603cadb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "model_id = \"emdemor/question-generator-v2\"\n",
    "commit_hash = None\n",
    "\n",
    "\n",
    "# A quantização é uma técnica para reduzir o tamanho do modelo e aumentar a eficiência computacional.\n",
    "# Utilizamos a classe BitsAndBytesConfig para configurar a quantização em 4 bits, o que reduz o uso de memória e acelera o treinamento.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Usamos a classe AutoModelForCausalLM para carregar um modelo pré-treinado adequado para modelagem de linguagem causal.\n",
    "# Parâmetros importantes incluem:\n",
    "#  - torch_dtype=compute_dtype: Define o tipo de dado para o modelo.\n",
    "#  - quantization_config=bnb_config: Aplica a configuração de quantização.\n",
    "#  - device_map=\"auto\": Distribui automaticamente o modelo nos dispositivos disponíveis.\n",
    "#  - attn_implementation=attn_implementation: Define a implementação da atenção.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=compute_dtype,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    revision=commit_hash,\n",
    ")\n",
    "\n",
    "# # adapta o modelo para o treinamento em k-bits, otimizando ainda mais o desempenho.\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "def set_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=commit_hash)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "tokenizer = set_tokenizer(model_id)\n",
    "\n",
    "llm = LanguageModel(tokenizer, model, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f56cf17-ef19-4c30-b085-ff7b9a22b736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:15.532420Z",
     "iopub.status.busy": "2024-09-15T15:36:15.532093Z",
     "iopub.status.idle": "2024-09-15T15:36:15.534942Z",
     "shell.execute_reply": "2024-09-15T15:36:15.534567Z",
     "shell.execute_reply.started": "2024-09-15T15:36:15.532402Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_question(context, temperature=0.01):\n",
    "    return llm.generate([{\"content\": f\"{context}\", \"role\": \"user\"}], temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9dde86f5-188c-40d0-b03c-c2fafb5b1e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:46.501756Z",
     "iopub.status.busy": "2024-09-15T15:36:46.501229Z",
     "iopub.status.idle": "2024-09-15T15:36:46.505676Z",
     "shell.execute_reply": "2024-09-15T15:36:46.505305Z",
     "shell.execute_reply.started": "2024-09-15T15:36:46.501732Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "\n",
    "book = TextLoader(f\"data/translated-{video_title}.txt\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b0ba421a-a32d-4499-b6fa-a29d2ce27335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:49:11.190090Z",
     "iopub.status.busy": "2024-09-15T19:49:11.189898Z",
     "iopub.status.idle": "2024-09-15T20:12:20.273820Z",
     "shell.execute_reply": "2024-09-15T20:12:20.273456Z",
     "shell.execute_reply.started": "2024-09-15T19:49:11.190075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endereço = data/questions-nlp-demystified-13-recurrent-neural-networks-and-language-models.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a5956919f48578c53ff49ce141490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 9s, sys: 735 ms, total: 23min 10s\n",
      "Wall time: 23min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "csv_filename = f\"data/questions-{video_title}.csv\"\n",
    "pd.DataFrame().to_csv(csv_filename)\n",
    "\n",
    "print(\"Endereço =\",csv_filename)\n",
    "\n",
    "\n",
    "\n",
    "def correct_json(json_string):\n",
    "    corrected_json_string = json_string\n",
    "    if json_string[-2:] in [\"]]\", \"]}\"]:\n",
    "        corrected_json_string  = corrected_json_string[:-1]\n",
    "    return corrected_json_string\n",
    "\n",
    "\n",
    "def generate(p):\n",
    "    temperature = 0.01\n",
    "\n",
    "    for i in range(10):\n",
    "        try:     \n",
    "            qa_pairs_string = generate_question(p.page_content, temperature=temperature)\n",
    "            qa_pairs_string = correct_json(qa_pairs_string)\n",
    "            qa_pairs = json.loads(qa_pairs_string)\n",
    "            base_df = pd.read_csv(csv_filename)\n",
    "            updated_df = pd.concat([base_df, pd.DataFrame(qa_pairs)])\n",
    "            updated_df.to_csv(csv_filename, index=False)\n",
    "            return\n",
    "        except JSONDecodeError as err:\n",
    "            temperature += 0.05\n",
    "            continue\n",
    "\n",
    "\n",
    "for p in tqdm(paragraphs, total=len(paragraphs)):\n",
    "    generate(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7b871-1531-4b71-8707-1ceb226ede39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b45d6-a23f-416a-bb6a-d51260eedc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596a777-fa5b-4a0e-883e-8460c7f7ac95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25454d5-af3f-49d3-8d9e-355d512a2ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075f5cb-bb5d-4d51-b53f-d4a976b43057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
