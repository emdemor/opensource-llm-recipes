{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f0b627-c0af-418f-967b-210835a2d6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T01:45:24.367662Z",
     "iopub.status.busy": "2024-09-15T01:45:24.367429Z",
     "iopub.status.idle": "2024-09-15T01:45:25.892886Z",
     "shell.execute_reply": "2024-09-15T01:45:25.892400Z",
     "shell.execute_reply.started": "2024-09-15T01:45:24.367640Z"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56764ffc-28b2-4be5-8cd1-c8725fef6bdb",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dd3d70-5682-4229-9ac8-21cee59c9855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:00:16.195447Z",
     "iopub.status.busy": "2024-09-15T03:00:16.195174Z",
     "iopub.status.idle": "2024-09-15T03:00:16.198214Z",
     "shell.execute_reply": "2024-09-15T03:00:16.197834Z",
     "shell.execute_reply.started": "2024-09-15T03:00:16.195423Z"
    }
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def get_youtube_video_title(url):\n",
    "    ydl_opts = {}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        video_title = info_dict.get('title', None)\n",
    "    return video_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef91b04b-62d6-460e-9472-6336a2fb1984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:03:42.490832Z",
     "iopub.status.busy": "2024-09-15T03:03:42.490541Z",
     "iopub.status.idle": "2024-09-15T03:03:42.493258Z",
     "shell.execute_reply": "2024-09-15T03:03:42.492891Z",
     "shell.execute_reply.started": "2024-09-15T03:03:42.490816Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]+', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f82aa4-2244-4433-ad68-0b70d8148135",
   "metadata": {},
   "source": [
    "# Fazendo download de vídeo do youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae177e7a-55f5-487b-8850-31bb2f1c839d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:01:28.807233Z",
     "iopub.status.busy": "2024-09-15T03:01:28.806468Z",
     "iopub.status.idle": "2024-09-15T03:01:28.809705Z",
     "shell.execute_reply": "2024-09-15T03:01:28.809305Z",
     "shell.execute_reply.started": "2024-09-15T03:01:28.807209Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEO_URL = 'https://www.youtube.com/watch?v=y0FqGWbfkQw'\n",
    "TRANSCRIPTION_LANGUAGE = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a6135-a59d-40e2-8ce7-a9ec8e5132a4",
   "metadata": {},
   "source": [
    "#### Obtendo o nome do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a7f9528-5b15-4329-880a-37e5395ef8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:04:34.754708Z",
     "iopub.status.busy": "2024-09-15T03:04:34.754313Z",
     "iopub.status.idle": "2024-09-15T03:04:37.356852Z",
     "shell.execute_reply": "2024-09-15T03:04:37.356315Z",
     "shell.execute_reply.started": "2024-09-15T03:04:34.754690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=y0FqGWbfkQw\n",
      "[youtube] y0FqGWbfkQw: Downloading webpage\n",
      "[youtube] y0FqGWbfkQw: Downloading ios player API JSON\n",
      "[youtube] y0FqGWbfkQw: Downloading web creator player API JSON\n",
      "[youtube] y0FqGWbfkQw: Downloading m3u8 information\n",
      "Título do vídeo:\n",
      "\t\"NLP Demystified 13: Recurrent Neural Networks and Language Models\"\n",
      "Formated label:\n",
      "\t\"nlp-demystified-13-recurrent-neural-networks-and-language-models\"\n"
     ]
    }
   ],
   "source": [
    "video_title = get_youtube_video_title(VIDEO_URL)\n",
    "print(f'Título do vídeo:\\n\\t\"{video_title}\"')\n",
    "video_title = remove_special_characters(video_title).lower().replace(\" \",\"-\")\n",
    "print(f'Formated label:\\n\\t\"{video_title}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d71f26-906a-41d0-8252-b3e18aad5ee8",
   "metadata": {},
   "source": [
    "#### Download do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "830062ee-31e5-4af6-bcba-d1583cec42eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:11:07.825640Z",
     "iopub.status.busy": "2024-09-15T03:11:07.825414Z",
     "iopub.status.idle": "2024-09-15T03:12:05.084656Z",
     "shell.execute_reply": "2024-09-15T03:12:05.084173Z",
     "shell.execute_reply.started": "2024-09-15T03:11:07.825623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=y0FqGWbfkQw\n",
      "[youtube] y0FqGWbfkQw: Downloading webpage\n",
      "[youtube] y0FqGWbfkQw: Downloading ios player API JSON\n",
      "[youtube] y0FqGWbfkQw: Downloading web creator player API JSON\n",
      "[youtube] y0FqGWbfkQw: Downloading m3u8 information\n",
      "[info] y0FqGWbfkQw: Downloading 1 format(s): 251\n",
      "[download] Destination: data/nlp-demystified-13-recurrent-neural-networks-and-language-models.webm\n",
      "[download] 100% of   53.90MiB in 00:00:03 at 15.56MiB/s    \n",
      "[ExtractAudio] Destination: data/nlp-demystified-13-recurrent-neural-networks-and-language-models.mp3\n",
      "Deleting original file data/nlp-demystified-13-recurrent-neural-networks-and-language-models.webm (pass -k to keep)\n",
      "CPU times: user 1.63 s, sys: 360 ms, total: 1.99 s\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'data/{video_title}.%(ext)s',\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96738107-bdc4-4757-bd88-b62fbb249809",
   "metadata": {},
   "source": [
    "# Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "871407ca-15bf-466d-97c6-74d4dbf701bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:13:43.052207Z",
     "iopub.status.busy": "2024-09-15T03:13:43.051879Z",
     "iopub.status.idle": "2024-09-15T03:13:43.054696Z",
     "shell.execute_reply": "2024-09-15T03:13:43.054201Z",
     "shell.execute_reply.started": "2024-09-15T03:13:43.052191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4e61baf-fd5e-464a-9b18-98920afb14d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:14:58.324593Z",
     "iopub.status.busy": "2024-09-15T03:14:58.324318Z",
     "iopub.status.idle": "2024-09-15T03:15:20.909027Z",
     "shell.execute_reply": "2024-09-15T03:15:20.908409Z",
     "shell.execute_reply.started": "2024-09-15T03:14:58.324571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 5.41 s, total: 27.8 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84c0edca-2fb1-4a66-be14-af99e354334b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:40:17.300747Z",
     "iopub.status.busy": "2024-09-15T03:40:17.300499Z",
     "iopub.status.idle": "2024-09-15T03:57:17.011954Z",
     "shell.execute_reply": "2024-09-15T03:57:17.011459Z",
     "shell.execute_reply.started": "2024-09-15T03:40:17.300722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 4s, sys: 3.9 s, total: 17min 8s\n",
      "Wall time: 16min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_filename = f\"data/{video_title}.mp3\"\n",
    "raw_text_filename = f\"data/raw_{video_title}.txt\"\n",
    "\n",
    "\n",
    "result = model.transcribe(audio_filename, language=TRANSCRIPTION_LANGUAGE)\n",
    "\n",
    "with open(raw_text_filename, \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "15106857-5705-4b61-b3d3-08c7e843b612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:25:23.315398Z",
     "iopub.status.busy": "2024-09-15T15:25:23.315204Z",
     "iopub.status.idle": "2024-09-15T15:25:23.320206Z",
     "shell.execute_reply": "2024-09-15T15:25:23.319698Z",
     "shell.execute_reply.started": "2024-09-15T15:25:23.315382Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4920ac1-6680-46e8-b7fd-7594200c68a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:29:04.430683Z",
     "iopub.status.busy": "2024-09-15T03:29:04.430440Z",
     "iopub.status.idle": "2024-09-15T03:29:04.433351Z",
     "shell.execute_reply": "2024-09-15T03:29:04.432882Z",
     "shell.execute_reply.started": "2024-09-15T03:29:04.430667Z"
    }
   },
   "source": [
    "# Traduzindo o texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72a6dbee-fb9a-4639-a112-f698cd221c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:57:40.327523Z",
     "iopub.status.busy": "2024-09-15T03:57:40.327328Z",
     "iopub.status.idle": "2024-09-15T03:57:40.330330Z",
     "shell.execute_reply": "2024-09-15T03:57:40.329863Z",
     "shell.execute_reply.started": "2024-09-15T03:57:40.327507Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "INPUT_PRICE = 0.150 # per million\n",
    "OUTPUT_PRICE = 0.600 # per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57e0023b-1b8a-4252-ae3b-7d4d2e77b737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:57:42.200850Z",
     "iopub.status.busy": "2024-09-15T03:57:42.200025Z",
     "iopub.status.idle": "2024-09-15T03:57:42.207312Z",
     "shell.execute_reply": "2024-09-15T03:57:42.206806Z",
     "shell.execute_reply.started": "2024-09-15T03:57:42.200776Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "book = TextLoader(raw_text_filename).load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de599e86-b5aa-4c28-b41d-d39fcd3938ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:17:37.799664Z",
     "iopub.status.busy": "2024-09-15T04:17:37.799420Z",
     "iopub.status.idle": "2024-09-15T04:17:37.802465Z",
     "shell.execute_reply": "2024-09-15T04:17:37.802121Z",
     "shell.execute_reply.started": "2024-09-15T04:17:37.799647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0689"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3fa82f5-baad-411c-9173-d6098caee8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:27:39.715102Z",
     "iopub.status.busy": "2024-09-15T04:27:39.714880Z",
     "iopub.status.idle": "2024-09-15T04:30:01.354141Z",
     "shell.execute_reply": "2024-09-15T04:30:01.353352Z",
     "shell.execute_reply.started": "2024-09-15T04:27:39.715087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custo = 0.0686 | Percentual: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [02:21<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 799 ms, sys: 299 ms, total: 1.1 s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "Path(f\"data/translate-{video_title}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "text_template = (\n",
    "    \"Traduza o seguinte para português, mantendo os jargões técnicos em inglês. Não retorne nada exceto a tradução:\\n\"\n",
    "\n",
    "    \"{text}\"\n",
    "\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=text_template)\n",
    "llm = ChatOpenAI(temperature=0, model=LLM_MODEL)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "cost = 0\n",
    "with tqdm(total=len(paragraphs)) as pbar:\n",
    "    pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        with get_openai_callback() as cb:\n",
    "            summary = chain.invoke({\"text\": p.page_content+\". \"})\n",
    "            cost += cb.total_cost\n",
    "    \n",
    "        with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"w\") as f:\n",
    "            f.write(summary.content)\n",
    "        \n",
    "        pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb61fe68-578c-4620-934c-61030d4d678b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:32:53.381649Z",
     "iopub.status.busy": "2024-09-15T04:32:53.381401Z",
     "iopub.status.idle": "2024-09-15T04:32:53.385504Z",
     "shell.execute_reply": "2024-09-15T04:32:53.385105Z",
     "shell.execute_reply.started": "2024-09-15T04:32:53.381632Z"
    }
   },
   "outputs": [],
   "source": [
    "text_pieces = []\n",
    "for i, p in enumerate(paragraphs):\n",
    "    with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"r\") as f:\n",
    "        text_pieces.append(f.read())\n",
    "\n",
    "text = \" \".join(text_pieces)\n",
    "\n",
    "with open(f\"data/translated-{video_title}.txt\", \"w\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8ab41-4f54-4eeb-925d-40d341f17429",
   "metadata": {},
   "source": [
    "# Gerando Questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616d9cb-d94e-48a9-b617-03aaa54d51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adb2089a-d79f-4d1b-9d6d-58834bdd0e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:30:07.005441Z",
     "iopub.status.busy": "2024-09-15T15:30:07.005203Z",
     "iopub.status.idle": "2024-09-15T15:30:07.009880Z",
     "shell.execute_reply": "2024-09-15T15:30:07.009360Z",
     "shell.execute_reply.started": "2024-09-15T15:30:07.005424Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, tokenizer, model, device):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def tokenize(self, messages):\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "        return model_inputs\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=2000, **kwargs):\n",
    "        model_inputs = self.tokenize(messages)\n",
    "        model_inputs[\"attention_mask\"] = model_inputs[\"attention_mask\"].to(\n",
    "            model_inputs[\"input_ids\"].device\n",
    "        )\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            **kwargs\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a490df8-76aa-4429-a288-5697639460f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:31:26.893324Z",
     "iopub.status.busy": "2024-09-15T15:31:26.893044Z",
     "iopub.status.idle": "2024-09-15T15:31:26.895757Z",
     "shell.execute_reply": "2024-09-15T15:31:26.895305Z",
     "shell.execute_reply.started": "2024-09-15T15:31:26.893305Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_dtype = torch.float16\n",
    "attn_implementation = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "659525d3-2de6-4c29-b975-a5a5f6549160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:32:47.655512Z",
     "iopub.status.busy": "2024-09-15T15:32:47.655038Z",
     "iopub.status.idle": "2024-09-15T15:33:11.149080Z",
     "shell.execute_reply": "2024-09-15T15:33:11.148452Z",
     "shell.execute_reply.started": "2024-09-15T15:32:47.655469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e986dfd1473147d79c64399bb77caf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d342f566bba04251ad1c94d4603cadb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "model_id = \"emdemor/question-generator-v2\"\n",
    "commit_hash = None\n",
    "\n",
    "\n",
    "# A quantização é uma técnica para reduzir o tamanho do modelo e aumentar a eficiência computacional.\n",
    "# Utilizamos a classe BitsAndBytesConfig para configurar a quantização em 4 bits, o que reduz o uso de memória e acelera o treinamento.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Usamos a classe AutoModelForCausalLM para carregar um modelo pré-treinado adequado para modelagem de linguagem causal.\n",
    "# Parâmetros importantes incluem:\n",
    "#  - torch_dtype=compute_dtype: Define o tipo de dado para o modelo.\n",
    "#  - quantization_config=bnb_config: Aplica a configuração de quantização.\n",
    "#  - device_map=\"auto\": Distribui automaticamente o modelo nos dispositivos disponíveis.\n",
    "#  - attn_implementation=attn_implementation: Define a implementação da atenção.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=compute_dtype,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    revision=commit_hash,\n",
    ")\n",
    "\n",
    "# # adapta o modelo para o treinamento em k-bits, otimizando ainda mais o desempenho.\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "def set_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=commit_hash)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "tokenizer = set_tokenizer(model_id)\n",
    "\n",
    "llm = LanguageModel(tokenizer, model, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f56cf17-ef19-4c30-b085-ff7b9a22b736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:15.532420Z",
     "iopub.status.busy": "2024-09-15T15:36:15.532093Z",
     "iopub.status.idle": "2024-09-15T15:36:15.534942Z",
     "shell.execute_reply": "2024-09-15T15:36:15.534567Z",
     "shell.execute_reply.started": "2024-09-15T15:36:15.532402Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_question(context, temperature=0.01):\n",
    "    return llm.generate([{\"content\": f\"{context}\", \"role\": \"user\"}], temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9dde86f5-188c-40d0-b03c-c2fafb5b1e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:46.501756Z",
     "iopub.status.busy": "2024-09-15T15:36:46.501229Z",
     "iopub.status.idle": "2024-09-15T15:36:46.505676Z",
     "shell.execute_reply": "2024-09-15T15:36:46.505305Z",
     "shell.execute_reply.started": "2024-09-15T15:36:46.501732Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "\n",
    "book = TextLoader(f\"data/translated-{video_title}.txt\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b0ba421a-a32d-4499-b6fa-a29d2ce27335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:49:11.190090Z",
     "iopub.status.busy": "2024-09-15T19:49:11.189898Z",
     "iopub.status.idle": "2024-09-15T20:12:20.273820Z",
     "shell.execute_reply": "2024-09-15T20:12:20.273456Z",
     "shell.execute_reply.started": "2024-09-15T19:49:11.190075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endereço = data/questions-nlp-demystified-13-recurrent-neural-networks-and-language-models.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a5956919f48578c53ff49ce141490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 9s, sys: 735 ms, total: 23min 10s\n",
      "Wall time: 23min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "csv_filename = f\"data/questions-{video_title}.csv\"\n",
    "pd.DataFrame().to_csv(csv_filename)\n",
    "\n",
    "print(\"Endereço =\",csv_filename)\n",
    "\n",
    "\n",
    "\n",
    "def correct_json(json_string):\n",
    "    corrected_json_string = json_string\n",
    "    if json_string[-2:] in [\"]]\", \"]}\"]:\n",
    "        corrected_json_string  = corrected_json_string[:-1]\n",
    "    return corrected_json_string\n",
    "\n",
    "\n",
    "def generate(p):\n",
    "    temperature = 0.01\n",
    "\n",
    "    for i in range(10):\n",
    "        try:     \n",
    "            qa_pairs_string = generate_question(p.page_content, temperature=temperature)\n",
    "            qa_pairs_string = correct_json(qa_pairs_string)\n",
    "            qa_pairs = json.loads(qa_pairs_string)\n",
    "            base_df = pd.read_csv(csv_filename)\n",
    "            updated_df = pd.concat([base_df, pd.DataFrame(qa_pairs)])\n",
    "            updated_df.to_csv(csv_filename, index=False)\n",
    "            return\n",
    "        except JSONDecodeError as err:\n",
    "            temperature += 0.05\n",
    "            continue\n",
    "\n",
    "\n",
    "for p in tqdm(paragraphs, total=len(paragraphs)):\n",
    "    generate(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7b871-1531-4b71-8707-1ceb226ede39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b45d6-a23f-416a-bb6a-d51260eedc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596a777-fa5b-4a0e-883e-8460c7f7ac95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25454d5-af3f-49d3-8d9e-355d512a2ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075f5cb-bb5d-4d51-b53f-d4a976b43057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
