{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488be881-a374-4bc4-ae9d-d0ff23dbd08a",
   "metadata": {},
   "source": [
    "# Dataset Translation\n",
    "\n",
    "In this notebook, I will translate the sentences from the `b-mc2/sql-create-context` dataset into portuguese using OpenAI`s GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609dd78-b6c8-4d11-a048-240981a4ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cff96-22b5-48e6-87d2-93e2616dac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = False\n",
    "\n",
    "filepath = \"data/raw/sql_create_context_v4.parquet\"\n",
    "\n",
    "if update:\n",
    "    login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "    \n",
    "    REPO_ID = \"b-mc2/sql-create-context\"\n",
    "    FILENAME = \"sql_create_context_v4.json\"\n",
    "    \n",
    "    dataset = pd.read_json(\n",
    "        hf_hub_download(repo_id=REPO_ID, filename=FILENAME, repo_type=\"dataset\", force_download=True)\n",
    "    )\n",
    "    dataset.to_parquet(filepath)\n",
    "\n",
    "dataset = pd.read_parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a29f5-5b73-496e-9124-3fb510901ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"query\"],\n",
    "    template = (\n",
    "        \"Translate the following query to portuguese:\\n\"\n",
    "        \"'{query}'\"\n",
    "    )\n",
    ")\n",
    "chain = prompt | ChatOpenAI(model = 'gpt-3.5-turbo', temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc90a4-a233-485d-b3df-9cd7ca4ed875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "translated_path = \"data/processed/translated\"\n",
    "n_batch = 100\n",
    "\n",
    "n_iterations = 10\n",
    "\n",
    "for j in range(n_iterations):\n",
    "    batches = [int(x.replace(\".parquet\", \"\")) for x in os.listdir(translated_path)]\n",
    "    new_batch = str(int(round(np.max(batches)+1))).zfill(4)\n",
    "    translated = pd.read_parquet(translated_path)\n",
    "    done = translated[\"index\"].to_list()\n",
    "    \n",
    "    elegible = [x for x in dataset.index if x not in done]\n",
    "    selected_ids = np.random.choice(elegible, n_batch)\n",
    "    selected = dataset[dataset.reset_index()[\"index\"].isin(selected_ids)]\n",
    "    \n",
    "    \n",
    "    responses = []\n",
    "    total_cost = 0\n",
    "    for i, row in tqdm(selected[[\"question\"]].iterrows()):\n",
    "        query = row[\"question\"]\n",
    "        with get_openai_callback() as cb:\n",
    "            response =  chain.invoke(input={\"query\": query})\n",
    "            total_cost += cb.total_cost\n",
    "            responses.append(dict(index=i, translated=response.content))\n",
    "    print(f\"total_cost = {total_cost}\")\n",
    "    \n",
    "    translated = pd.DataFrame(responses)\n",
    "    \n",
    "    translated.to_parquet(f\"{translated_path}/{new_batch}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
