{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a6a8ee-a5e2-4967-aca6-4f0c4829ab64",
   "metadata": {},
   "source": [
    "# Fine-Tune with Pair-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211b505a-d487-4386-9c8e-5604ff495b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos de FutureWarning e UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*TRANSFORMERS_CACHE.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*resume_download.*deprecated.*\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_cache=True.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_reentrant parameter should be passed explicitly.*\", category=UserWarning)\n",
    "\n",
    "# Configurar o nível de log para a biblioteca transformers\n",
    "logging.getLogger(\"transformers.trainer\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.trainer_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.training_args\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5240ffb7-65d4-4d71-9b3d-f7f048d57a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.1\n",
      "bitsandbytes version: 0.43.1\n",
      "peft version: 0.11.1\n",
      "accelerate version: 0.31.0\n",
      "datasets version: 2.19.2\n",
      "trl version: 0.9.4\n",
      "Device name: 'NVIDIA GeForce GTX 1650'\n",
      "Device: cuda\n",
      "Device properties: '_CudaDeviceProperties(name='NVIDIA GeForce GTX 1650', major=7, minor=5, total_memory=3903MB, multi_processor_count=14)'\n",
      "Suporta bfloat16.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes\n",
    "import peft\n",
    "import accelerate\n",
    "import datasets\n",
    "import trl\n",
    "import warnings\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"bitsandbytes version:\", bitsandbytes.__version__)\n",
    "print(\"peft version:\", peft.__version__)\n",
    "print(\"accelerate version:\", accelerate.__version__)\n",
    "print(\"datasets version:\", datasets.__version__)\n",
    "print(\"trl version:\", trl.__version__)\n",
    "print(f\"Device name: '{torch.cuda.get_device_name()}'\")\n",
    "print(\"Device:\", device)\n",
    "print(f\"Device properties: '{torch.cuda.get_device_properties(torch.cuda.current_device())}'\")\n",
    "print(\"Suporta bfloat16.\" if torch.cuda.is_bf16_supported() else \"Não suporta bfloat16.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532b621-7181-494a-9b20-843af30c9298",
   "metadata": {},
   "source": [
    "# Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ba0dd0-36fc-4c2c-89a3-dca067ca04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: 'NVIDIA GeForce GTX 1650'\n",
      "Device properties: '_CudaDeviceProperties(name='NVIDIA GeForce GTX 1650', major=7, minor=5, total_memory=3903MB, multi_processor_count=14)'\n",
      "Suporta bfloat16.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "from tqdm import tqdm\n",
    "import GPUtil\n",
    "\n",
    "from huggingface_hub import hf_hub_download, login\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.losses import CoSENTLoss\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "\n",
    "print(f\"Device name: '{torch.cuda.get_device_name()}'\")\n",
    "print(f\"Device properties: '{torch.cuda.get_device_properties(torch.cuda.current_device())}'\")\n",
    "print(\"Suporta bfloat16.\" if torch.cuda.is_bf16_supported() else \"Não suporta bfloat16.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e68eb-e9df-43da-bc0b-4c2a54f5ad87",
   "metadata": {},
   "source": [
    "# Referências de Embedding Fine Tune\n",
    "\n",
    "- https://huggingface.co/blog/train-sentence-transformers\n",
    "- https://huggingface.co/blog/abhishek/finetune-custom-embeddings-autotrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c15dde-2059-4d4c-b94f-2a36a133c3a3",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c6d5f8-8cdc-4e2f-85ae-ff7a5c21c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_summary():\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU {gpu.id}:\")\n",
    "        print(f\"  Memória Total: {gpu.memoryTotal} MB\")\n",
    "        print(f\"  Memória Usada: {gpu.memoryUsed} MB\")\n",
    "        print(f\"  Memória Livre: {gpu.memoryFree} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb81080-7933-4b25-9f6a-ebf1a11dff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b, distance=\"cos\"):\n",
    "    if distance==\"cartesian\":\n",
    "        return np.dot(a, b)\n",
    "    elif distance == \"cos\":\n",
    "        return float(cos_sim(a, b)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebf551b-e375-4565-914b-7ba12b6ea718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bechmark(model, test_dataset):\n",
    "    similarities = [np.abs(similarity(model.encode(r['sentence1']), model.encode(r['sentence2'])) - r[\"score\"])  for r in tqdm(test_dataset)]\n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd094f56-50fb-4ed4-bd5e-90878e30c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveCheckpointCallback(TrainerCallback):\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        print(f\"Saving checkpoint at step {state.global_step}\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=3, early_stopping_threshold=0.02):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, metrics=None, **kwargs):\n",
    "        current_metric = metrics.get(\"eval_loss\")  # Use the relevant metric for your task\n",
    "\n",
    "        if current_metric is None:\n",
    "            return\n",
    "\n",
    "        if self.best_metric is None or current_metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = current_metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Early stopping at step {state.global_step} with best eval_loss = {self.best_metric}\")\n",
    "\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, output_dir):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        self.output_dir = output_dir\n",
    "        self.output_path = os.path.join(output_dir, \"metrics.json\")\n",
    "        self.state_path = os.path.join(output_dir, \"state.json\")\n",
    "        print(f\"Output directory initialized at {output_dir}\")\n",
    "        self.metrics = self.load_existing_metrics()\n",
    "\n",
    "    def load_existing_metrics(self):\n",
    "        if os.path.isfile(self.output_path):\n",
    "            return pd.read_json(self.output_path, lines=True).to_dict('records')\n",
    "        return []\n",
    "\n",
    "    def on_step_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        state.save_to_json(self.state_path)\n",
    "    \n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            step = state.global_step\n",
    "            _metrics = {\"Step\": step, **metrics}\n",
    "            self.metrics.append(_metrics)\n",
    "            metrics_df = pd.DataFrame(self.metrics).drop_duplicates(subset=['Step'], keep='last')\n",
    "            metrics_df.to_json(self.output_path, orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e9f88-ceca-4a0e-8c21-0906d2ab97ee",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1267f8c9-1a5f-41e5-a9a2-3473a8ad1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62717ef-d4bc-40e7-807d-11d1784aacec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0:\n",
      "  Memória Total: 4096.0 MB\n",
      "  Memória Usada: 198.0 MB\n",
      "  Memória Livre: 3705.0 MB\n"
     ]
    }
   ],
   "source": [
    "gpu_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835df053-2c66-4803-a35a-b009d97f3976",
   "metadata": {},
   "source": [
    "# Dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6bfa3fd-b196-4bf0-bf23-d52f743a1326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 38000 samples\n",
      "Validation dataset: 2000 samples\n",
      "Test dataset: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-score\", split=\"train\")\n",
    "dataset = dataset.shuffle(42).select(range(50000))\n",
    "\n",
    "# Dividir em treino e teste\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "# Dividir o conjunto de treino para criar validação\n",
    "train_validation_split = train_dataset.train_test_split(test_size=0.05)\n",
    "train_dataset = train_validation_split['train']\n",
    "validation_dataset = train_validation_split['test']\n",
    "\n",
    "# Verificar as divisões\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation dataset: {len(validation_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fd5f4-811f-4a4b-9920-b014d34ee73e",
   "metadata": {},
   "source": [
    "# Dataset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3498e814-c256-474c-b837-192c72a21758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "# eval_dataset = eval_dataset.shuffle(42).select(range(100,1100))\n",
    "\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=validation_dataset[\"sentence1\"],\n",
    "    sentences2=validation_dataset[\"sentence2\"],\n",
    "    scores=validation_dataset[\"score\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"sts-dev\",\n",
    ")\n",
    "# Run evaluation manually:\n",
    "# print(dev_evaluator(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6612ff-c28e-4885-b9bc-8792d849032d",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e753dabd-acf4-4e7a-af4e-ef42462b57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81728a2d-63a2-4d8b-a6e7-08e5ed530b1a",
   "metadata": {},
   "source": [
    "# Parâmetros de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2ff628-e3cb-459f-90a6-e947fb546aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "output_dir=\"models/finetune-MiniLM-pair-score\"\n",
    "\n",
    "# This loss requires pairs of text and a floating point similarity score as a label\n",
    "loss = losses.CosineSimilarityLoss(model)\n",
    "# loss = losses.CoSENTLoss(model)\n",
    "# loss = losses.AnglELoss(model)\n",
    "\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    seed=42,\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Training Hyperparameters\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    \n",
    "    # Validation \n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "\n",
    "    # Chackpoints\n",
    "    save_strategy=\"steps\",  # Salvando a cada 100 passos # save_strategy=\"epoch\",  # Salvando ao final de cada época\n",
    "    save_steps=1000,         # Salvando a cada 100 passos\n",
    "    save_total_limit=2,\n",
    "\n",
    "    # Loggings\n",
    "    log_level=\"warning\",\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # Optional training parameters:\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=False,  # Set to False if your GPU can't handle FP16\n",
    "    bf16=True,  # Set to True if your GPU supports BF16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ee610-fd06-4abb-a93c-edb6f2540a44",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac0a1a8-e819-4895-8a2a-5713d624e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory initialized at models/finetune-MiniLM-pair-score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4750' max='4750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4750/4750 20:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sts-dev Pearson Cosine</th>\n",
       "      <th>Sts-dev Spearman Cosine</th>\n",
       "      <th>Sts-dev Pearson Manhattan</th>\n",
       "      <th>Sts-dev Spearman Manhattan</th>\n",
       "      <th>Sts-dev Pearson Euclidean</th>\n",
       "      <th>Sts-dev Spearman Euclidean</th>\n",
       "      <th>Sts-dev Pearson Dot</th>\n",
       "      <th>Sts-dev Spearman Dot</th>\n",
       "      <th>Sts-dev Pearson Max</th>\n",
       "      <th>Sts-dev Spearman Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>0.540740</td>\n",
       "      <td>0.543125</td>\n",
       "      <td>0.533978</td>\n",
       "      <td>0.539115</td>\n",
       "      <td>0.538133</td>\n",
       "      <td>0.543125</td>\n",
       "      <td>0.540740</td>\n",
       "      <td>0.543125</td>\n",
       "      <td>0.540740</td>\n",
       "      <td>0.543125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>0.109989</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.593245</td>\n",
       "      <td>0.579038</td>\n",
       "      <td>0.589589</td>\n",
       "      <td>0.582791</td>\n",
       "      <td>0.593245</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.593245</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.593245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.102545</td>\n",
       "      <td>0.619357</td>\n",
       "      <td>0.627646</td>\n",
       "      <td>0.612093</td>\n",
       "      <td>0.625258</td>\n",
       "      <td>0.614952</td>\n",
       "      <td>0.627646</td>\n",
       "      <td>0.619357</td>\n",
       "      <td>0.627646</td>\n",
       "      <td>0.619357</td>\n",
       "      <td>0.627646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>0.630493</td>\n",
       "      <td>0.639352</td>\n",
       "      <td>0.625103</td>\n",
       "      <td>0.637643</td>\n",
       "      <td>0.627204</td>\n",
       "      <td>0.639352</td>\n",
       "      <td>0.630493</td>\n",
       "      <td>0.639352</td>\n",
       "      <td>0.630493</td>\n",
       "      <td>0.639352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.098049</td>\n",
       "      <td>0.638798</td>\n",
       "      <td>0.646097</td>\n",
       "      <td>0.633962</td>\n",
       "      <td>0.644551</td>\n",
       "      <td>0.635893</td>\n",
       "      <td>0.646098</td>\n",
       "      <td>0.638798</td>\n",
       "      <td>0.646097</td>\n",
       "      <td>0.638798</td>\n",
       "      <td>0.646098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.097830</td>\n",
       "      <td>0.642880</td>\n",
       "      <td>0.659225</td>\n",
       "      <td>0.646922</td>\n",
       "      <td>0.657780</td>\n",
       "      <td>0.648560</td>\n",
       "      <td>0.659225</td>\n",
       "      <td>0.642880</td>\n",
       "      <td>0.659225</td>\n",
       "      <td>0.648560</td>\n",
       "      <td>0.659225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.657853</td>\n",
       "      <td>0.644723</td>\n",
       "      <td>0.655863</td>\n",
       "      <td>0.646498</td>\n",
       "      <td>0.657853</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.657853</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.657853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.093685</td>\n",
       "      <td>0.659617</td>\n",
       "      <td>0.670649</td>\n",
       "      <td>0.657987</td>\n",
       "      <td>0.668780</td>\n",
       "      <td>0.659815</td>\n",
       "      <td>0.670649</td>\n",
       "      <td>0.659617</td>\n",
       "      <td>0.670649</td>\n",
       "      <td>0.659815</td>\n",
       "      <td>0.670649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.091891</td>\n",
       "      <td>0.667223</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.661591</td>\n",
       "      <td>0.672411</td>\n",
       "      <td>0.663813</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.667223</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.667223</td>\n",
       "      <td>0.674608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.092472</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>0.674176</td>\n",
       "      <td>0.661632</td>\n",
       "      <td>0.672179</td>\n",
       "      <td>0.663859</td>\n",
       "      <td>0.674176</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>0.674176</td>\n",
       "      <td>0.668005</td>\n",
       "      <td>0.674176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.089629</td>\n",
       "      <td>0.677426</td>\n",
       "      <td>0.684292</td>\n",
       "      <td>0.672277</td>\n",
       "      <td>0.682933</td>\n",
       "      <td>0.673984</td>\n",
       "      <td>0.684291</td>\n",
       "      <td>0.677426</td>\n",
       "      <td>0.684292</td>\n",
       "      <td>0.677426</td>\n",
       "      <td>0.684292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.090341</td>\n",
       "      <td>0.675947</td>\n",
       "      <td>0.683463</td>\n",
       "      <td>0.673778</td>\n",
       "      <td>0.682409</td>\n",
       "      <td>0.675065</td>\n",
       "      <td>0.683463</td>\n",
       "      <td>0.675947</td>\n",
       "      <td>0.683463</td>\n",
       "      <td>0.675947</td>\n",
       "      <td>0.683463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.090169</td>\n",
       "      <td>0.675016</td>\n",
       "      <td>0.680796</td>\n",
       "      <td>0.669257</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.670876</td>\n",
       "      <td>0.680796</td>\n",
       "      <td>0.675016</td>\n",
       "      <td>0.680796</td>\n",
       "      <td>0.675016</td>\n",
       "      <td>0.680796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.091221</td>\n",
       "      <td>0.677664</td>\n",
       "      <td>0.687403</td>\n",
       "      <td>0.678791</td>\n",
       "      <td>0.686256</td>\n",
       "      <td>0.680294</td>\n",
       "      <td>0.687403</td>\n",
       "      <td>0.677664</td>\n",
       "      <td>0.687403</td>\n",
       "      <td>0.680294</td>\n",
       "      <td>0.687403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.090270</td>\n",
       "      <td>0.674543</td>\n",
       "      <td>0.681026</td>\n",
       "      <td>0.670251</td>\n",
       "      <td>0.679510</td>\n",
       "      <td>0.672201</td>\n",
       "      <td>0.681026</td>\n",
       "      <td>0.674543</td>\n",
       "      <td>0.681026</td>\n",
       "      <td>0.674543</td>\n",
       "      <td>0.681026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.682098</td>\n",
       "      <td>0.671490</td>\n",
       "      <td>0.680857</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.682098</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.682098</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.682098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.089875</td>\n",
       "      <td>0.676984</td>\n",
       "      <td>0.682953</td>\n",
       "      <td>0.673892</td>\n",
       "      <td>0.681540</td>\n",
       "      <td>0.675586</td>\n",
       "      <td>0.682954</td>\n",
       "      <td>0.676984</td>\n",
       "      <td>0.682953</td>\n",
       "      <td>0.676984</td>\n",
       "      <td>0.682954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.089064</td>\n",
       "      <td>0.680034</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.673796</td>\n",
       "      <td>0.682388</td>\n",
       "      <td>0.675581</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.680034</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.680034</td>\n",
       "      <td>0.683785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.088885</td>\n",
       "      <td>0.680711</td>\n",
       "      <td>0.685887</td>\n",
       "      <td>0.675617</td>\n",
       "      <td>0.684218</td>\n",
       "      <td>0.677506</td>\n",
       "      <td>0.685887</td>\n",
       "      <td>0.680711</td>\n",
       "      <td>0.685887</td>\n",
       "      <td>0.680711</td>\n",
       "      <td>0.685887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.088663</td>\n",
       "      <td>0.681885</td>\n",
       "      <td>0.687694</td>\n",
       "      <td>0.678395</td>\n",
       "      <td>0.686483</td>\n",
       "      <td>0.680082</td>\n",
       "      <td>0.687694</td>\n",
       "      <td>0.681885</td>\n",
       "      <td>0.687694</td>\n",
       "      <td>0.681885</td>\n",
       "      <td>0.687694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.087959</td>\n",
       "      <td>0.685733</td>\n",
       "      <td>0.693096</td>\n",
       "      <td>0.684378</td>\n",
       "      <td>0.691717</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>0.693096</td>\n",
       "      <td>0.685733</td>\n",
       "      <td>0.693096</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>0.693096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.685055</td>\n",
       "      <td>0.690539</td>\n",
       "      <td>0.681374</td>\n",
       "      <td>0.689093</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>0.690539</td>\n",
       "      <td>0.685055</td>\n",
       "      <td>0.690539</td>\n",
       "      <td>0.685055</td>\n",
       "      <td>0.690539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.688135</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>0.684621</td>\n",
       "      <td>0.693075</td>\n",
       "      <td>0.686130</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>0.688135</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>0.688135</td>\n",
       "      <td>0.694433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.687572</td>\n",
       "      <td>0.692680</td>\n",
       "      <td>0.681563</td>\n",
       "      <td>0.690905</td>\n",
       "      <td>0.683460</td>\n",
       "      <td>0.692680</td>\n",
       "      <td>0.687572</td>\n",
       "      <td>0.692680</td>\n",
       "      <td>0.687572</td>\n",
       "      <td>0.692680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.689647</td>\n",
       "      <td>0.695062</td>\n",
       "      <td>0.684763</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.686413</td>\n",
       "      <td>0.695062</td>\n",
       "      <td>0.689647</td>\n",
       "      <td>0.695062</td>\n",
       "      <td>0.689647</td>\n",
       "      <td>0.695062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.087583</td>\n",
       "      <td>0.688150</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.680167</td>\n",
       "      <td>0.689891</td>\n",
       "      <td>0.681856</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.688150</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.688150</td>\n",
       "      <td>0.691555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.087154</td>\n",
       "      <td>0.689550</td>\n",
       "      <td>0.693380</td>\n",
       "      <td>0.683023</td>\n",
       "      <td>0.691891</td>\n",
       "      <td>0.684560</td>\n",
       "      <td>0.693380</td>\n",
       "      <td>0.689550</td>\n",
       "      <td>0.693380</td>\n",
       "      <td>0.689550</td>\n",
       "      <td>0.693380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>0.689813</td>\n",
       "      <td>0.693961</td>\n",
       "      <td>0.684592</td>\n",
       "      <td>0.692013</td>\n",
       "      <td>0.686370</td>\n",
       "      <td>0.693961</td>\n",
       "      <td>0.689813</td>\n",
       "      <td>0.693961</td>\n",
       "      <td>0.689813</td>\n",
       "      <td>0.693961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.086410</td>\n",
       "      <td>0.691852</td>\n",
       "      <td>0.698079</td>\n",
       "      <td>0.688851</td>\n",
       "      <td>0.696525</td>\n",
       "      <td>0.690355</td>\n",
       "      <td>0.698079</td>\n",
       "      <td>0.691852</td>\n",
       "      <td>0.698079</td>\n",
       "      <td>0.691852</td>\n",
       "      <td>0.698079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.087169</td>\n",
       "      <td>0.688910</td>\n",
       "      <td>0.695064</td>\n",
       "      <td>0.686565</td>\n",
       "      <td>0.693326</td>\n",
       "      <td>0.688283</td>\n",
       "      <td>0.695064</td>\n",
       "      <td>0.688910</td>\n",
       "      <td>0.695064</td>\n",
       "      <td>0.688910</td>\n",
       "      <td>0.695064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.086145</td>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.698138</td>\n",
       "      <td>0.688893</td>\n",
       "      <td>0.696633</td>\n",
       "      <td>0.690399</td>\n",
       "      <td>0.698138</td>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.698138</td>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.698138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.086044</td>\n",
       "      <td>0.693278</td>\n",
       "      <td>0.699472</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0.691804</td>\n",
       "      <td>0.699472</td>\n",
       "      <td>0.693278</td>\n",
       "      <td>0.699472</td>\n",
       "      <td>0.693278</td>\n",
       "      <td>0.699472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.701521</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.699924</td>\n",
       "      <td>0.694499</td>\n",
       "      <td>0.701521</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.701522</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.701522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.695483</td>\n",
       "      <td>0.701640</td>\n",
       "      <td>0.692897</td>\n",
       "      <td>0.700171</td>\n",
       "      <td>0.694311</td>\n",
       "      <td>0.701640</td>\n",
       "      <td>0.695483</td>\n",
       "      <td>0.701640</td>\n",
       "      <td>0.695483</td>\n",
       "      <td>0.701640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.086019</td>\n",
       "      <td>0.693661</td>\n",
       "      <td>0.700315</td>\n",
       "      <td>0.691374</td>\n",
       "      <td>0.698912</td>\n",
       "      <td>0.692804</td>\n",
       "      <td>0.700315</td>\n",
       "      <td>0.693661</td>\n",
       "      <td>0.700315</td>\n",
       "      <td>0.693661</td>\n",
       "      <td>0.700315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.086040</td>\n",
       "      <td>0.694017</td>\n",
       "      <td>0.702014</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>0.700752</td>\n",
       "      <td>0.694698</td>\n",
       "      <td>0.702014</td>\n",
       "      <td>0.694017</td>\n",
       "      <td>0.702014</td>\n",
       "      <td>0.694698</td>\n",
       "      <td>0.702014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.086067</td>\n",
       "      <td>0.694106</td>\n",
       "      <td>0.699498</td>\n",
       "      <td>0.689889</td>\n",
       "      <td>0.698230</td>\n",
       "      <td>0.691315</td>\n",
       "      <td>0.699498</td>\n",
       "      <td>0.694106</td>\n",
       "      <td>0.699498</td>\n",
       "      <td>0.694106</td>\n",
       "      <td>0.699498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.085730</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.702278</td>\n",
       "      <td>0.693451</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.702278</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.702278</td>\n",
       "      <td>0.695003</td>\n",
       "      <td>0.702278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>0.692456</td>\n",
       "      <td>0.700318</td>\n",
       "      <td>0.693937</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>0.695199</td>\n",
       "      <td>0.701828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.085485</td>\n",
       "      <td>0.695986</td>\n",
       "      <td>0.703064</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.701393</td>\n",
       "      <td>0.695143</td>\n",
       "      <td>0.703064</td>\n",
       "      <td>0.695986</td>\n",
       "      <td>0.703064</td>\n",
       "      <td>0.695986</td>\n",
       "      <td>0.703064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>0.692894</td>\n",
       "      <td>0.700957</td>\n",
       "      <td>0.694526</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.702621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.695392</td>\n",
       "      <td>0.701155</td>\n",
       "      <td>0.690842</td>\n",
       "      <td>0.699220</td>\n",
       "      <td>0.692631</td>\n",
       "      <td>0.701155</td>\n",
       "      <td>0.695392</td>\n",
       "      <td>0.701155</td>\n",
       "      <td>0.695392</td>\n",
       "      <td>0.701155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.693639</td>\n",
       "      <td>0.701640</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>0.703196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.085428</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.703453</td>\n",
       "      <td>0.694121</td>\n",
       "      <td>0.701813</td>\n",
       "      <td>0.695750</td>\n",
       "      <td>0.703453</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.703452</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.703453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.085252</td>\n",
       "      <td>0.696793</td>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.692309</td>\n",
       "      <td>0.700725</td>\n",
       "      <td>0.693995</td>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.696793</td>\n",
       "      <td>0.702459</td>\n",
       "      <td>0.696793</td>\n",
       "      <td>0.702459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.085267</td>\n",
       "      <td>0.696828</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.691825</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>0.693519</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.696828</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.696828</td>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.702447</td>\n",
       "      <td>0.692071</td>\n",
       "      <td>0.700616</td>\n",
       "      <td>0.693740</td>\n",
       "      <td>0.702447</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.702447</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.702447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint at step 1000\n",
      "Saving checkpoint at step 2000\n",
      "Saving checkpoint at step 3000\n",
      "Saving checkpoint at step 4000\n"
     ]
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    "    callbacks=[SaveCheckpointCallback(), SaveMetricsCallback(output_dir)],\n",
    "    # callbacks=[SaveCheckpointCallback(), EarlyStoppingCallback( early_stopping_threshold=0.0005)],\n",
    "    # callbacks=[SaveCheckpointCallback(), EarlyStoppingCallback( early_stopping_threshold=0.0005), SaveMetricsCallback(output_dir)],\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "model.save(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067de42f-f1cf-42ce-83e8-0c752c353208",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "029abd83-fd13-40b0-8022-83aea47f8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bechmark(model, test_dataset):\n",
    "    similarities = [np.abs(similarity(model.encode(r['sentence1']), model.encode(r['sentence2'])) - r[\"score\"])  for r in tqdm(test_dataset)]\n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e99dcc-cf1c-44e3-949a-307b1c0085ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:20<00:00, 123.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23825372176468373"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = SentenceTransformer(\"models/finetune-MiniLM-pair-score\")\n",
    "bechmark(tuned_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3551aa5-9a29-4e50-82c7-7f6f635a8623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:22<00:00, 121.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29415455153742803"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "bechmark(base_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f59802-9ccd-4d5c-a399-e8612ac231fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0045-071d-4bf6-a605-7940e9547bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0d9ac-cac9-4384-9c82-a7a3e89b2088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab062274-b4be-4897-a370-7b4c597d72f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29fd1c-9e14-4359-ad68-f66127120b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e94f36eb-fd3b-44a2-8681-b9204c2810ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del trainer\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa1531-4863-49d4-9f4c-8edc192d6eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8af4896-6ec1-4442-995c-9fd81d1a7aa8",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d42d34c3-48f3-4222-a26a-67bb75b6b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57cebb07-23f1-4513-9573-e4b24cb5d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "\n",
    "def generate_dataloader(\n",
    "    dataset: datasets.arrow_dataset.Dataset,\n",
    "    question_column: str,\n",
    "    answer_column: str,\n",
    "    shuffle: bool = True,\n",
    "    batch_size: int = 16,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\" \"\"\"\n",
    "    return DataLoader(\n",
    "        [\n",
    "            InputExample(texts=[row[question_column], row[answer_column]])\n",
    "            for row in dataset\n",
    "        ]\n",
    "        ,\n",
    "        shuffle=shuffle, batch_size=batch_size,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = generate_dataloader(train_dataset, 'sentence1', 'sentence2')\n",
    "test_dataloader = generate_dataloader(test_dataset, 'sentence1', 'sentence2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db4c6f7-7f8b-4b39-b3af-949a7baa7173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 04:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.237600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 19s, sys: 8.45 s, total: 4min 27s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_dir=\"models/finetune-MiniLM-comparison\"\n",
    "\n",
    "\n",
    "\n",
    "# model = SentenceTransformer(model_id)\n",
    "\n",
    "# train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model) #use if you have related sentence pairs\n",
    "#train_loss = losses.TripletLoss(model=model)  # use this if you have an achor, positive, negative triplets\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=500,\n",
    ")\n",
    "\n",
    "model.save(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f93ab78-1ca8-4eef-85db-8e0f2ae15671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:32<00:00, 108.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000000054460764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tuned_model = SentenceTransformer(\"models/finetune-MiniLM-pair-score\")\n",
    "# bechmark(tuned_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b5af638-457b-4776-a018-0d4a451b25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:21<00:00, 121.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6409838970854412"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir=\"models/finetune-MiniLM-comparison\"\n",
    "tuned_model_comparison = SentenceTransformer(output_dir)\n",
    "# bechmark(tuned_model_comparison, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "955520e5-0663-4593-bb0c-360a92f97418",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "tuned_model = SentenceTransformer(\"models/finetune-MiniLM-pair-score\")\n",
    "tuned_model_comparison = SentenceTransformer(\"models/finetune-MiniLM-comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2e771d9-06f8-4fc8-a2cc-80f34fe11f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 = The right cannot understand that ordinary Americans sparked the '60s cultural revolution.\n",
      "sentence2 = The right understands how ordinary Americans sparked a cultural revolution in the 60s because the right was there at the time.\n",
      "score = 0.0\n",
      "base model = 0.8458305597305298\n",
      "tuned_model = 0.9999999403953552\n",
      "tuned_model_comparison = 0.9482017755508423\n"
     ]
    }
   ],
   "source": [
    "temp = test_dataset.to_pandas().sample().iloc[0].to_dict()\n",
    "sentence1 = temp[\"sentence1\"]\n",
    "sentence2 = temp[\"sentence2\"]\n",
    "score = temp[\"score\"]\n",
    "\n",
    "print\n",
    "print(f\"sentence1 = {sentence1}\")\n",
    "print(f\"sentence2 = {sentence2}\")\n",
    "print(f\"score = {score}\")\n",
    "print(f\"base model = {similarity(base_model.encode(sentence1), base_model.encode(sentence2))}\")\n",
    "print(f\"tuned_model = {similarity(tuned_model.encode(sentence1), tuned_model.encode(sentence2))}\")\n",
    "print(f\"tuned_model_comparison = {similarity(tuned_model_comparison.encode(sentence1), tuned_model_comparison.encode(sentence2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975e466-9332-43b4-8b1d-096da6f213f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e2a3d-9ae5-473d-b613-d4a8978f465f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0aa79e-6afa-4c0f-8186-91018cf36ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fea550-1566-4a82-9236-8577696053c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e55c8-178a-4ad9-8f14-344063d0d0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2da518d0-d423-489d-a9d3-ced6014363f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"models/finetune-MiniLM-comparison\"\n",
    "tuned_model_1 = SentenceTransformer(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1afc2d6-e2d6-4ee5-b6fc-858be7b99ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5211070775985718"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"qual o nome do seu pai?\"\n",
    "a = \"ele se chama joao\"\n",
    "\n",
    "similarity(tuned_model_1.encode(q), tuned_model_1.encode(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dc3c6b6-1b85-4c38-be73-8c1ccc117b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001192092896"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir=\"models/finetune-MiniLM-pair-score\"\n",
    "tuned_model_2 = SentenceTransformer(output_dir)\n",
    "\n",
    "similarity(tuned_model_2.encode(q), tuned_model_2.encode(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91804b10-3245-4002-ad45-7eef7c1f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee718ad0-faf4-42d5-a200-2440ea7f0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bechmark(model, test_dataset):\n",
    "    \n",
    "    similarities = [\n",
    "        np.abs(similarity(model.encode(r['sentence1']), model.encode(r['sentence2']))-r[\"score\"])\n",
    "        for r in tqdm(test_dataset)\n",
    "    ]\n",
    "    \n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467a8a7-c991-4b2a-acd4-2f61f6886329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb206d4-3a85-4a86-a5bb-9c6e2f9bb45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5121c5f-3cca-42d6-89c8-a3d024e1a77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee88ae-eb22-4679-8784-d01662c83f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31395513-2e46-4fc2-9168-1cc7e89b60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"models/finetune-MiniLM-comparison\"\n",
    "tuned_model = SentenceTransformer(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2253e0c-4c76-4864-9fff-0305b0dd0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb697dd1-a26b-498c-9150-c612ba7dfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"models/finetune-MiniLM-pair-score\"\n",
    "\n",
    "# This loss requires pairs of text and a floating point similarity score as a label\n",
    "loss = CoSENTLoss(model)\n",
    "\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    seed=42,\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Training Hyperparameters\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    \n",
    "    # Validation \n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "\n",
    "    # Chackpoints\n",
    "    save_strategy=\"steps\",  # Salvando a cada 100 passos # save_strategy=\"epoch\",  # Salvando ao final de cada época\n",
    "    save_steps=1000,         # Salvando a cada 100 passos\n",
    "    save_total_limit=2,\n",
    "\n",
    "    # Loggings\n",
    "    log_level=\"warning\",\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # Optional training parameters:\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=False,  # Set to False if your GPU can't handle FP16\n",
    "    bf16=True,  # Set to True if your GPU supports BF16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361c4fb-bd31-4dc9-bcc5-5e20239470ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70fc53-f3b1-4915-aa7a-a34b6c901992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b0c95c-2a6a-4d26-95ca-4929b5b0a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O céu é azul --- 0.8213341236114502\n",
      "Eu como ovos no café da manhã --- 0.7087804079055786\n",
      "Qual é a cor do mar? --- 0.9428924322128296\n",
      "Quão alto é o céu? --- 0.8686226606369019\n"
     ]
    }
   ],
   "source": [
    "tuned_model = SentenceTransformer(\"models/finetune-MiniLM-pair-score\")\n",
    "\n",
    "question = ['Qual é a cor do céu?']\n",
    "answers = [\"O céu é azul\", \"Eu como ovos no café da manhã\",\"Qual é a cor do mar?\",\"Quão alto é o céu?\"]\n",
    "\n",
    "# Obtendo os vetores de embedding\n",
    "question_embedding = tuned_model.encode(question)\n",
    "answers_embeddings = tuned_model.encode(answers)\n",
    "\n",
    "\n",
    "emb_q = question_embedding[0]\n",
    "similarities = [similarity(emb_a, emb_q) for emb_a in answers_embeddings]\n",
    "\n",
    "for a, s in zip(answers, similarities):\n",
    "  print(a + \" --- \" + str(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208257b0-ea5a-4838-aa69-7637a2d23596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sts-dev_pearson_cosine': 0.7696243947343424, 'sts-dev_spearman_cosine': 0.7890590202325146, 'sts-dev_pearson_manhattan': 0.7866918847058119, 'sts-dev_spearman_manhattan': 0.788402013180287, 'sts-dev_pearson_euclidean': 0.7867983537211847, 'sts-dev_spearman_euclidean': 0.7890590202325146, 'sts-dev_pearson_dot': 0.769624392140128, 'sts-dev_spearman_dot': 0.7890590202325146, 'sts-dev_pearson_max': 0.7867983537211847, 'sts-dev_spearman_max': 0.7890590202325146}\n",
      "CPU times: user 1.98 s, sys: 67.6 ms, total: 2.05 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(dev_evaluator(tuned_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d0fc5-9359-4730-a4d3-74e773dda52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
