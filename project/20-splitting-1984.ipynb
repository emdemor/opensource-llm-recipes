{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8976cac-8c2d-44f7-955d-40069317fb18",
   "metadata": {},
   "source": [
    "# Utilização de LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc86a87a-482f-4303-8d9d-d0df123f017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos específicos de FutureWarning e UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*TRANSFORMERS_CACHE.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*resume_download.*deprecated.*\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_cache=True.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_reentrant parameter should be passed explicitly.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly.\")\n",
    "\n",
    "\n",
    "# Configurar o nível de log para a biblioteca transformers\n",
    "logging.getLogger(\"transformers.trainer\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.trainer_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.training_args\").setLevel(logging.WARNING)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5b702c-fa21-4c82-a531-2538593ad3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.1\n",
      "bitsandbytes version: 0.43.1\n",
      "peft version: 0.11.1\n",
      "accelerate version: 0.31.0\n",
      "datasets version: 2.19.2\n",
      "trl version: 0.9.6\n",
      "transformers version: 4.44.0\n",
      "Device name: 'NVIDIA GeForce GTX 1650'\n",
      "Device: cuda\n",
      "Device properties: '_CudaDeviceProperties(name='NVIDIA GeForce GTX 1650', major=7, minor=5, total_memory=3903MB, multi_processor_count=14)'\n",
      "Suporta bfloat16.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes\n",
    "import peft\n",
    "import accelerate\n",
    "import datasets\n",
    "import trl\n",
    "import warnings\n",
    "import transformers\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"bitsandbytes version:\", bitsandbytes.__version__)\n",
    "print(\"peft version:\", peft.__version__)\n",
    "print(\"accelerate version:\", accelerate.__version__)\n",
    "print(\"datasets version:\", datasets.__version__)\n",
    "print(\"trl version:\", trl.__version__)\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(f\"Device name: '{torch.cuda.get_device_name()}'\")\n",
    "print(\"Device:\", device)\n",
    "print(f\"Device properties: '{torch.cuda.get_device_properties(torch.cuda.current_device())}'\")\n",
    "print(\"Suporta bfloat16.\" if torch.cuda.is_bf16_supported() else \"Não suporta bfloat16.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25699ee-09f7-4ee2-952d-adda0691d833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513a330f-7957-435a-92f8-6ccf87a66926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    "    set_seed,\n",
    "    pipeline,\n",
    "    TrainerCallback,\n",
    "    TrainerControl,\n",
    "    TrainerState,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867fb4c8-6542-4d96-84de-92bf5859ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, tokenizer, model, device):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def tokenize(self, messages):\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "        return model_inputs\n",
    "\n",
    "    def generate(self, messages):\n",
    "        model_inputs = self.tokenize(messages)\n",
    "        model_inputs['attention_mask'] = model_inputs['attention_mask'].to(model_inputs['input_ids'].device)\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=2000,\n",
    "            do_sample=True,\n",
    "            attention_mask=model_inputs['attention_mask'],\n",
    "            pad_token_id=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "        return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09761d40-2d18-4f3e-ae49-e44aee9f3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# if torch.cuda.is_bf16_supported():\n",
    "#     compute_dtype = torch.bfloat16\n",
    "#     # attn_implementation = 'flash_attention_2'\n",
    "#     attn_implementation = 'eager'\n",
    "# else:\n",
    "compute_dtype = torch.float16\n",
    "attn_implementation = 'eager'\n",
    "\n",
    "print(attn_implementation)\n",
    "print(compute_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9a447-3793-4e9f-af92-fa8ec71b96e1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31008e43-2937-4246-b04f-41ed9af35911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c8b0ed-d219-4a09-86c6-fd7bb69cb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "book = TextLoader(\"data/1984.txt\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=50, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d3d22ff-79b2-43d9-98e2-13d04efbac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39874dd7-0942-4af7-ab0b-cc1a15729a66",
   "metadata": {},
   "source": [
    "# Modelo de Linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61512dd0-3453-4aa5-bcfc-aaeea453ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4a5589c1ff491b9e934bc6bde2c28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacfb534498d41d8b93cd7830c944308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "model_id = \"emdemor/question-generator-v2\"\n",
    "commit_hash = None\n",
    "\n",
    "\n",
    "# A quantização é uma técnica para reduzir o tamanho do modelo e aumentar a eficiência computacional.\n",
    "# Utilizamos a classe BitsAndBytesConfig para configurar a quantização em 4 bits, o que reduz o uso de memória e acelera o treinamento.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Usamos a classe AutoModelForCausalLM para carregar um modelo pré-treinado adequado para modelagem de linguagem causal.\n",
    "# Parâmetros importantes incluem:\n",
    "#  - torch_dtype=compute_dtype: Define o tipo de dado para o modelo.\n",
    "#  - quantization_config=bnb_config: Aplica a configuração de quantização.\n",
    "#  - device_map=\"auto\": Distribui automaticamente o modelo nos dispositivos disponíveis.\n",
    "#  - attn_implementation=attn_implementation: Define a implementação da atenção.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=compute_dtype,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    revision=commit_hash,\n",
    ")\n",
    "\n",
    "# # adapta o modelo para o treinamento em k-bits, otimizando ainda mais o desempenho.\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "def set_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=commit_hash)\n",
    "    tokenizer.padding_side = 'right'\n",
    "    return tokenizer\n",
    "tokenizer = set_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a3a7fc-fbd9-47ae-8c76-62dd12988a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "llm = LanguageModel(tokenizer, model, device=\"cuda\")\n",
    "\n",
    "def generate_text(context):\n",
    "    messages = [\n",
    "        {\n",
    "            \"content\": f\"{context}\",\n",
    "            \"role\": \"user\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        result = llm.generate(messages)\n",
    "    \n",
    "    try:\n",
    "        return json.dumps(json.loads(result), indent=4, ensure_ascii=False)\n",
    "    except:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f913003-366b-49d9-8d74-ed1f7e8f50e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 34.9 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "paragraph = paragraphs[0]\n",
    "\n",
    "response = generate_text(paragraph.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cde02e-f858-4382-bcf9-aedb9a8e770c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac37c822-80da-49a6-9e5b-6a9c31d2f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pergunta': 'Qual é a época do ano mencionada no texto?',\n",
       "  'resposta': 'Abril.'},\n",
       " {'pergunta': 'Qual é a característica do clima que é ressaltada?',\n",
       "  'resposta': 'Um dia frio e ensolarado.'},\n",
       " {'pergunta': 'Qual é a etnia do personagem que se identifica no contexto?',\n",
       "  'resposta': 'Judeu.'},\n",
       " {'pergunta': 'Quem é Winston Smith mencionado no texto?',\n",
       "  'resposta': 'Um personagem que se esgueirava pelas portas de vidro do Edifício Vitória.'},\n",
       " {'pergunta': 'O que Winston Smith consegue fazer com a onda de pó áspero?',\n",
       "  'resposta': 'Ele não consegue fugir a tempo, o que leva ao seu contato com a onda de pó.'},\n",
       " {'pergunta': 'Como é descrito a escada onde Winston subiu?',\n",
       "  'resposta': 'Ela apresenta um cartaz colorido de uma cara enorme.'},\n",
       " {'pergunta': 'Quem é a imagem representada no cartaz da escada?',\n",
       "  'resposta': 'O rosto de um homem de uns quarenta e cinco anos.'},\n",
       " {'pergunta': 'Qual é o cartaz que Winston encontra na escada?',\n",
       "  'resposta': 'Alegremente representa a figura do Grande Irmão e está exibindo uma mensagem de vigilância.'},\n",
       " {'pergunta': 'Para qual andar Winston vai subindo no apartamento?',\n",
       "  'resposta': 'O sétimo andar.'},\n",
       " {'pergunta': 'Qual é a descrição da porta do elevador no apartamento?',\n",
       "  'resposta': 'Fora pintado com uma cara grande.'},\n",
       " {'pergunta': 'Qual é o nome dos personagens que lê uma lista de cifras no apartamento?',\n",
       "  'resposta': 'Um homem que se identifica como frágil, louro e tem uma voz sonora.'},\n",
       " {'pergunta': 'Qual é o nome do equipamento que é ligado no apartamento com o fone de ouvido?',\n",
       "  'resposta': 'Teletela.'},\n",
       " {'pergunta': 'Por que o apartamento está equipado com teletela?',\n",
       "  'resposta': 'Por razões relacionadas à economia e ao preparo para a Semana do Ódio.'},\n",
       " {'pergunta': 'Winston tem algum problema físico?',\n",
       "  'resposta': 'Sim, ele possui uma varize ulcerada acima do tornozelo direito.'},\n",
       " {'pergunta': 'O que pode ser retirado do apartamento em relação ao teletela?',\n",
       "  'resposta': 'A voz pode ser diminuída, mas não é possível desligá-lo completamente.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e8d7f6-ef50-408f-9081-e1c5d646c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n    {\\n        \"pergunta\": \"Qual era a estação do ano descrita no início do trecho?\",\\n        \"resposta\": \"É um dia frio e ensolarado de abril.\"\\n    },\\n    {\\n        \"pergunta\": \"Qual era a fonte de luz fornecida de acordo com o trecho?\",\\n        \"resposta\": \"Os relógio batiam treze horas.\"\\n    },\\n    {\\n        \"pergunta\": \"O que estava escondido em Winston Smith que tentava se movimentar?\",\\n        \"resposta\": \"Winston Smith tinha o queixo fincado no peito, numa tentativa de fugir ao vento impiedoso.\"\\n    },\\n    {\\n        \"pergunta\": \"O que Winston Smith evitou ao se mover do elevador?\",\\n        \"resposta\": \"Ele não conseguiu evitar que o acompanhasse uma onda de pó áspero.\"\\n    },\\n    {\\n        \"pergunta\": \"O que Winston Smith encontrava no saguão do apartamento?\",\\n        \"resposta\": \"O saguão cheirava a repolho cozido e a capacho de trapos.\"\\n    },\\n    {\\n        \"pergunta\": \"Descrição de um cartaz que Winston Smith encontra no saguão?\",\\n        \"resposta\": \"Fazia parecer um cartaz colorido, grande demais para exibição interna.\"\\n    },\\n    {\\n        \"pergunta\": \"Por que Winston Smith não tentou usar o elevador?\",\\n        \"resposta\": \"O elevador raramente funcionava, mesmo no tempo das vacas gordas, e agora a eletricidade era desligada durante o dia.\"\\n    },\\n    {\\n        \"pergunta\": \"Qual foi o motivo da campanha de economia descrita?\",\\n        \"resposta\": \"Foi parte da campanha preparatória para Semana do Ódio.\"\\n    },\\n    {\\n        \"pergunta\": \"A que andar Winston Smith subia o apartamento?\",\\n        \"resposta\": \"O apartamento ficava no sétimo andar.\"\\n    },\\n    {\\n        \"pergunta\": \"Qual era uma das condições de saúde de Winston Smith mencionadas no trecho?\",\\n        \"resposta\": \"Winston tinha uma varizia ulcerada acima do tornozelo direito.\"\\n    },\\n    {\\n        \"pergunta\": \"Que tipo de voz é mencionada relacionado à produção de ferro gusa?\",\\n        \"resposta\": \"Uma voz sonora lia uma lista de cifras relacionadas com a produção de ferro gusa.\"\\n    },\\n    {\\n        \"pergunta\": \"Onde estava localizado o aparelho responsável pela voz de cifras?\",\\n        \"resposta\": \"O aparelho, chamado teletela, estava embutido na parede direita.\"\\n    },\\n    {\\n        \"pergunta\": \"O que dizia a legenda do cartaz no apartamento?\",\\n        \"resposta\": \"A legenda dizia: \\'O GRANDE IRMÃO ESTÁ TE VIGIANDO.\\'\"\\n    },\\n    {\\n        \"pergunta\": \"Descreva o uniforme da figura miúda que estava na janela do apartamento. Quantas pessoas podem ser contadas em sua descrição?\",\\n        \"resposta\": \"Ela usava um macacão azul que era o uniforme do Partido.\"\\n    },\\n    {\\n        \"pergunta\": \"O que se pode observar sobre a pessoa que aparecia na janela do apartamento?\",\\n        \"resposta\": \"Ela tinha uma magreza natural que era apenas realçada pelo macacão azul.\"\\n    },\\n    {\\n        \"pergunta\": \"Quais outras características estão descritas da pessoa na janela?\",\\n        \"resposta\": \"O cabelo era muito louro, a face naturalmente sanguínea, o rosto arranhado pelo sabão ordinário, as giletes sem corte e o inverno que mal terminara.\"\\n    }\\n]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856006a5-c91c-4639-a0c4-ae3949264bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01\\n\\nERA UM DIA FRIO E ENSOLARADO DE ABRIL, E OS RELÓGIOS batiam treze horas. Winston Smith, o queixo fincado no peito, numa tentativa de fugir ao vento impiedoso, esgueirou-se rápido pelas portas de vidro do Edifício Vitória; não porém com rapidez suficiente para evitar que o acompanhasse uma onda de pó áspero. \\n\\nO saguão cheirava a repolho cozido e a capacho de trapos. Na parede do fundo fora pregado um cartaz colorido, grande demais para exibição interna. \\n\\nRepresentava apenas uma cara enorme, de mais de um metro de largura: o rosto de um homem de uns quarenta e cinco anos, com espesso bigode preto e traços rústicos mas atraentes. Winston encaminhou-se para a escada. Inútil experimentar o elevador. Raramente funcionava, mesmo no tempo das vacas gordas, e agora a eletricidade era desligada durante o dia. Fazia parte da campanha de economia, preparatória da Semana do Ódio. O apartamento ficava no sétimo andar e Winston, que tinha trinta e nove anos e uma variz ulcerada acima do tornozelo direito, subiu devagar, descansando várias vezes no caminho. Em cada patamar, diante da porta do elevador, o cartaz da cara enorme o fitava da parede. Era uma dessas figuras cujos olhos seguem a gente por toda parte. O GRANDE IRMÃO ESTÁ TE VIGIANDO, dizia a legenda. \\n\\nDentro do apartamento uma voz sonora lia uma lista de cifras relacionadas com a produção de ferro gusa. A voz saía de uma placa metálica retangular semelhante a um espelho fosco, embutido na parede direita. Winston torceu um comutador e a voz diminuiu um pouco, embora as palavras ainda fossem audíveis. O aparelho (chamava-se teletela) podia ter o volume reduzido, mas era impossível desligá-lo de vez. Winston foi até a janela: uma figura miúda, frágil, a magreza do corpo apenas realçada pelo macacão azul que era o uniforme do Partido. O cabelo era muito louro, a face naturalmente sanguínea, e a pele arranhada pelo sabão ordinário, as giletes sem corte e o inverno que mal terminara.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a64a980d-a443-4973-84de-f26631199b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"pergunta\": \"O que pode ser deduzido a partir do princípio teórico que leva às equações de Maxwell?\",\n",
      "        \"resposta\": \"A partir do mesmo procedimento estabelecido em teoria dos campos clássicos, é possível deduzir as equações de eletrodinâmica de Podolsky.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Qual é a consequência das equações de campo de Podolsky?\",\n",
      "        \"resposta\": \"A partir das equações de campo de Podolsky, é possível deduzir a equação de estado para a radiação de Podolsky.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Quais são os componentes da equação de estado de Podolsky?\",\n",
      "        \"resposta\": \"A equação de estado é do tipo P=w(a,T)ε, onde P é a pressão do gás fotônico, ε é a densidade de energia do gás fotônico, e w é o parâmetro da equação barotrópica que depende da temperatura T e da massa do fóton.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"O que a equação de estado de Podolsky permite resolver em relação à dinâmica cósmica?\",\n",
      "        \"resposta\": \"Usando a equação de estado na expressão de conservação do tensor energia-momento de fluido perfeito e na equação de Friedmann, é possível resolver a dinâmica cósmica para um universo preenchido pela radiação de Podolsky.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Qual é a relação entre a presença de fótons massivos e a dinâmica cósmica?\",\n",
      "        \"resposta\": \"A dinâmica é pouco afetada pela presença de fótons massivos, uma vez que 0,282 < wPodolsky < wMaxwell = 1/3 para qualquer valor de temperatura T, ou equivalentente, do tempo cosmológico t.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Como a correção de Podolsky para a lei de Stefan-Boltzmann é relevante?\",\n",
      "        \"resposta\": \"A correção de Podolsky para a lei de Stefan-Boltzmann é obtida para qualquer valor de temperatura, descrevendo potencialmente a dinâmica cósmica desde o universo primordial até o universo atual.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Qual é a máxima influência da massa do fóton na dinâmica de Podolsky?\",\n",
      "        \"resposta\": \"A máxima influência da massa do fóton acontece em ξref = 2,899, o que ocorre dentro de um intervalo de 0≦ξ≦8 para o parâmetro adimensional ξ=βm.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"Para que valores do parâmetro ξ ocorre a máxima influência da massa do fóton?\",\n",
      "        \"resposta\": \"A máxima influência da massa do fóton ocorre para ξref = 2,899.\"\n",
      "    },\n",
      "    {\n",
      "        \"pergunta\": \"O que acontece com a dinâmica de Podolsky quando a máxima influência da massa do fóton ocorre?\",\n",
      "        \"resposta\": \"Fora do intervalo de 0≦ξ≦8, a dinâmica de Podolsky tende à de Maxwell: nos limites de universo primordial (ξ≪1) e universo atual/futuro (ξ≫1), wPodolsky → wMaxwell e o fator de escala de Podoslsky vai com √t, de maneira consistente com um gás de fótons não massivos.\"\n",
      "    }\n",
      "]\n",
      "CPU times: user 1min 33s, sys: 16.1 ms, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "\n",
    "O mesmo procedimento estabelecido em teoria dos campos clássicos que nos leva a deduzir as equações de Maxwell, também conduz à eletrodinâmica de Podolsky, desde que a Lagrangia envolva derivadas do tensor intensidade de campo. A partir das equações de campo para Podolsky, que apresenta uma constante de acoplamento a associada à massa do fóton, é possível deduzir a equação de estado para a radiação de Podolsky. Essa equação é do tipo P=w(a,T)ε, em que P é pressão do gás fotônico; ε, a sua densidade de energia e w é o parâmetro da equação barotrópica que depende da temperatura T, além da massa do fóton. Usando essa equação de estado na expressão de conservação do tensor energia-momento de fluido perfeito e na equação de Friedmann, é possível resolver a dinâmica cósmica para um universo preenchido pela radiação de Podolsky. Mostramos que a dinâmica é pouco afetada pela presença de fótons massivos, uma vez que 0,282<wPodolsky<wMaxwell=1/3 para qualquer valor de T, ou equivalentente, do tempo cosmológico t. A correção de Podolsky para a lei de Stefan-Boltzmann é obtida para qualquer valor de temperatura, descrevendo potencialmente desde o universo primordial até o universo atual. Essa correção é relevante no intervalo 0≲ξ≲8 para o parâmetro adimensional ξ=βm. A máxima influência da massa do fóton acontece em ξref=2,899. Fora do intervalo referido intervalo de ξ, a dinâmica cosmológica de Podolsky tende à de Maxwell: nos limites de universo primordial (ξ≪1) e universo atual/futuro (ξ≫1), wPodolsky → wMaxwell e o fator de escala de Podoslsky vai com √t, de maneira consistente com um gás de fótons não massivos.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e6776d4-c617-42cc-af9a-d45bdc2b6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"pergunta\": \"Qual é a necessidade para se adentrar nos estudos cosmológicos?\",\n",
      "    \"resposta\": \"É necessário entender os desafios que tal jornada propicia.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Como é caracterizada a cosmologia em relação à natureza?\",\n",
      "    \"resposta\": \"A cosmologia é uma ciência que aborda aspectos da natureza do universo.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Quais são os desafios enfrentados na cosmologia?\",\n",
      "    \"resposta\": \"Destaca-se um enorme abismo entre a cosmologia e as demais ciências no que tange a escalas onde os fenômenos físicos ocorrem.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Quais são alguns dos fenômenos que a cosmologia estuda?\",\n",
      "    \"resposta\": \"Galáxias, aglomerados galácticos e todos objetos tais como esses.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Quais são as dimensões dos objetos estudados na cosmologia?\",\n",
      "    \"resposta\": \"Esses objetos apresentam dimensões tão superiores as escalas com que estamos habituados.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Como deve ser realizada a estudo dos objetos cosmológicos?\",\n",
      "    \"resposta\": \"Quadra estudá-los deve ser uma tarefa a ser realizada com extremo cuidado.\"\n",
      "  },\n",
      "  {\n",
      "    \"pergunta\": \"Qual método deve ser aplicado em estudos cosmológicos?\",\n",
      "    \"resposta\": \"O método científico deve ser aplicado de modo se obter resultados que independentem do senso comum humano.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(json.dumps(json.loads(result), indent=2, ensure_ascii=False))\n",
    "except:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e649f465-4f1a-4075-81b0-4876396e993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pergunta': 'Quem foi flagrado furtando um celular?',\n",
       "  'resposta': 'Um idoso.'},\n",
       " {'pergunta': 'Onde o furto ocorreu?',\n",
       "  'resposta': 'Dentro de um estúdio de tatuagem na Rua prefeito Chagas, no centro de Poços de Caldas.'},\n",
       " {'pergunta': 'Quando o furto aconteceu?',\n",
       "  'resposta': 'Na tarde desta terça-feira, dia 20 de agosto.'},\n",
       " {'pergunta': 'Qual era a razão pela qual o idoso frequentava o estúdio regularmente?',\n",
       "  'resposta': 'O idoso costuma ir ao estúdio pedir ajuda para comprar leite para o neto.'},\n",
       " {'pergunta': 'Além de pedir ajuda para leite, o que mais o idoso de aproximadamente 70 anos fazia?',\n",
       "  'resposta': 'Afirmava que pediam ajuda financeira aos comerciantes vizinhos.'},\n",
       " {'pergunta': 'O que os comerciantes faziam no momento que a ajuda foi solicitada?',\n",
       "  'resposta': 'Eles ajudavam sempre que podiam.'},\n",
       " {'pergunta': 'O que o tatuador estava fazendo quando o celular foi desaparecido?',\n",
       "  'resposta': 'O tatuador estava trabalhando e precisou usar o celular para entrar em contato com um cliente.'},\n",
       " {'pergunta': 'O que o tatuador fez após perder o celular?',\n",
       "  'resposta': 'Verificou as imagens das câmeras de segurança.'},\n",
       " {'pergunta': 'Como o idoso furtou o celular?',\n",
       "  'resposta': 'Aproveitou a situação em que uma funcionária estava servindo café e deixou o celular da empresa em cima do balcão.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5d404-3cfb-4344-9226-b0619e0bb0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df18c2d-1c95-4042-aec4-ecdf058cbc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e49774-6d3d-487d-9c0a-ddb374a6df19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca7c32-038b-4673-9d4f-8c01e345fefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c892492-8799-488b-8279-68a183cb4efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93923fdc-b92c-4b84-b371-ff630d9ebcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b312b5-e66e-4d47-99cf-0909acf76a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5cbf0-43d8-4126-bd0c-b0a972942e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fc9890-25f9-4d79-8771-02ec2153dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question = Quem saiu correndo do bar após ser preso?\n",
      "response = O jovem de 19 anos, que havia disparado a arma e repassado a arma a um segundo indivíduo, foi quem saiu correndo em direção à Rua Engenheiro Ubirajara Machado de Moraes após os disparos. No entanto, ele foi localizado e abordado pela Polícia Militar. Portanto, ninguém \"saiu correndo do bar após ser preso\", já que após serem abordados, os dois jovens foram presos.\n",
      "CPU times: user 10.2 s, sys: 6.15 s, total: 16.3 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = LanguageModel(tokenizer, model, device=\"cuda\")\n",
    "\n",
    "context = \"\"\"\n",
    "Dois jovens de 19 e 23 anos foram presos na noite desta sexta-feira,16, após disparos de arma de fogo próximo a um bar em Poços de Caldas.\n",
    "\n",
    "Segundo a Polícia Militar, durante uma operação na Avenida Marechal Castelo Branco, no bairro Jardim São Paulo, os policiais ouviram dois disparos de arma de fogo.\n",
    "\n",
    "Clique aqui e participe do grupo de notícias da Onda Poços no WhatsApp\n",
    "\n",
    "Em seguida foi recebida uma denúncia, via 190, relatando que o jovem de 19 anos trajando camiseta do flamengo havia efetuado dois disparos de arma de fogo próximo a um bar e que ele havia repassado a arma a um segundo indivíduo que trajava blusa com capuz preta e bermuda de cor preta, que após pegar arma saiu correndo em direção à Rua Engenheiro Ubirajara Machado de Moraes.\n",
    "\n",
    " \n",
    "\n",
    "Ainda segundo a PM, o jovem de 19 anos já conhecido no meio policial por posse ilegal de arma e tráfico de drogas, foi localizado e abordado.\n",
    "\n",
    " \n",
    "\n",
    "Uma outra equipe da Polícia Militar recebeu denúncias, via 190, de que o segundo suspeito que havia fugido do local com a arma de fogo, a deixou em uma lixeira na Rua Abrieiro. A arma foi apreendida.\n",
    "\n",
    " \n",
    "\n",
    "Ainda segundo a PM, após capturar o primeiro suspeito, a equipe continuou o rastreamento para localizar o segundo envolvido. O jovem foi encontrado ao final da Rua Engenheiro Ubirajara Machado de Moraes com as mesmas vestes repassadas pela denúncia.\n",
    "\n",
    " \n",
    "A arma de fogo se tratava de um revólver calibre 38 marca Taurus, que foi apreendida. Ainda segundo a PM, no local e nas adjacências não foram localizadas vítimas e não foi detectado o local exato em que o projétil atingiu.\n",
    "\n",
    "A dupla foi presa, encaminhada à UPA e em seguida levada para a Delegacia de Polícia Civil.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"content\": \"Você é um assistente especializado em interpretação de texto\",\n",
    "        \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "        \"content\": f\"Gere uma pergunta para o seguinte contexto:\\n```\\n{context}\\n```\\nPergunta:\",\n",
    "        \"role\": \"user\"\n",
    "    },\n",
    "]\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    # model.generate(**tokenizer(\"test\", return_tensors=\"pt\").to(\"cuda\"))\n",
    "    question = llm.generate(messages)\n",
    "    print(\"question =\", question)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Dado o seguinte contexto ```{context}``` responda a pergunta: `{question}`.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"response =\", completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71fbd99d-e4ad-4791-b4f3-6ff8b2e526c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "00c0e518-8837-4c5b-917c-0fc01a572f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def get_list(texto):\n",
    "    resultado = re.search(r'\\[([\\s\\S]*)\\]', texto)\n",
    "    if resultado:\n",
    "        conteudo = resultado.group(1)\n",
    "        return json.loads(f\"[{conteudo}]\")\n",
    "    else:\n",
    "        return \"Nenhum conteúdo encontrado entre os colchetes.\"\n",
    "\n",
    "\n",
    "\n",
    "def get_questions(context):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    prompt_text = f\"\"\"\n",
    "    Dado o seguinte contexto:\n",
    "    ```\n",
    "    {context}\n",
    "    ```\n",
    "    Escreva um conjunto de perguntas e respostas sobre o contexto.\n",
    "    As perguntas devem ser tais que, concatenando as respostas, seja possível recuperar o conteúdo completo do contexto.\n",
    "    As perguntas deve ser autocontidas; ou seja, um leitor deve entendê-la sem neessariamente conhecer o contexto\n",
    "\n",
    "    \n",
    "    \n",
    "    # Formato de saída:\n",
    "    O resultado deve ser parseavel em json:\n",
    "\n",
    "    ```\n",
    "    [\n",
    "     {{\"pergunta\": \"<<pergunta 1>>\", \"pergunta\": \"<<resposta 1>>\"}},\n",
    "     {{\"pergunta\": \"<<pergunta 2>>\", \"pergunta\": \"<<resposta 2>>\"}},\n",
    "     ...\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=prompt_text)\n",
    "    ])\n",
    "    \n",
    "    chain = chat_prompt | llm\n",
    "    \n",
    "    with get_openai_callback() as cb:\n",
    "        response = chain.invoke(dict(context=context))\n",
    "        preco_real = 5.7 * (0.15 * cb.prompt_tokens+ 0.6*cb.completion_tokens) / 1_000_000\n",
    "        print(f\"preco = {preco_real}\")\n",
    "        \n",
    "    return get_list(response.content), preco_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3da1a6-cc48-449d-8afe-c2b7505f6467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf1155-450b-47b2-b1a0-839f39e3f003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c95fa-8293-4a86-bc79-c8581cd54a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cc9b34e-1fc8-4a9b-9af2-b342e725295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response = [\n",
      " {\"Qual foi o maior obstáculo para o estudo dos fenômenos cósmicos até algumas décadas atrás?\": \"A ausência de dados.\"},\n",
      " {\"O que ditava as características dos modelos elaborados antes das profundas alterações na cosmologia?\": \"Aspectos filosóficos.\"},\n",
      " {\"Qual foi o objetivo de Einstein ao adicionar a constante cosmológica em suas equações da Relatividade Geral?\": \"Descrever um universo estático, em equilíbrio (instável).\"},\n",
      " {\"Quem abandonou a premissa de um universo estático e qual foi sua contribuição?\": \"Alexander Friedmann, que encontrou a descrição analítica de um universo dinâmico.\"},\n",
      " {\"O que as soluções das equações de campo da Relatividade Geral de Friedmann descrevem?\": \"A evolução de um universo proveniente de uma singularidade.\"},\n",
      " {\"Quem cunhou o termo 'átomo primordial' para descrever o modelo dinâmico do universo de Friedmann?\": \"Georges Lemaître.\"},\n",
      " {\"Em que ano Georges Lemaître encontrou uma solução dinâmica para a evolução do universo?\": \"1927.\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "A ciência da cosmologia sofreu profundas alterações nas últimas décadas. Até então,\n",
    "a ausência de dados era o maior obstáculo para o estudo dos fenômenos cósmicos. Muitas\n",
    "das vezes, eram os aspectos filosóficos que ditavam as características de modelos elaborados.\n",
    "Como exemplo, temos o acréscimo da constante cosmológica por Einstein em suas equações\n",
    "da Relatividade Geral com o objetivo de descrição de um universo estático, em equilíbrio\n",
    "(instável)(EINSTEIN, 1918). Em contrapartida, Alexander Friedmann abandonou a premissa de um universo estático e encontrou a descrição analítica de um universo dinâmico\n",
    "perante a solução das equações de campo da Relatividade Geral (FRIEDMANN, 1922;\n",
    "FRIEDMANN, 1924). Tal modelo descreve a evolução de um universo proveniente de uma\n",
    "singularidade, que posteriormente seria cunhado por Lemaître como o átomo primordial.\n",
    "Uma solução dinâmica para a evolução do universo foi encontrada também por Georges\n",
    "Lemaître em 1927 (LEMAÎTRE, 1927).\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Dado o seguinte contexto:\n",
    "```\n",
    "{context}\n",
    "```\n",
    "Escreva um conjunto de perguntas e respostas sobre o contexto. As perguntas devem ser tais que, concatenando as respostas, seja possível recuperar o conteúdo completo do contexto\n",
    "\n",
    "# Formato de saída:\n",
    "\n",
    "[\n",
    " {{\"pergunta_1\": \"resposta_1\"}},\n",
    " {{\"pergunta_2\": \"resposta_2\"}},\n",
    " {{\"pergunta_3\": \"resposta_3\"}},\n",
    " ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"response =\", completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e5ce2dd-11d5-4702-9a6b-4228ea15408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preco = 0.0015313049999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pergunta': 'Quais foram as principais mudanças na ciência da cosmologia nas últimas décadas?',\n",
       "  'resposta': 'A ciência da cosmologia sofreu profundas alterações, com a superação da ausência de dados que antes era o maior obstáculo para o estudo dos fenômenos cósmicos.'},\n",
       " {'pergunta': 'Como os aspectos filosóficos influenciaram os modelos cosmológicos anteriormente?',\n",
       "  'resposta': 'Os aspectos filosóficos muitas vezes ditavam as características de modelos elaborados, como no caso do acréscimo da constante cosmológica por Einstein para descrever um universo estático.'},\n",
       " {'pergunta': 'Qual foi a contribuição de Einstein para a cosmologia?',\n",
       "  'resposta': 'Einstein acrescentou a constante cosmológica em suas equações da Relatividade Geral com o objetivo de descrever um universo estático em equilíbrio.'},\n",
       " {'pergunta': 'Quem foi Alexander Friedmann e qual foi sua contribuição para a cosmologia?',\n",
       "  'resposta': 'Alexander Friedmann abandonou a ideia de um universo estático e encontrou a descrição analítica de um universo dinâmico com base nas equações de campo da Relatividade Geral.'},\n",
       " {'pergunta': 'Como Friedmann descreveu a evolução do universo?',\n",
       "  'resposta': 'Friedmann descreveu a evolução do universo como proveniente de uma singularidade, que mais tarde seria denominado por Lemaître como o átomo primordial.'},\n",
       " {'pergunta': 'Qual outra solução dinâmica para a evolução do universo foi encontrada e por quem?',\n",
       "  'resposta': 'Georges Lemaître também encontrou uma solução dinâmica para a evolução do universo em 1927.'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "context = \"\"\"\n",
    "A ciência da cosmologia sofreu profundas alterações nas últimas décadas. Até então,\n",
    "a ausência de dados era o maior obstáculo para o estudo dos fenômenos cósmicos. Muitas\n",
    "das vezes, eram os aspectos filosóficos que ditavam as características de modelos elaborados.\n",
    "Como exemplo, temos o acréscimo da constante cosmológica por Einstein em suas equações\n",
    "da Relatividade Geral com o objetivo de descrição de um universo estático, em equilíbrio\n",
    "(instável)(EINSTEIN, 1918). Em contrapartida, Alexander Friedmann abandonou a premissa de um universo estático e encontrou a descrição analítica de um universo dinâmico\n",
    "perante a solução das equações de campo da Relatividade Geral (FRIEDMANN, 1922;\n",
    "FRIEDMANN, 1924). Tal modelo descreve a evolução de um universo proveniente de uma\n",
    "singularidade, que posteriormente seria cunhado por Lemaître como o átomo primordial.\n",
    "Uma solução dinâmica para a evolução do universo foi encontrada também por Georges\n",
    "Lemaître em 1927 (LEMAÎTRE, 1927).\n",
    "\"\"\"\n",
    "\n",
    "response, preco_real = get_questions(context)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "620cb098-156a-4b4f-9410-1c700d18d217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3226fc34bcbc470391e19ec50b7631a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd41b8fd51054a65b3fe04fa0e23878f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56398aad63a4ac0a761cffbf5a90247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.95M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100c4a09bbe940759eee87ada1a6ef6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf84f6483d7456ba43c1099e3582046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7a431ae5ed42938060465b4f1fa91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08cbf4c0ffd43b8a7861ee80a6bec7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "columns = ['id', 'context', 'question','response']\n",
    "train_dataset = dataset[\"train\"].shuffle(42).select(range(5000)).select_columns(columns)\n",
    "test_dataset = dataset[\"validation\"].shuffle(42).select(range(100)).select_columns(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19610fbb-fbf7-42e0-85b6-396c2dd5baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f59e7ab2-d718-4574-ae0f-20a5ceef747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como nas outras línguas românicas ocidentais, a principal expressão plural é o sufixo -s, que pode criar alternâncias morfológicas semelhantes às encontradas na inflexão de gênero, embora mais raramente. O mais importante é o acréscimo, antes de certos grupos de consoantes, a um fenómeno fonético que não afeta as formas femininas: el pols / els polsos (&quot;o pulso&quot; / &quot;os pulsos&quot;) vs. la pols / les pols ( &quot;a poeira&quot; / &quot;as poeiras&quot;).\n",
      "\n",
      "preco = 0.0010225800000000001\n",
      "\n",
      "[{'pergunta': 'Qual é a principal expressão plural nas línguas românicas ocidentais?', 'resposta': 'O sufixo -s.'}, {'pergunta': 'O que o sufixo -s pode criar nas línguas românicas ocidentais?', 'resposta': 'Alternâncias morfológicas semelhantes às encontradas na inflexão de gênero.'}, {'pergunta': 'O fenômeno fonético que afeta a formação do plural nas línguas românicas ocidentais tem impacto nas formas femininas?', 'resposta': 'Não, ele não afeta as formas femininas.'}, {'pergunta': 'Dê um exemplo de como o sufixo -s é aplicado a palavras masculinas e femininas.', 'resposta': \"Por exemplo, 'el pols' se torna 'els polsos' (o pulso / os pulsos) e 'la pols' se torna 'les pols' (a poeira / as poeiras).\"}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e012ccff-9ce9-460c-9faa-aa5874918756",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in test_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ce232-3a82-4990-993d-65191bae29de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a563f31-35be-4da1-bfd7-5d73a0b28d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 17\n",
      "\tPrompt Tokens: 8\n",
      "\tCompletion Tokens: 9\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f10658-6046-49c9-b918-1577b2e1f845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
