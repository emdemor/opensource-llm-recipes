{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b50a112-75c6-489c-a717-94c7e9324ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from datasets import load_from_disk, load_dataset, concatenate_datasets\n",
    "\n",
    "load_from_hub = True\n",
    "\n",
    "dataset_id = \"clips/mqa\"\n",
    "dataset_filepath = \"data/clips_mqa/pt\"\n",
    "\n",
    "blacklist_domains = [\n",
    "    \"ti-enxame.com\",\n",
    "]\n",
    "\n",
    "prohibited_terms = [\"href\", \"https\", \"www.\", \".html\", \"volumen caps\"]\n",
    "\n",
    "\n",
    "def format_dataset(row):\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"question\": row[\"name\"],\n",
    "        \"domain\": row[\"domain\"],\n",
    "        \"answer\": row[\"answers\"][0][\"text\"],\n",
    "    }\n",
    "\n",
    "def contains_prohibited_term_regex(text):\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, prohibited_terms)))\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def remove_links(text):\n",
    "    url_regex = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_regex, '', text)\n",
    "\n",
    "def remove_non_alphanumeric(text):\n",
    "    return re.sub(r'[^\\w\\s.,!?;:\\'\\\"-]', '', text)\n",
    "\n",
    "def remove_long_words(text, max_length=15):\n",
    "    # Expressão regular para encontrar substrings com mais de 15 caracteres consecutivos\n",
    "    pattern = r'\\S{' + str(max_length + 1) + r',}'\n",
    "    # Substituir as substrings que correspondem ao padrão por uma string vazia\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def check_if_question_is_big_enough(text):\n",
    "    if len(text) < 20:\n",
    "        return False\n",
    "    elif 20 <= len(text) <= 30:\n",
    "        if \"?\" in text[-3:]:\n",
    "            return True\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def format_text_fields(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = remove_long_words(text)\n",
    "    text = remove_non_alphanumeric(text)\n",
    "    text = remove_links(text)\n",
    "    text = text.replace(\"--\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"](\", \"\")\n",
    "    text = text.replace(\" [\", \"\")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def format_text(row):\n",
    "    return {\n",
    "        \"text\": format_text_fields(row[\"text\"]),\n",
    "        \"question\": format_text_fields(row[\"question\"]),\n",
    "        \"answer\": format_text_fields(row[\"answer\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "if load_from_hub:\n",
    "    raw_dataset = load_dataset(dataset_id, language=\"pt\", trust_remote_code=True)[\"train\"]\n",
    "    raw_dataset = raw_dataset.filter(lambda row: row[\"answers\"][0][\"is_accepted\"] == True)\n",
    "    raw_dataset = raw_dataset.filter(lambda row: row[\"domain\"] not in blacklist_domains)\n",
    "    raw_dataset = raw_dataset.filter(lambda row: not contains_prohibited_term_regex(row[\"answers\"][0][\"text\"]) )\n",
    "    raw_dataset = raw_dataset.filter(lambda row: not contains_prohibited_term_regex(row[\"name\"]) )\n",
    "    raw_dataset = raw_dataset.filter(lambda row: not contains_prohibited_term_regex(row[\"text\"]) )\n",
    "    raw_dataset = raw_dataset.filter(lambda row: check_if_question_is_big_enough(row[\"name\"]) )\n",
    "    raw_dataset = raw_dataset.filter(lambda row: len(row[\"answers\"][0][\"text\"]) > 0)\n",
    "    raw_dataset = raw_dataset.map(format_dataset)\n",
    "    dataset = raw_dataset.map(format_text).select_columns(['id', 'bucket', 'domain', 'text', 'question', 'answer'])\n",
    "    dataset = dataset.filter(lambda row: check_if_question_is_big_enough(row[\"question\"]) )\n",
    "    dataset.save_to_disk(dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2ee810-b6ed-46fa-bed9-a344b9d5285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac639270-56e0-472e-8acc-f2e746b768a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
