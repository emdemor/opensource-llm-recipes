{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f0b627-c0af-418f-967b-210835a2d6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:01.410439Z",
     "iopub.status.busy": "2024-09-16T01:53:01.409934Z",
     "iopub.status.idle": "2024-09-16T01:53:02.926907Z",
     "shell.execute_reply": "2024-09-16T01:53:02.926410Z",
     "shell.execute_reply.started": "2024-09-16T01:53:01.410416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56764ffc-28b2-4be5-8cd1-c8725fef6bdb",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2dd3d70-5682-4229-9ac8-21cee59c9855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:04.218894Z",
     "iopub.status.busy": "2024-09-16T01:53:04.218468Z",
     "iopub.status.idle": "2024-09-16T01:53:04.222982Z",
     "shell.execute_reply": "2024-09-16T01:53:04.222546Z",
     "shell.execute_reply.started": "2024-09-16T01:53:04.218870Z"
    }
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def get_youtube_video_title(url):\n",
    "    ydl_opts = {}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        video_title = info_dict.get('title', None)\n",
    "    return video_title\n",
    "\n",
    "def get_youtube_video_metadata(video_url):\n",
    "    ydl_opts = {\n",
    "        'skip_download': True,  # Não baixa o vídeo\n",
    "        'extract_flat': True,   # Não extrai streams de mídia, só metadados\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "    return info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef91b04b-62d6-460e-9472-6336a2fb1984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:05.713606Z",
     "iopub.status.busy": "2024-09-16T01:53:05.712464Z",
     "iopub.status.idle": "2024-09-16T01:53:05.720153Z",
     "shell.execute_reply": "2024-09-16T01:53:05.718825Z",
     "shell.execute_reply.started": "2024-09-16T01:53:05.713543Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f44d2ebe-2545-4918-87a1-690670cc8da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:42:00.397142Z",
     "iopub.status.busy": "2024-09-16T01:42:00.396951Z",
     "iopub.status.idle": "2024-09-16T01:42:00.400109Z",
     "shell.execute_reply": "2024-09-16T01:42:00.399740Z",
     "shell.execute_reply.started": "2024-09-16T01:42:00.397127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ab5cd-2083-4497-ae2e-769b2048a914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f82aa4-2244-4433-ad68-0b70d8148135",
   "metadata": {},
   "source": [
    "# Fazendo download de vídeo do youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae177e7a-55f5-487b-8850-31bb2f1c839d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:27.563138Z",
     "iopub.status.busy": "2024-09-16T01:53:27.562853Z",
     "iopub.status.idle": "2024-09-16T01:53:27.565990Z",
     "shell.execute_reply": "2024-09-16T01:53:27.565565Z",
     "shell.execute_reply.started": "2024-09-16T01:53:27.563117Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEO_URL = 'https://www.youtube.com/watch?v=tvIzBouq6lk'\n",
    "TRANSCRIPTION_LANGUAGE = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a6135-a59d-40e2-8ce7-a9ec8e5132a4",
   "metadata": {},
   "source": [
    "#### Obtendo o nome do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5578940-210c-4847-a566-866aa760a530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:28.283305Z",
     "iopub.status.busy": "2024-09-16T01:53:28.281799Z",
     "iopub.status.idle": "2024-09-16T01:53:31.081629Z",
     "shell.execute_reply": "2024-09-16T01:53:31.081004Z",
     "shell.execute_reply.started": "2024-09-16T01:53:28.283220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tvIzBouq6lk\n",
      "[youtube] tvIzBouq6lk: Downloading webpage\n",
      "[youtube] tvIzBouq6lk: Downloading ios player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading web creator player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading m3u8 information\n"
     ]
    }
   ],
   "source": [
    "video_metadata = get_youtube_video_metadata(VIDEO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4ba264-b5bb-450a-9a38-210ad0c12ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:53:33.428380Z",
     "iopub.status.busy": "2024-09-16T01:53:33.428001Z",
     "iopub.status.idle": "2024-09-16T01:53:33.434035Z",
     "shell.execute_reply": "2024-09-16T01:53:33.433512Z",
     "shell.execute_reply.started": "2024-09-16T01:53:33.428362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1068ae-ce69-4c64-bf5a-6534788836f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7f9528-5b15-4329-880a-37e5395ef8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T02:12:50.213250Z",
     "iopub.status.busy": "2024-09-16T02:12:50.212845Z",
     "iopub.status.idle": "2024-09-16T02:12:50.217197Z",
     "shell.execute_reply": "2024-09-16T02:12:50.216738Z",
     "shell.execute_reply.started": "2024-09-16T02:12:50.213231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título do vídeo:\n",
      "\t\"NLP Demystified 14: Machine Translation With Sequence-to-Sequence and Attention\"\n",
      "Formated label:\n",
      "\t\"nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Seq2Seq and Attention',\n",
       " 'Seq2Seq as a general problem-solving approach',\n",
       " 'Translating language with a seq2seq model',\n",
       " 'Machine translation challenges',\n",
       " 'Effective decoding with Beam Search',\n",
       " 'Evaluating translation models with BLEU',\n",
       " 'The information bottleneck',\n",
       " 'Overcoming the bottleneck with Attention',\n",
       " 'Additive vs Multiplicative Attention',\n",
       " '[DEMO] Neural Machine Translation WITHOUT Attention',\n",
       " '[DEMO] Neural Machine Translation WITH Attention',\n",
       " 'Attention as information retrieval']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_title = video_metadata[\"title\"]\n",
    "\n",
    "print(f'Título do vídeo:\\n\\t\"{video_title}\"')\n",
    "video_title = remove_special_characters(video_title).lower().replace(\" \",\"-\")\n",
    "print(f'Formated label:\\n\\t\"{video_title}\"')\n",
    "\n",
    "chapters = [c[\"title\"] for c in video_metadata[\"chapters\"]]\n",
    "\n",
    "chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d71f26-906a-41d0-8252-b3e18aad5ee8",
   "metadata": {},
   "source": [
    "#### Download do vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830062ee-31e5-4af6-bcba-d1583cec42eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T23:59:22.312681Z",
     "iopub.status.busy": "2024-09-15T23:59:22.311951Z",
     "iopub.status.idle": "2024-09-16T00:00:55.203089Z",
     "shell.execute_reply": "2024-09-16T00:00:55.202586Z",
     "shell.execute_reply.started": "2024-09-15T23:59:22.312653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tvIzBouq6lk\n",
      "[youtube] tvIzBouq6lk: Downloading webpage\n",
      "[youtube] tvIzBouq6lk: Downloading ios player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading web creator player API JSON\n",
      "[youtube] tvIzBouq6lk: Downloading m3u8 information\n",
      "[info] tvIzBouq6lk: Downloading 1 format(s): 251\n",
      "[download] Destination: data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.webm\n",
      "[download] 100% of   62.43MiB in 00:00:26 at 2.33MiB/s     \n",
      "[ExtractAudio] Destination: data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.mp3\n",
      "Deleting original file data/nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention.webm (pass -k to keep)\n",
      "CPU times: user 1.84 s, sys: 365 ms, total: 2.2 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl': f'data/{video_title}.%(ext)s',\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([VIDEO_URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96738107-bdc4-4757-bd88-b62fbb249809",
   "metadata": {},
   "source": [
    "# Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871407ca-15bf-466d-97c6-74d4dbf701bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:01:16.679787Z",
     "iopub.status.busy": "2024-09-16T00:01:16.677653Z",
     "iopub.status.idle": "2024-09-16T00:01:16.690865Z",
     "shell.execute_reply": "2024-09-16T00:01:16.688686Z",
     "shell.execute_reply.started": "2024-09-16T00:01:16.679663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large']\n"
     ]
    }
   ],
   "source": [
    "print(whisper.available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e61baf-fd5e-464a-9b18-98920afb14d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:01:18.562920Z",
     "iopub.status.busy": "2024-09-16T00:01:18.562491Z",
     "iopub.status.idle": "2024-09-16T00:01:35.897875Z",
     "shell.execute_reply": "2024-09-16T00:01:35.897327Z",
     "shell.execute_reply.started": "2024-09-16T00:01:18.562892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 3.27 s, total: 25.6 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c0edca-2fb1-4a66-be14-af99e354334b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T00:03:15.636010Z",
     "iopub.status.busy": "2024-09-16T00:03:15.635495Z",
     "iopub.status.idle": "2024-09-16T00:17:15.768948Z",
     "shell.execute_reply": "2024-09-16T00:17:15.768427Z",
     "shell.execute_reply.started": "2024-09-16T00:03:15.635988Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 6s, sys: 3.32 s, total: 14min 9s\n",
      "Wall time: 14min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_filename = f\"data/{video_title}.mp3\"\n",
    "raw_text_filename = f\"data/raw_{video_title}.txt\"\n",
    "\n",
    "\n",
    "result = model.transcribe(audio_filename, language=TRANSCRIPTION_LANGUAGE)\n",
    "\n",
    "with open(raw_text_filename, \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15106857-5705-4b61-b3d3-08c7e843b612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:20.746034Z",
     "iopub.status.busy": "2024-09-16T01:28:20.745768Z",
     "iopub.status.idle": "2024-09-16T01:28:20.826542Z",
     "shell.execute_reply": "2024-09-16T01:28:20.825023Z",
     "shell.execute_reply.started": "2024-09-16T01:28:20.746013Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258559d6-e88d-4ab8-9143-9b6fecdb87b5",
   "metadata": {},
   "source": [
    "# Sintetizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4593f4d0-8467-48a6-81e4-be462252d54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T02:30:06.873005Z",
     "iopub.status.busy": "2024-09-16T02:30:06.872773Z",
     "iopub.status.idle": "2024-09-16T02:30:06.921589Z",
     "shell.execute_reply": "2024-09-16T02:30:06.921067Z",
     "shell.execute_reply.started": "2024-09-16T02:30:06.872988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.6 ms, sys: 2.13 ms, total: 45.8 ms\n",
      "Wall time: 45.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "INPUT_PRICE = 0.150 # per million\n",
    "OUTPUT_PRICE = 0.600 # per million\n",
    "\n",
    "\n",
    "raw_text_filename = f\"data/raw_{video_title}.txt\"\n",
    "summary_directory = f\"data/summary-{video_title}\"\n",
    "\n",
    "Path(summary_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "text_template = (\n",
    "    \"Considere o seguinte texto:\\n\"\n",
    "    \"<text>{text}</text>\\n\"\n",
    "    f\"Ele tem os seguintes capítulos: {str(chapters)}. \\n\"\n",
    "    \"Sua tarefa: Gere um texto didático em markdown que explique em detalhes o capítulo `{chapter}`.\\n\"\n",
    "    \"Instruções:\"\n",
    "    \"1. A hierarquia máxima de títulos no markdown deve ser `##`.\\n\"\n",
    "    \"2. Retorne apenas o código markdown.\\n\"\n",
    "    \"3. Não retorne os delimitadores de bloco de código.\\n\"\n",
    "    \"4. Não economize nas explicações\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\", \"chapter\"], template=text_template)\n",
    "llm = ChatOpenAI(temperature=0, model=LLM_MODEL)\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acf6ad26-0998-4d39-a033-64e4a2b354cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T02:31:59.158542Z",
     "iopub.status.busy": "2024-09-16T02:31:59.158349Z",
     "iopub.status.idle": "2024-09-16T02:34:20.144898Z",
     "shell.execute_reply": "2024-09-16T02:34:20.144478Z",
     "shell.execute_reply.started": "2024-09-16T02:31:59.158526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custo = 0.199 | Percentual: 100%|█████████████████████████| 12/12 [02:20<00:00, 11.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(raw_text_filename, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "cost = 0\n",
    "\n",
    "with tqdm(total=len(chapters)) as pbar:\n",
    "    pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "    \n",
    "    for i, chapter in enumerate(chapters):\n",
    "        md_filename = f\"{summary_directory}/{str(i+1).zfill(2)}-{chapter}.md\"\n",
    "        with get_openai_callback() as cb:\n",
    "            summary = chain.invoke({\"text\": text, \"chapter\": chapter})\n",
    "            cost += cb.total_cost\n",
    "\n",
    "        md_content = f\"# {i+1} - {chapter}\\n\\n{summary.content}\"\n",
    "        with open(md_filename, \"w\") as f:\n",
    "            f.write(md_content)\n",
    "        \n",
    "        pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "        pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66457862-247a-48c8-8749-578ad74b9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T02:44:19.815113Z",
     "iopub.status.busy": "2024-09-16T02:44:19.814029Z",
     "iopub.status.idle": "2024-09-16T02:44:19.821491Z",
     "shell.execute_reply": "2024-09-16T02:44:19.821098Z",
     "shell.execute_reply.started": "2024-09-16T02:44:19.815025Z"
    }
   },
   "outputs": [],
   "source": [
    "md_content = [video_metadata[\"title\"]]\n",
    "for i, chapter in enumerate(chapters):\n",
    "    md_chapter_filename = f\"{summary_directory}/{str(i+1).zfill(2)}-{chapter}.md\"\n",
    "    with open(md_chapter_filename, \"r\") as f:\n",
    "        chapter_content = f.read()\n",
    "    md_content.append(chapter_content)\n",
    "\n",
    "full_summary_filepath = f\"{summary_directory}/complete-summary.md\"\n",
    "with open(full_summary_filepath, \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(md_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41b90ba7-a8fd-4025-b9ed-897a3da0dec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T02:44:22.850785Z",
     "iopub.status.busy": "2024-09-16T02:44:22.849587Z",
     "iopub.status.idle": "2024-09-16T02:44:22.855852Z",
     "shell.execute_reply": "2024-09-16T02:44:22.854923Z",
     "shell.execute_reply.started": "2024-09-16T02:44:22.850653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/summary-nlp-demystified-14-machine-translation-with-sequencetosequence-and-attention/complete-summary.md'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_summary_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4920ac1-6680-46e8-b7fd-7594200c68a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T03:29:04.430683Z",
     "iopub.status.busy": "2024-09-15T03:29:04.430440Z",
     "iopub.status.idle": "2024-09-15T03:29:04.433351Z",
     "shell.execute_reply": "2024-09-15T03:29:04.432882Z",
     "shell.execute_reply.started": "2024-09-15T03:29:04.430667Z"
    }
   },
   "source": [
    "# Traduzindo o texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a6dbee-fb9a-4639-a112-f698cd221c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:28.163731Z",
     "iopub.status.busy": "2024-09-16T01:28:28.163524Z",
     "iopub.status.idle": "2024-09-16T01:28:28.814401Z",
     "shell.execute_reply": "2024-09-16T01:28:28.813880Z",
     "shell.execute_reply.started": "2024-09-16T01:28:28.163707Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "INPUT_PRICE = 0.150 # per million\n",
    "OUTPUT_PRICE = 0.600 # per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e0023b-1b8a-4252-ae3b-7d4d2e77b737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T01:28:29.766211Z",
     "iopub.status.busy": "2024-09-16T01:28:29.765920Z",
     "iopub.status.idle": "2024-09-16T01:28:29.775844Z",
     "shell.execute_reply": "2024-09-16T01:28:29.775381Z",
     "shell.execute_reply.started": "2024-09-16T01:28:29.766187Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "book = TextLoader(raw_text_filename).load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3fa82f5-baad-411c-9173-d6098caee8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:27:39.715102Z",
     "iopub.status.busy": "2024-09-15T04:27:39.714880Z",
     "iopub.status.idle": "2024-09-15T04:30:01.354141Z",
     "shell.execute_reply": "2024-09-15T04:30:01.353352Z",
     "shell.execute_reply.started": "2024-09-15T04:27:39.715087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custo = 0.0686 | Percentual: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [02:21<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 799 ms, sys: 299 ms, total: 1.1 s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "Path(f\"data/translate-{video_title}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "text_template = (\n",
    "    \"Traduza o seguinte para português, mantendo os jargões técnicos em inglês. Não retorne nada exceto a tradução:\\n\"\n",
    "\n",
    "    \"{text}\"\n",
    "\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=text_template)\n",
    "llm = ChatOpenAI(temperature=0, model=LLM_MODEL)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "cost = 0\n",
    "with tqdm(total=len(paragraphs)) as pbar:\n",
    "    pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        with get_openai_callback() as cb:\n",
    "            summary = chain.invoke({\"text\": p.page_content+\". \"})\n",
    "            cost += cb.total_cost\n",
    "    \n",
    "        with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"w\") as f:\n",
    "            f.write(summary.content)\n",
    "        \n",
    "        pbar.set_description(f\"Custo = {round(cost*6, 4)} | Percentual\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb61fe68-578c-4620-934c-61030d4d678b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T04:32:53.381649Z",
     "iopub.status.busy": "2024-09-15T04:32:53.381401Z",
     "iopub.status.idle": "2024-09-15T04:32:53.385504Z",
     "shell.execute_reply": "2024-09-15T04:32:53.385105Z",
     "shell.execute_reply.started": "2024-09-15T04:32:53.381632Z"
    }
   },
   "outputs": [],
   "source": [
    "text_pieces = []\n",
    "for i, p in enumerate(paragraphs):\n",
    "    with open(f\"data/translate-{video_title}/{str(i).zfill(2)}.txt\", \"r\") as f:\n",
    "        text_pieces.append(f.read())\n",
    "\n",
    "text = \" \".join(text_pieces)\n",
    "\n",
    "with open(f\"data/translated-{video_title}.txt\", \"w\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8ab41-4f54-4eeb-925d-40d341f17429",
   "metadata": {},
   "source": [
    "# Gerando Questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616d9cb-d94e-48a9-b617-03aaa54d51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adb2089a-d79f-4d1b-9d6d-58834bdd0e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:30:07.005441Z",
     "iopub.status.busy": "2024-09-15T15:30:07.005203Z",
     "iopub.status.idle": "2024-09-15T15:30:07.009880Z",
     "shell.execute_reply": "2024-09-15T15:30:07.009360Z",
     "shell.execute_reply.started": "2024-09-15T15:30:07.005424Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, tokenizer, model, device):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def tokenize(self, messages):\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "        return model_inputs\n",
    "\n",
    "    def generate(self, messages, max_new_tokens=2000, **kwargs):\n",
    "        model_inputs = self.tokenize(messages)\n",
    "        model_inputs[\"attention_mask\"] = model_inputs[\"attention_mask\"].to(\n",
    "            model_inputs[\"input_ids\"].device\n",
    "        )\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            **kwargs\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a490df8-76aa-4429-a288-5697639460f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:31:26.893324Z",
     "iopub.status.busy": "2024-09-15T15:31:26.893044Z",
     "iopub.status.idle": "2024-09-15T15:31:26.895757Z",
     "shell.execute_reply": "2024-09-15T15:31:26.895305Z",
     "shell.execute_reply.started": "2024-09-15T15:31:26.893305Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_dtype = torch.float16\n",
    "attn_implementation = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "659525d3-2de6-4c29-b975-a5a5f6549160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:32:47.655512Z",
     "iopub.status.busy": "2024-09-15T15:32:47.655038Z",
     "iopub.status.idle": "2024-09-15T15:33:11.149080Z",
     "shell.execute_reply": "2024-09-15T15:33:11.148452Z",
     "shell.execute_reply.started": "2024-09-15T15:32:47.655469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e986dfd1473147d79c64399bb77caf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d342f566bba04251ad1c94d4603cadb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "login(token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "\n",
    "model_id = \"emdemor/question-generator-v2\"\n",
    "commit_hash = None\n",
    "\n",
    "\n",
    "# A quantização é uma técnica para reduzir o tamanho do modelo e aumentar a eficiência computacional.\n",
    "# Utilizamos a classe BitsAndBytesConfig para configurar a quantização em 4 bits, o que reduz o uso de memória e acelera o treinamento.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Usamos a classe AutoModelForCausalLM para carregar um modelo pré-treinado adequado para modelagem de linguagem causal.\n",
    "# Parâmetros importantes incluem:\n",
    "#  - torch_dtype=compute_dtype: Define o tipo de dado para o modelo.\n",
    "#  - quantization_config=bnb_config: Aplica a configuração de quantização.\n",
    "#  - device_map=\"auto\": Distribui automaticamente o modelo nos dispositivos disponíveis.\n",
    "#  - attn_implementation=attn_implementation: Define a implementação da atenção.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=compute_dtype,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    revision=commit_hash,\n",
    ")\n",
    "\n",
    "# # adapta o modelo para o treinamento em k-bits, otimizando ainda mais o desempenho.\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "def set_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=commit_hash)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "tokenizer = set_tokenizer(model_id)\n",
    "\n",
    "llm = LanguageModel(tokenizer, model, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f56cf17-ef19-4c30-b085-ff7b9a22b736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:15.532420Z",
     "iopub.status.busy": "2024-09-15T15:36:15.532093Z",
     "iopub.status.idle": "2024-09-15T15:36:15.534942Z",
     "shell.execute_reply": "2024-09-15T15:36:15.534567Z",
     "shell.execute_reply.started": "2024-09-15T15:36:15.532402Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_question(context, temperature=0.01):\n",
    "    return llm.generate([{\"content\": f\"{context}\", \"role\": \"user\"}], temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9dde86f5-188c-40d0-b03c-c2fafb5b1e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T15:36:46.501756Z",
     "iopub.status.busy": "2024-09-15T15:36:46.501229Z",
     "iopub.status.idle": "2024-09-15T15:36:46.505676Z",
     "shell.execute_reply": "2024-09-15T15:36:46.505305Z",
     "shell.execute_reply.started": "2024-09-15T15:36:46.501732Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "\n",
    "book = TextLoader(f\"data/translated-{video_title}.txt\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=0, \n",
    "    separators=[\". \"],\n",
    "    keep_separator=False,\n",
    ")\n",
    "paragraphs = text_splitter.split_documents(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b0ba421a-a32d-4499-b6fa-a29d2ce27335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-15T19:49:11.190090Z",
     "iopub.status.busy": "2024-09-15T19:49:11.189898Z",
     "iopub.status.idle": "2024-09-15T20:12:20.273820Z",
     "shell.execute_reply": "2024-09-15T20:12:20.273456Z",
     "shell.execute_reply.started": "2024-09-15T19:49:11.190075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endereço = data/questions-nlp-demystified-13-recurrent-neural-networks-and-language-models.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a5956919f48578c53ff49ce141490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 9s, sys: 735 ms, total: 23min 10s\n",
      "Wall time: 23min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "csv_filename = f\"data/questions-{video_title}.csv\"\n",
    "pd.DataFrame().to_csv(csv_filename)\n",
    "\n",
    "print(\"Endereço =\",csv_filename)\n",
    "\n",
    "\n",
    "\n",
    "def correct_json(json_string):\n",
    "    corrected_json_string = json_string\n",
    "    if json_string[-2:] in [\"]]\", \"]}\"]:\n",
    "        corrected_json_string  = corrected_json_string[:-1]\n",
    "    return corrected_json_string\n",
    "\n",
    "\n",
    "def generate(p):\n",
    "    temperature = 0.01\n",
    "\n",
    "    for i in range(10):\n",
    "        try:     \n",
    "            qa_pairs_string = generate_question(p.page_content, temperature=temperature)\n",
    "            qa_pairs_string = correct_json(qa_pairs_string)\n",
    "            qa_pairs = json.loads(qa_pairs_string)\n",
    "            base_df = pd.read_csv(csv_filename)\n",
    "            updated_df = pd.concat([base_df, pd.DataFrame(qa_pairs)])\n",
    "            updated_df.to_csv(csv_filename, index=False)\n",
    "            return\n",
    "        except JSONDecodeError as err:\n",
    "            temperature += 0.05\n",
    "            continue\n",
    "\n",
    "\n",
    "for p in tqdm(paragraphs, total=len(paragraphs)):\n",
    "    generate(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7b871-1531-4b71-8707-1ceb226ede39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b45d6-a23f-416a-bb6a-d51260eedc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596a777-fa5b-4a0e-883e-8460c7f7ac95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25454d5-af3f-49d3-8d9e-355d512a2ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075f5cb-bb5d-4d51-b53f-d4a976b43057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
